#!/usr/bin/env python3
"""
æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹ç³»ç»Ÿ - RAG MCPæœåŠ¡
æä¾›æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½çš„MCPæœåŠ¡å™¨
"""

import asyncio
import os
import logging
from typing import Any, Dict, List, Optional
from pathlib import Path

from mcp.server import Server, stdio_server
from mcp.server.models import InitializationOptions
from mcp.types import (
    Tool,
    Resource,
    TextContent,
    ResourceContents,
    TextResourceContents
)

# RAGç›¸å…³å¯¼å…¥
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI
from langchain.schema import Document

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DocumentAssistantRAGService:
    """
    æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹RAGæœåŠ¡
    åŸºäºMCPåè®®çš„ä¼ä¸šçº§RAGæœåŠ¡å®ç°
    """
    
    def __init__(self, 
                 persist_directory: str = "./data/vector_db",
                 model_name: str = "gpt-3.5-turbo"):
        """
        åˆå§‹åŒ–RAGæœåŠ¡
        
        å‚æ•°:
            persist_directory: å‘é‡æ•°æ®åº“æŒä¹…åŒ–ç›®å½•
            model_name: ä½¿ç”¨çš„LLMæ¨¡å‹
        """
        self.server = Server("doc-assistant-rag")
        self.persist_directory = persist_directory
        self.model_name = model_name
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.embeddings = None
        self.vectorstore = None
        self.llm = None
        
        # æ–‡æ¡£ç»Ÿè®¡
        self.doc_stats = {
            "total_documents": 0,
            "total_chunks": 0,
            "last_updated": None
        }
        
        logger.info(f"åˆå§‹åŒ–æ–‡æ¡£åŠ©æ‰‹RAGæœåŠ¡ - æ•°æ®åº“: {persist_directory}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        self._setup_handlers()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–RAGç»„ä»¶"""
        try:
            logger.info("åˆå§‹åŒ–åµŒå…¥æ¨¡å‹...")
            # ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            logger.info("åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # åˆå§‹åŒ–Chromaæ•°æ®åº“
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings,
                collection_name="documents"
            )
            
            # è·å–æ–‡æ¡£ç»Ÿè®¡
            try:
                collection = self.vectorstore._collection
                count = collection.count()
                self.doc_stats["total_chunks"] = count
                logger.info(f"åŠ è½½ç°æœ‰æ•°æ®åº“ï¼ŒåŒ…å« {count} ä¸ªæ–‡æ¡£å—")
            except:
                logger.info("åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“")
            
            logger.info("åˆå§‹åŒ–è¯­è¨€æ¨¡å‹...")
            # åˆå§‹åŒ–LLM
            self.llm = ChatOpenAI(
                model=self.model_name, 
                temperature=0.1,
                max_tokens=2000
            )
            
            logger.info("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _setup_handlers(self):
        """è®¾ç½®MCPå¤„ç†å™¨"""
        
        @self.server.list_tools()
        async def handle_list_tools() -> list[Tool]:
            """å®šä¹‰RAGæœåŠ¡çš„æ‰€æœ‰å·¥å…·"""
            return [
                # æ–‡æ¡£ç®¡ç†å·¥å…·
                Tool(
                    name="add_document",
                    description="æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "æ–‡æ¡£å†…å®¹"
                            },
                            "metadata": {
                                "type": "object",
                                "description": "æ–‡æ¡£å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€æ¥æºã€æ ‡ç­¾ç­‰ï¼‰",
                                "properties": {
                                    "title": {"type": "string"},
                                    "source": {"type": "string"},
                                    "author": {"type": "string"},
                                    "tags": {"type": "array", "items": {"type": "string"}},
                                    "category": {"type": "string"}
                                },
                                "default": {}
                            },
                            "chunk_size": {
                                "type": "integer",
                                "description": "æ–‡æœ¬åˆ†å—å¤§å°",
                                "default": 1000
                            }
                        },
                        "required": ["content"]
                    }
                ),
                
                Tool(
                    name="batch_add_documents",
                    description="æ‰¹é‡æ·»åŠ å¤šä¸ªæ–‡æ¡£",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "documents": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "content": {"type": "string"},
                                        "metadata": {"type": "object"}
                                    },
                                    "required": ["content"]
                                }
                            }
                        },
                        "required": ["documents"]
                    }
                ),
                
                # æ£€ç´¢å·¥å…·
                Tool(
                    name="search_documents",
                    description="åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³æ–‡æ¡£",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æœç´¢æŸ¥è¯¢"
                            },
                            "k": {
                                "type": "integer",
                                "description": "è¿”å›ç»“æœæ•°é‡",
                                "default": 5,
                                "minimum": 1,
                                "maximum": 20
                            },
                            "filter": {
                                "type": "object",
                                "description": "å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶",
                                "default": None
                            },
                            "include_scores": {
                                "type": "boolean",
                                "description": "æ˜¯å¦åŒ…å«ç›¸ä¼¼åº¦åˆ†æ•°",
                                "default": True
                            }
                        },
                        "required": ["query"]
                    }
                ),
                
                Tool(
                    name="semantic_search",
                    description="é«˜çº§è¯­ä¹‰æœç´¢ï¼Œæ”¯æŒå¤æ‚æŸ¥è¯¢",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {"type": "string"},
                            "search_type": {
                                "type": "string",
                                "enum": ["similarity", "mmr", "similarity_score_threshold"],
                                "default": "similarity"
                            },
                            "k": {"type": "integer", "default": 5},
                            "score_threshold": {"type": "number", "default": 0.5}
                        },
                        "required": ["query"]
                    }
                ),
                
                # é—®ç­”å·¥å…·
                Tool(
                    name="answer_question",
                    description="åŸºäºçŸ¥è¯†åº“å›ç­”é—®é¢˜",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "è¦å›ç­”çš„é—®é¢˜"
                            },
                            "context_k": {
                                "type": "integer",
                                "description": "ä½¿ç”¨çš„ä¸Šä¸‹æ–‡æ–‡æ¡£æ•°é‡",
                                "default": 3,
                                "minimum": 1,
                                "maximum": 10
                            },
                            "answer_style": {
                                "type": "string",
                                "enum": ["detailed", "concise", "analytical"],
                                "description": "å›ç­”é£æ ¼",
                                "default": "detailed"
                            },
                            "include_sources": {
                                "type": "boolean",
                                "description": "æ˜¯å¦åŒ…å«ä¿¡æ¯æ¥æº",
                                "default": True
                            }
                        },
                        "required": ["question"]
                    }
                ),
                
                Tool(
                    name="multi_turn_chat",
                    description="å¤šè½®å¯¹è¯é—®ç­”",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "messages": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "role": {"type": "string", "enum": ["user", "assistant"]},
                                        "content": {"type": "string"}
                                    }
                                }
                            },
                            "context_k": {"type": "integer", "default": 3}
                        },
                        "required": ["messages"]
                    }
                ),
                
                # åˆ†æå·¥å…·
                Tool(
                    name="summarize_documents",
                    description="ç”Ÿæˆæ–‡æ¡£æ‘˜è¦",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æ‘˜è¦ä¸»é¢˜æˆ–æŸ¥è¯¢"
                            },
                            "summary_type": {
                                "type": "string",
                                "enum": ["executive", "detailed", "bullet_points"],
                                "default": "detailed"
                            },
                            "max_length": {"type": "integer", "default": 500}
                        },
                        "required": ["query"]
                    }
                ),
                
                # ç®¡ç†å·¥å…·
                Tool(
                    name="get_collection_stats",
                    description="è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "detailed": {
                                "type": "boolean",
                                "description": "æ˜¯å¦è¿”å›è¯¦ç»†ç»Ÿè®¡",
                                "default": False
                            }
                        }
                    }
                ),
                
                Tool(
                    name="clear_collection",
                    description="æ¸…ç©ºçŸ¥è¯†åº“ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "confirm": {
                                "type": "boolean",
                                "description": "ç¡®è®¤æ¸…ç©ºæ“ä½œ"
                            }
                        },
                        "required": ["confirm"]
                    }
                )
            ]
        
        @self.server.list_resources()
        async def handle_list_resources() -> list[Resource]:
            """åˆ—å‡ºå¯ç”¨çš„èµ„æº"""
            return [
                Resource(
                    uri="rag://stats",
                    name="çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯",
                    description="å½“å‰çŸ¥è¯†åº“çš„è¯¦ç»†ç»Ÿè®¡æ•°æ®",
                    mimeType="application/json"
                ),
                Resource(
                    uri="rag://config",
                    name="æœåŠ¡é…ç½®ä¿¡æ¯",
                    description="RAGæœåŠ¡çš„é…ç½®å‚æ•°",
                    mimeType="application/json"
                ),
                Resource(
                    uri="rag://health",
                    name="æœåŠ¡å¥åº·çŠ¶æ€",
                    description="æœåŠ¡ç»„ä»¶çš„å¥åº·æ£€æŸ¥ç»“æœ",
                    mimeType="application/json"
                )
            ]
        
        @self.server.read_resource()
        async def handle_read_resource(uri: str) -> ResourceContents:
            """è¯»å–èµ„æºå†…å®¹"""
            if uri == "rag://stats":
                stats = await self._get_detailed_stats()
                return TextResourceContents(
                    uri=uri,
                    mimeType="application/json",
                    text=stats
                )
            elif uri == "rag://config":
                config = self._get_service_config()
                return TextResourceContents(
                    uri=uri,
                    mimeType="application/json",
                    text=config
                )
            elif uri == "rag://health":
                health = await self._get_health_status()
                return TextResourceContents(
                    uri=uri,
                    mimeType="application/json",
                    text=health
                )
            else:
                return TextResourceContents(
                    uri=uri,
                    mimeType="text/plain",
                    text=f"æœªçŸ¥çš„èµ„æº: {uri}"
                )
        
        @self.server.call_tool()
        async def handle_call_tool(
            name: str,
            arguments: Dict[str, Any]
        ) -> list[TextContent]:
            """å¤„ç†å·¥å…·è°ƒç”¨"""
            
            try:
                logger.info(f"è°ƒç”¨å·¥å…·: {name}")
                
                # æ–‡æ¡£ç®¡ç†å·¥å…·
                if name == "add_document":
                    result = await self._add_document(
                        arguments["content"],
                        arguments.get("metadata", {}),
                        arguments.get("chunk_size", 1000)
                    )
                
                elif name == "batch_add_documents":
                    result = await self._batch_add_documents(
                        arguments["documents"]
                    )
                
                # æ£€ç´¢å·¥å…·
                elif name == "search_documents":
                    result = await self._search_documents(
                        arguments["query"],
                        arguments.get("k", 5),
                        arguments.get("filter"),
                        arguments.get("include_scores", True)
                    )
                
                elif name == "semantic_search":
                    result = await self._semantic_search(
                        arguments["query"],
                        arguments.get("search_type", "similarity"),
                        arguments.get("k", 5),
                        arguments.get("score_threshold", 0.5)
                    )
                
                # é—®ç­”å·¥å…·
                elif name == "answer_question":
                    result = await self._answer_question(
                        arguments["question"],
                        arguments.get("context_k", 3),
                        arguments.get("answer_style", "detailed"),
                        arguments.get("include_sources", True)
                    )
                
                elif name == "multi_turn_chat":
                    result = await self._multi_turn_chat(
                        arguments["messages"],
                        arguments.get("context_k", 3)
                    )
                
                # åˆ†æå·¥å…·
                elif name == "summarize_documents":
                    result = await self._summarize_documents(
                        arguments["query"],
                        arguments.get("summary_type", "detailed"),
                        arguments.get("max_length", 500)
                    )
                
                # ç®¡ç†å·¥å…·
                elif name == "get_collection_stats":
                    result = await self._get_detailed_stats(
                        arguments.get("detailed", False)
                    )
                
                elif name == "clear_collection":
                    result = await self._clear_collection(
                        arguments.get("confirm", False)
                    )
                
                else:
                    result = f"âŒ æœªçŸ¥çš„å·¥å…·: {name}"
                
                logger.info(f"å·¥å…· {name} æ‰§è¡Œå®Œæˆ")
                return [TextContent(type="text", text=result)]
                
            except Exception as e:
                error_msg = f"âŒ æ‰§è¡Œå·¥å…· {name} æ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                return [TextContent(type="text", text=error_msg)]
    
    # å®ç°æ‰€æœ‰å·¥å…·æ–¹æ³•ï¼ˆè¿™é‡Œåªå®ç°å…³é”®æ–¹æ³•ï¼Œå…¶ä»–æ–¹æ³•ç±»ä¼¼ï¼‰
    async def _add_document(self, content: str, metadata: Dict, chunk_size: int) -> str:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            if not content.strip():
                return "âŒ æ–‡æ¡£å†…å®¹ä¸èƒ½ä¸ºç©º"
            
            # æ–‡æœ¬åˆ†å‰²
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=chunk_size,
                chunk_overlap=100,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", " ", ""]
            )
            
            chunks = text_splitter.split_text(content)
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            documents = []
            for i, chunk in enumerate(chunks):
                chunk_metadata = metadata.copy()
                chunk_metadata.update({
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "chunk_size": len(chunk)
                })
                
                documents.append(Document(
                    page_content=chunk,
                    metadata=chunk_metadata
                ))
            
            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            self.vectorstore.add_documents(documents)
            
            # æ›´æ–°ç»Ÿè®¡
            self.doc_stats["total_chunks"] += len(chunks)
            self.doc_stats["last_updated"] = asyncio.get_event_loop().time()
            
            return f"âœ… æˆåŠŸæ·»åŠ æ–‡æ¡£ï¼Œç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—\n" + \
                   f"ğŸ“Š å¹³å‡å—å¤§å°: {sum(len(c) for c in chunks) // len(chunks)} å­—ç¬¦"
            
        except Exception as e:
            return f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}"
    
    async def _answer_question(self, question: str, context_k: int, 
                              answer_style: str, include_sources: bool) -> str:
        """åŸºäºçŸ¥è¯†åº“å›ç­”é—®é¢˜"""
        try:
            # æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.vectorstore.similarity_search_with_score(
                question, k=context_k
            )
            
            if not docs:
                return "âŒ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªé—®é¢˜"
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            sources = []
            
            for i, (doc, score) in enumerate(docs, 1):
                context_parts.append(f"[æ–‡æ¡£ {i}]: {doc.page_content}")
                
                # æ”¶é›†æ¥æºä¿¡æ¯
                metadata = doc.metadata
                source_info = metadata.get("title", metadata.get("source", f"æ–‡æ¡£å— {i}"))
                sources.append(f"{source_info} (ç›¸ä¼¼åº¦: {1-score:.3f})")
            
            context = "\n\n".join(context_parts)
            
            # æ ¹æ®å›ç­”é£æ ¼æ„å»ºæç¤ºè¯
            style_prompts = {
                "detailed": "è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›è¯¦ç»†ã€å…¨é¢çš„å›ç­”ã€‚",
                "concise": "è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›ç®€æ´ã€è¦ç‚¹æ˜ç¡®çš„å›ç­”ã€‚",
                "analytical": "è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯è¿›è¡Œæ·±å…¥åˆ†æï¼Œæä¾›æœ‰è§è§£çš„å›ç­”ã€‚"
            }
            
            prompt = f"""{style_prompts[answer_style]}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ï¼š"""
            
            # ç”Ÿæˆç­”æ¡ˆ
            response = await self.llm.ainvoke(prompt)
            
            # æ„å»ºå®Œæ•´å›ç­”
            answer = f"ğŸ¤– **å›ç­”**\n\n{response.content}\n\n"
            
            if include_sources:
                answer += f"ğŸ“š **ä¿¡æ¯æ¥æº** (åŸºäº {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£):\n"
                for i, source in enumerate(sources, 1):
                    answer += f"  {i}. {source}\n"
            
            return answer
            
        except Exception as e:
            return f"âŒ å›ç­”é—®é¢˜å¤±è´¥: {e}"
    
    async def _get_detailed_stats(self, detailed: bool = False) -> str:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            collection = self.vectorstore._collection
            total_docs = collection.count()
            
            stats = {
                "service": "Document Assistant RAG Service",
                "status": "active",
                "total_chunks": total_docs,
                "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
                "llm_model": self.model_name,
                "vector_db": "ChromaDB"
            }
            
            if detailed and total_docs > 0:
                # è·å–æ›´è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
                results = collection.get()
                if results['metadatas']:
                    # åˆ†æå…ƒæ•°æ®
                    categories = {}
                    sources = {}
                    
                    for metadata in results['metadatas']:
                        cat = metadata.get('category', 'æœªåˆ†ç±»')
                        src = metadata.get('source', 'æœªçŸ¥æ¥æº')
                        
                        categories[cat] = categories.get(cat, 0) + 1
                        sources[src] = sources.get(src, 0) + 1
                    
                    stats["categories"] = categories
                    stats["sources"] = dict(list(sources.items())[:10])  # å‰10ä¸ªæ¥æº
            
            import json
            return json.dumps(stats, indent=2, ensure_ascii=False)
            
        except Exception as e:
            return f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}"
    
    def _get_service_config(self) -> str:
        """è·å–æœåŠ¡é…ç½®"""
        config = {
            "service_name": "doc-assistant-rag",
            "persist_directory": self.persist_directory,
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
            "llm_model": self.model_name,
            "vector_dimensions": 384,
            "max_chunk_size": 2000,
            "chunk_overlap": 100
        }
        
        import json
        return json.dumps(config, indent=2, ensure_ascii=False)
    
    async def _get_health_status(self) -> str:
        """è·å–å¥åº·çŠ¶æ€"""
        health = {
            "status": "healthy",
            "components": {
                "embeddings": "ok",
                "vectorstore": "ok", 
                "llm": "ok"
            },
            "uptime": "running",
            "last_check": asyncio.get_event_loop().time()
        }
        
        # ç®€å•çš„å¥åº·æ£€æŸ¥
        try:
            # æµ‹è¯•åµŒå…¥
            self.embeddings.embed_query("test")
            
            # æµ‹è¯•å‘é‡æ•°æ®åº“
            self.vectorstore._collection.count()
            
            # æµ‹è¯•LLMï¼ˆç®€å•è°ƒç”¨ï¼‰
            # await self.llm.ainvoke("Hello")
            
        except Exception as e:
            health["status"] = "unhealthy"
            health["error"] = str(e)
        
        import json
        return json.dumps(health, indent=2, ensure_ascii=False)
    
    async def run(self):
        """è¿è¡ŒMCPæœåŠ¡å™¨"""
        logger.info("ğŸš€ å¯åŠ¨æ–‡æ¡£åŠ©æ‰‹RAG MCPæœåŠ¡...")
        logger.info("ğŸ“¡ ç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
        
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                InitializationOptions()
            )

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹ç³»ç»Ÿ - RAG MCPæœåŠ¡")
    print("=" * 60)
    print("ğŸ“š åŠŸèƒ½: ä¼ä¸šçº§æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”æœåŠ¡")
    print("ğŸ”§ æŠ€æœ¯: LangChain + ChromaDB + OpenAI")
    print("ğŸ“¡ åè®®: Model Context Protocol (MCP)")
    print("=" * 60)
    
    # åˆ›å»ºå¹¶è¿è¡ŒæœåŠ¡å™¨
    service = DocumentAssistantRAGService()
    await service.run()

if __name__ == "__main__":
    asyncio.run(main())