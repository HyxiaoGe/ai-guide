#!/usr/bin/env python3
"""
æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹ - ç®€åŒ–Webç•Œé¢
ç›´æ¥ä½¿ç”¨RAGåŠŸèƒ½ï¼Œä¸é€šè¿‡MCP
"""

import streamlit as st
import os
from datetime import datetime
from dotenv import load_dotenv

# ç›´æ¥å¯¼å…¥RAGåŠŸèƒ½
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥å¿…è¦çš„åº“
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
import chromadb

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None
if 'llm' not in st.session_state:
    st.session_state.llm = None

class SimpleRAGSystem:
    """ç®€åŒ–çš„RAGç³»ç»Ÿ"""
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.1)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", "ï¼Œ", " ", ""]
        )
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        persist_directory = "./data/vector_db"
        os.makedirs(persist_directory, exist_ok=True)
        
        self.vectorstore = Chroma(
            collection_name="documents",
            embedding_function=self.embeddings,
            persist_directory=persist_directory
        )
    
    def add_document(self, content: str, metadata: dict = None):
        """æ·»åŠ æ–‡æ¡£"""
        try:
            # åˆ†å—
            chunks = self.text_splitter.split_text(content)
            
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            documents = []
            for i, chunk in enumerate(chunks):
                doc_metadata = metadata.copy() if metadata else {}
                doc_metadata["chunk_index"] = i
                doc_metadata["total_chunks"] = len(chunks)
                doc_metadata["created_at"] = datetime.now().isoformat()
                
                documents.append(Document(
                    page_content=chunk,
                    metadata=doc_metadata
                ))
            
            # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
            ids = self.vectorstore.add_documents(documents)
            
            return {
                "success": True,
                "document_id": metadata.get("title", "untitled"),
                "chunks_added": len(ids)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def search_documents(self, query: str, top_k: int = 5):
        """æœç´¢æ–‡æ¡£"""
        try:
            results = self.vectorstore.similarity_search_with_score(query, k=top_k)
            
            formatted_results = []
            for doc, score in results:
                formatted_results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": 1 - score  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                })
            
            return {"success": True, "results": formatted_results}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def answer_question(self, question: str, use_context: bool = True):
        """å›ç­”é—®é¢˜"""
        try:
            if use_context:
                # æœç´¢ç›¸å…³æ–‡æ¡£
                search_results = self.search_documents(question, top_k=3)
                
                if search_results.get("success") and search_results.get("results"):
                    # æ„å»ºä¸Šä¸‹æ–‡
                    context = "\n\n".join([
                        f"æ–‡æ¡£{i+1}: {result['content']}"
                        for i, result in enumerate(search_results["results"])
                    ])
                    
                    # æ„å»ºæç¤ºè¯
                    prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

ç›¸å…³æ–‡æ¡£ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æä¾›å‡†ç¡®ã€ç›¸å…³çš„å›ç­”ï¼š"""
                else:
                    prompt = f"è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{question}"
            else:
                prompt = question
            
            # è·å–å›ç­”
            response = self.llm.invoke(prompt)
            
            return {
                "success": True,
                "answer": response.content,
                "sources": [r["metadata"].get("title", "æœªå‘½å") 
                          for r in search_results.get("results", [])] if use_context else []
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–é›†åˆä¿¡æ¯
            collection = self.vectorstore._collection
            count = collection.count()
            
            return {
                "total_chunks": count,
                "collection_name": "documents",
                "embedding_model": "text-embedding-3-small"
            }
        except:
            return {
                "total_chunks": 0,
                "collection_name": "documents",
                "embedding_model": "text-embedding-3-small"
            }

# åˆ›å»ºRAGç³»ç»Ÿå®ä¾‹
@st.cache_resource
def get_rag_system():
    return SimpleRAGSystem()

def main():
    """ä¸»ç•Œé¢"""
    
    # è·å–RAGç³»ç»Ÿ
    rag = get_rag_system()
    
    # æ ‡é¢˜
    st.title("ğŸ¤– æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹")
    st.markdown("åŸºäº RAG çš„æ–‡æ¡£ç®¡ç†å’Œé—®ç­”ç³»ç»Ÿ")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        # çŸ¥è¯†åº“ç»Ÿè®¡
        stats = rag.get_stats()
        st.metric("æ–‡æ¡£å—æ•°", stats.get("total_chunks", 0))
        st.metric("åµŒå…¥æ¨¡å‹", stats.get("embedding_model", "N/A"))
        
        if st.button("ğŸ”„ åˆ·æ–°ç»Ÿè®¡"):
            st.rerun()
        
        # åŠŸèƒ½é€‰æ‹©
        st.header("ğŸ”§ åŠŸèƒ½é€‰æ‹©")
        mode = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["ğŸ“ æ–‡æ¡£ç®¡ç†", "ğŸ” æ–‡æ¡£æœç´¢", "ğŸ’¬ æ™ºèƒ½é—®ç­”"]
        )
    
    # ä¸»ç•Œé¢å†…å®¹
    if mode == "ğŸ“ æ–‡æ¡£ç®¡ç†":
        document_management(rag)
    elif mode == "ğŸ” æ–‡æ¡£æœç´¢":
        document_search(rag)
    elif mode == "ğŸ’¬ æ™ºèƒ½é—®ç­”":
        intelligent_qa(rag)

def document_management(rag):
    """æ–‡æ¡£ç®¡ç†ç•Œé¢"""
    st.header("ğŸ“ æ–‡æ¡£ç®¡ç†")
    
    # æ–‡æ¡£å†…å®¹è¾“å…¥
    doc_content = st.text_area(
        "æ–‡æ¡£å†…å®¹",
        height=200,
        placeholder="è¯·è¾“å…¥æ–‡æ¡£å†…å®¹..."
    )
    
    # å…ƒæ•°æ®è¾“å…¥
    col1, col2 = st.columns(2)
    with col1:
        doc_title = st.text_input("æ ‡é¢˜", value="")
        doc_author = st.text_input("ä½œè€…", value="")
    with col2:
        doc_source = st.text_input("æ¥æº", value="")
        doc_category = st.text_input("åˆ†ç±»", value="")
    
    doc_tags = st.text_input("æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰", value="")
    
    if st.button("ğŸ“¤ æ·»åŠ æ–‡æ¡£", type="primary"):
        if doc_content:
            with st.spinner("æ·»åŠ ä¸­..."):
                metadata = {
                    "title": doc_title or "æœªå‘½åæ–‡æ¡£",
                    "author": doc_author,
                    "source": doc_source,
                    "category": doc_category,
                    "tags": [tag.strip() for tag in doc_tags.split(",") if tag.strip()]
                }
                
                result = rag.add_document(doc_content, metadata)
                
                if result.get("success"):
                    st.success(f"âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸï¼æ·»åŠ äº† {result.get('chunks_added')} ä¸ªæ–‡æ¡£å—")
                else:
                    st.error(f"âŒ æ–‡æ¡£æ·»åŠ å¤±è´¥: {result.get('error')}")
        else:
            st.warning("è¯·è¾“å…¥æ–‡æ¡£å†…å®¹")
    
    # ç¤ºä¾‹æ–‡æ¡£
    with st.expander("ğŸ“š æ·»åŠ ç¤ºä¾‹æ–‡æ¡£"):
        if st.button("æ·»åŠ AIæŠ€æœ¯ä»‹ç»"):
            sample_content = """äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

AIçš„ä¸»è¦æŠ€æœ¯åŒ…æ‹¬ï¼š
1. æœºå™¨å­¦ä¹ ï¼šè®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼
2. æ·±åº¦å­¦ä¹ ï¼šä½¿ç”¨ç¥ç»ç½‘ç»œå¤„ç†å¤æ‚æ•°æ®
3. è‡ªç„¶è¯­è¨€å¤„ç†ï¼šç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€
4. è®¡ç®—æœºè§†è§‰ï¼šè¯†åˆ«å’Œç†è§£å›¾åƒå†…å®¹

AIçš„åº”ç”¨é¢†åŸŸéå¸¸å¹¿æ³›ï¼ŒåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€é‡‘èåˆ†æã€æ™ºèƒ½å®¢æœç­‰ã€‚"""
            
            result = rag.add_document(sample_content, {
                "title": "AIæŠ€æœ¯ä»‹ç»",
                "author": "ç¤ºä¾‹ç³»ç»Ÿ",
                "category": "æŠ€æœ¯æ–‡æ¡£"
            })
            
            if result.get("success"):
                st.success("âœ… ç¤ºä¾‹æ–‡æ¡£æ·»åŠ æˆåŠŸï¼")
                st.rerun()

def document_search(rag):
    """æ–‡æ¡£æœç´¢ç•Œé¢"""
    st.header("ğŸ” æ–‡æ¡£æœç´¢")
    
    # æœç´¢è¾“å…¥
    query = st.text_input(
        "æœç´¢å†…å®¹",
        placeholder="è¾“å…¥æœç´¢å…³é”®è¯æˆ–é—®é¢˜..."
    )
    
    # æœç´¢é€‰é¡¹
    col1, col2 = st.columns([3, 1])
    with col2:
        top_k = st.number_input("è¿”å›ç»“æœæ•°", min_value=1, max_value=10, value=5)
    
    if st.button("ğŸ” æœç´¢", type="primary"):
        if query:
            with st.spinner("æœç´¢ä¸­..."):
                results = rag.search_documents(query, top_k)
                
                if results.get("success") and results.get("results"):
                    st.success(f"æ‰¾åˆ° {len(results['results'])} ä¸ªç›¸å…³æ–‡æ¡£å—")
                    
                    for i, result in enumerate(results["results"]):
                        with st.container():
                            col1, col2 = st.columns([4, 1])
                            with col1:
                                title = result.get("metadata", {}).get("title", "æœªå‘½åæ–‡æ¡£")
                                st.markdown(f"**{i+1}. {title}**")
                                st.write(result.get("content", ""))
                                
                                # æ˜¾ç¤ºå…ƒæ•°æ®
                                metadata = result.get("metadata", {})
                                if metadata.get("author"):
                                    st.caption(f"ä½œè€…: {metadata['author']}")
                                if metadata.get("category"):
                                    st.caption(f"åˆ†ç±»: {metadata['category']}")
                            
                            with col2:
                                st.metric("ç›¸å…³åº¦", f"{result.get('score', 0):.2%}")
                            
                            st.divider()
                else:
                    st.info("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
        else:
            st.warning("è¯·è¾“å…¥æœç´¢å†…å®¹")

def intelligent_qa(rag):
    """æ™ºèƒ½é—®ç­”ç•Œé¢"""
    st.header("ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # å¯¹è¯å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
            if message["role"] == "assistant" and message.get("sources"):
                with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
                    for source in message["sources"]:
                        st.write(f"- {source}")
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # è·å–AIå›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“
                use_context = st.sidebar.checkbox("ä½¿ç”¨çŸ¥è¯†åº“", value=True)
                
                result = rag.answer_question(prompt, use_context=use_context)
                
                if result.get("success"):
                    answer = result.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")
                    st.write(answer)
                    
                    # æ·»åŠ AIæ¶ˆæ¯
                    message_data = {"role": "assistant", "content": answer}
                    if result.get("sources"):
                        message_data["sources"] = result["sources"]
                        with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
                            for source in result["sources"]:
                                st.write(f"- {source}")
                    
                    st.session_state.messages.append(message_data)
                else:
                    st.error(f"è·å–å›ç­”å¤±è´¥: {result.get('error')}")
    
    # æ¸…é™¤å¯¹è¯æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 3])
    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯"):
            st.session_state.messages = []
            st.rerun()

if __name__ == "__main__":
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("OPENAI_API_KEY"):
        st.error("âŒ è¯·å…ˆé…ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        st.info("ç¼–è¾‘ .env æ–‡ä»¶å¹¶è®¾ç½®: OPENAI_API_KEY=your-api-key")
        st.stop()
    
    main()