{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬4å¤©ï¼šLangGraphå·¥ä½œæµç¼–æ’ - å¾ªåºæ¸è¿›å­¦ä¹ \n",
    "\n",
    "## ä»Šæ—¥å­¦ä¹ ç›®æ ‡\n",
    "1. ç†è§£LangGraphæ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆéœ€è¦å®ƒ\n",
    "2. ä»æœ€ç®€å•çš„ä¾‹å­å¼€å§‹ï¼Œé€æ­¥æŒæ¡æ ¸å¿ƒæ¦‚å¿µ\n",
    "3. å­¦ä¼šæ„å»ºçŠ¶æ€ç®¡ç†çš„å·¥ä½œæµ\n",
    "4. å®ç°æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯æ§åˆ¶\n",
    "5. æ·»åŠ äººå·¥äº¤äº’åŠŸèƒ½\n",
    "\n",
    "## å­¦ä¹ æ–¹å¼\n",
    "- æ¯ä¸ªæ¦‚å¿µéƒ½ä»é›¶å¼€å§‹è§£é‡Š\n",
    "- ä»£ç éƒ½æœ‰è¯¦ç»†æ³¨é‡Š\n",
    "- å¾ªåºæ¸è¿›ï¼Œé€æ­¥æé«˜å¤æ‚åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ä¸ºä»€ä¹ˆéœ€è¦LangGraphï¼Ÿ\n",
    "\n",
    "### 1.1 ä¼ ç»ŸLangChainçš„å±€é™æ€§\n",
    "\n",
    "åœ¨å‰é¢çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨LangChainæ„å»ºäº†ç®€å•çš„é“¾å¼è°ƒç”¨ï¼š\n",
    "```python\n",
    "chain = prompt | llm | parser\n",
    "```\n",
    "\n",
    "è¿™ç§æ–¹å¼çš„é—®é¢˜ï¼š\n",
    "- **åªèƒ½çº¿æ€§æ‰§è¡Œ**ï¼šA â†’ B â†’ Cï¼Œä¸èƒ½æœ‰å¤æ‚çš„æµç¨‹æ§åˆ¶\n",
    "- **æ²¡æœ‰çŠ¶æ€ç®¡ç†**ï¼šæ¯æ¬¡è°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œä¸èƒ½è®°ä½ä¸­é—´ç»“æœ\n",
    "- **ä¸æ”¯æŒæ¡ä»¶åˆ†æ”¯**ï¼šä¸èƒ½æ ¹æ®ç»“æœé€‰æ‹©ä¸åŒçš„è·¯å¾„\n",
    "- **æ²¡æœ‰å¾ªç¯èƒ½åŠ›**ï¼šä¸èƒ½é‡å¤æ‰§è¡ŒæŸäº›æ­¥éª¤ç›´åˆ°æ»¡è¶³æ¡ä»¶\n",
    "\n",
    "### 1.2 LangGraphè§£å†³äº†ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "LangGraphå°†å·¥ä½œæµå»ºæ¨¡ä¸º**æœ‰å‘å›¾ï¼ˆGraphï¼‰**ï¼š\n",
    "- **èŠ‚ç‚¹ï¼ˆNodeï¼‰**ï¼šæ‰§è¡Œå…·ä½“ä»»åŠ¡çš„å‡½æ•°\n",
    "- **è¾¹ï¼ˆEdgeï¼‰**ï¼šè¿æ¥èŠ‚ç‚¹ï¼Œå®šä¹‰æ‰§è¡Œé¡ºåº\n",
    "- **çŠ¶æ€ï¼ˆStateï¼‰**ï¼šåœ¨èŠ‚ç‚¹é—´ä¼ é€’çš„å…±äº«æ•°æ®\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸‹ï¼š\n",
    "- LangChainåƒæ˜¯**æµæ°´çº¿**ï¼šäº§å“åªèƒ½å•å‘æµåŠ¨\n",
    "- LangGraphåƒæ˜¯**å·¥å‚è½¦é—´**ï¼šäº§å“å¯ä»¥åœ¨ä¸åŒå·¥ä½é—´çµæ´»æµè½¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ä»æœ€ç®€å•çš„ä¾‹å­å¼€å§‹\n",
    "\n",
    "### 2.1 ç¬¬ä¸€ä¸ªLangGraphç¨‹åº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ç¬¬ä¸€æ­¥ï¼šå®šä¹‰çŠ¶æ€\n",
    "# çŠ¶æ€æ˜¯åœ¨æ•´ä¸ªå·¥ä½œæµä¸­å…±äº«çš„æ•°æ®ç»“æ„\n",
    "class SimpleState(TypedDict):\n",
    "    \"\"\"\n",
    "    æœ€ç®€å•çš„çŠ¶æ€å®šä¹‰\n",
    "    TypedDictè®©æˆ‘ä»¬å®šä¹‰å­—å…¸çš„ç»“æ„ï¼Œç¡®ä¿ç±»å‹å®‰å…¨\n",
    "    \"\"\"\n",
    "    message: str  # å­˜å‚¨ä¸€ä¸ªæ¶ˆæ¯\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šå®šä¹‰èŠ‚ç‚¹å‡½æ•°\n",
    "# èŠ‚ç‚¹å‡½æ•°æ¥æ”¶çŠ¶æ€ï¼Œå¤„ç†åè¿”å›æ›´æ–°çš„çŠ¶æ€\n",
    "def node_1(state: SimpleState) -> SimpleState:\n",
    "    \"\"\"ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼šæ·»åŠ é—®å€™\"\"\"\n",
    "    print(\"æ‰§è¡ŒèŠ‚ç‚¹1...\")\n",
    "    # è·å–å½“å‰æ¶ˆæ¯\n",
    "    current_message = state.get(\"message\", \"\")\n",
    "    # æ·»åŠ é—®å€™\n",
    "    new_message = f\"ä½ å¥½ï¼{current_message}\"\n",
    "    # è¿”å›æ›´æ–°åçš„çŠ¶æ€\n",
    "    return {\"message\": new_message}\n",
    "\n",
    "def node_2(state: SimpleState) -> SimpleState:\n",
    "    \"\"\"ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼šæ·»åŠ ç»“æŸè¯­\"\"\"\n",
    "    print(\"æ‰§è¡ŒèŠ‚ç‚¹2...\")\n",
    "    current_message = state[\"message\"]\n",
    "    new_message = f\"{current_message} ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\"\n",
    "    return {\"message\": new_message}\n",
    "\n",
    "# ç¬¬ä¸‰æ­¥ï¼šæ„å»ºå›¾\n",
    "# åˆ›å»ºä¸€ä¸ªçŠ¶æ€å›¾ï¼ŒæŒ‡å®šçŠ¶æ€ç±»å‹\n",
    "workflow = StateGraph(SimpleState)\n",
    "\n",
    "# ç¬¬å››æ­¥ï¼šæ·»åŠ èŠ‚ç‚¹\n",
    "# add_node(èŠ‚ç‚¹åç§°, èŠ‚ç‚¹å‡½æ•°)\n",
    "workflow.add_node(\"greeting\", node_1)\n",
    "workflow.add_node(\"farewell\", node_2)\n",
    "\n",
    "# ç¬¬äº”æ­¥ï¼šæ·»åŠ è¾¹ï¼ˆå®šä¹‰æ‰§è¡Œé¡ºåºï¼‰\n",
    "# set_entry_point: è®¾ç½®èµ·å§‹èŠ‚ç‚¹\n",
    "workflow.set_entry_point(\"greeting\")\n",
    "# add_edge: ä»ä¸€ä¸ªèŠ‚ç‚¹åˆ°å¦ä¸€ä¸ªèŠ‚ç‚¹\n",
    "workflow.add_edge(\"greeting\", \"farewell\")\n",
    "# è¿æ¥åˆ°ç»“æŸ\n",
    "workflow.add_edge(\"farewell\", END)\n",
    "\n",
    "# ç¬¬å…­æ­¥ï¼šç¼–è¯‘å›¾\n",
    "app = workflow.compile()\n",
    "\n",
    "# ç¬¬ä¸ƒæ­¥ï¼šè¿è¡Œ\n",
    "print(\"\\n=== è¿è¡Œç®€å•å·¥ä½œæµ ===\")\n",
    "result = app.invoke({\"message\": \"LangGraphå­¦ä¹ è€…\"})\n",
    "print(f\"\\næœ€ç»ˆç»“æœ: {result['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ç†è§£æ‰§è¡Œæµç¨‹\n",
    "\n",
    "ä¸Šé¢çš„ä»£ç æ‰§è¡Œæµç¨‹ï¼š\n",
    "1. **åˆå§‹çŠ¶æ€**ï¼š`{\"message\": \"LangGraphå­¦ä¹ è€…\"}`\n",
    "2. **èŠ‚ç‚¹1å¤„ç†**ï¼šæ·»åŠ \"ä½ å¥½ï¼\" â†’ `{\"message\": \"ä½ å¥½ï¼LangGraphå­¦ä¹ è€…\"}`\n",
    "3. **èŠ‚ç‚¹2å¤„ç†**ï¼šæ·»åŠ ç»“æŸè¯­ â†’ `{\"message\": \"ä½ å¥½ï¼LangGraphå­¦ä¹ è€… ç¥ä½ æœ‰ç¾å¥½çš„ä¸€å¤©ï¼\"}`\n",
    "4. **ç»“æŸ**ï¼šè¿”å›æœ€ç»ˆçŠ¶æ€\n",
    "\n",
    "### 2.3 å¯è§†åŒ–å·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å¯è§†åŒ–å·¥ä½œæµç»“æ„\n",
    "try:\n",
    "    # è·å–å›¾çš„Mermaidè¡¨ç¤ºï¼ˆä¸€ç§å›¾å½¢æè¿°è¯­è¨€ï¼‰\n",
    "    print(\"\\nå·¥ä½œæµç»“æ„ï¼ˆMermaidæ ¼å¼ï¼‰ï¼š\")\n",
    "    print(app.get_graph().draw_mermaid())\n",
    "    print(\"\\nä½ å¯ä»¥å°†ä¸Šé¢çš„ä»£ç ç²˜è´´åˆ° https://mermaid.live æŸ¥çœ‹å›¾å½¢\")\n",
    "except Exception as e:\n",
    "    print(f\"å¯è§†åŒ–å¤±è´¥: {e}\")\n",
    "    print(\"\\nå·¥ä½œæµç»“æ„ï¼š\")\n",
    "    print(\"å¼€å§‹ â†’ greeting â†’ farewell â†’ ç»“æŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ·»åŠ æ¡ä»¶åˆ†æ”¯\n",
    "\n",
    "ç°å®ä¸­çš„å·¥ä½œæµå¾€å¾€éœ€è¦æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„è·¯å¾„ã€‚è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªç®€å•çš„å®¢æœæœºå™¨äººã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import TypedDict, Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# å®šä¹‰æ›´å¤æ‚çš„çŠ¶æ€\n",
    "class CustomerServiceState(TypedDict):\n",
    "    \"\"\"å®¢æœçŠ¶æ€å®šä¹‰\"\"\"\n",
    "    user_input: str          # ç”¨æˆ·è¾“å…¥\n",
    "    intent: str             # æ„å›¾ï¼šquestionï¼ˆé—®é¢˜ï¼‰, complaintï¼ˆæŠ•è¯‰ï¼‰, otherï¼ˆå…¶ä»–ï¼‰\n",
    "    response: str           # å“åº”\n",
    "    satisfaction: str       # æ»¡æ„åº¦ï¼šsatisfiedï¼ˆæ»¡æ„ï¼‰, unsatisfiedï¼ˆä¸æ»¡æ„ï¼‰\n",
    "\n",
    "# åˆå§‹åŒ–LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# èŠ‚ç‚¹1ï¼šæ„å›¾è¯†åˆ«\n",
    "def analyze_intent(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"åˆ†æç”¨æˆ·æ„å›¾\"\"\"\n",
    "    print(\"ğŸ” åˆ†æç”¨æˆ·æ„å›¾...\")\n",
    "    \n",
    "    user_input = state[\"user_input\"]\n",
    "    \n",
    "    # ä½¿ç”¨LLMåˆ†ææ„å›¾\n",
    "    prompt = f\"\"\"\n",
    "    åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„æ„å›¾ï¼Œåªè¿”å›ä»¥ä¸‹ä¸‰ä¸ªé€‰é¡¹ä¹‹ä¸€ï¼š\n",
    "    - question: è¯¢é—®é—®é¢˜\n",
    "    - complaint: æŠ•è¯‰æŠ±æ€¨  \n",
    "    - other: å…¶ä»–\n",
    "    \n",
    "    ç”¨æˆ·è¾“å…¥ï¼š{user_input}\n",
    "    \n",
    "    æ„å›¾ï¼š\n",
    "    \"\"\"\n",
    "    \n",
    "    intent = llm.invoke(prompt).content.strip().lower()\n",
    "    \n",
    "    # ç¡®ä¿æ„å›¾æœ‰æ•ˆ\n",
    "    if intent not in [\"question\", \"complaint\", \"other\"]:\n",
    "        intent = \"other\"\n",
    "    \n",
    "    print(f\"è¯†åˆ«æ„å›¾ï¼š{intent}\")\n",
    "    return {\"intent\": intent}\n",
    "\n",
    "# èŠ‚ç‚¹2ï¼šå¤„ç†é—®é¢˜\n",
    "def handle_question(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"å¤„ç†ç”¨æˆ·é—®é¢˜\"\"\"\n",
    "    print(\"â“ å¤„ç†ç”¨æˆ·é—®é¢˜...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ä½œä¸ºå®¢æœï¼Œå‹å¥½åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "    \n",
    "    ç”¨æˆ·é—®é¢˜ï¼š{state['user_input']}\n",
    "    \n",
    "    å›ç­”ï¼š\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    return {\"response\": response, \"satisfaction\": \"satisfied\"}\n",
    "\n",
    "# èŠ‚ç‚¹3ï¼šå¤„ç†æŠ•è¯‰\n",
    "def handle_complaint(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"å¤„ç†ç”¨æˆ·æŠ•è¯‰\"\"\"\n",
    "    print(\"ğŸ˜¤ å¤„ç†ç”¨æˆ·æŠ•è¯‰...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    ä½œä¸ºå®¢æœï¼Œè€å¿ƒåœ°å¤„ç†ç”¨æˆ·æŠ•è¯‰ï¼Œè¡¨ç¤ºç†è§£å’Œæ­‰æ„ã€‚\n",
    "    \n",
    "    ç”¨æˆ·æŠ•è¯‰ï¼š{state['user_input']}\n",
    "    \n",
    "    å›å¤ï¼š\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    return {\"response\": response, \"satisfaction\": \"unsatisfied\"}\n",
    "\n",
    "# èŠ‚ç‚¹4ï¼šå¤„ç†å…¶ä»–\n",
    "def handle_other(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"å¤„ç†å…¶ä»–æƒ…å†µ\"\"\"\n",
    "    print(\"ğŸ’¬ å¤„ç†å…¶ä»–è¯·æ±‚...\")\n",
    "    return {\n",
    "        \"response\": \"æ„Ÿè°¢æ‚¨çš„ç•™è¨€ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ\",\n",
    "        \"satisfaction\": \"satisfied\"\n",
    "    }\n",
    "\n",
    "# é‡è¦ï¼šæ¡ä»¶å‡½æ•°\n",
    "# è¿™ä¸ªå‡½æ•°å†³å®šä¸‹ä¸€æ­¥å»å“ªä¸ªèŠ‚ç‚¹\n",
    "def route_by_intent(state: CustomerServiceState) -> Literal[\"handle_question\", \"handle_complaint\", \"handle_other\"]:\n",
    "    \"\"\"\n",
    "    æ ¹æ®æ„å›¾å†³å®šè·¯ç”±\n",
    "    è¿”å›å€¼å¿…é¡»æ˜¯èŠ‚ç‚¹çš„åç§°\n",
    "    \"\"\"\n",
    "    intent = state.get(\"intent\", \"other\")\n",
    "    \n",
    "    if intent == \"question\":\n",
    "        return \"handle_question\"\n",
    "    elif intent == \"complaint\":\n",
    "        return \"handle_complaint\"\n",
    "    else:\n",
    "        return \"handle_other\"\n",
    "\n",
    "# æ„å»ºå¸¦æ¡ä»¶åˆ†æ”¯çš„å›¾\n",
    "cs_workflow = StateGraph(CustomerServiceState)\n",
    "\n",
    "# æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹\n",
    "cs_workflow.add_node(\"analyze_intent\", analyze_intent)\n",
    "cs_workflow.add_node(\"handle_question\", handle_question)\n",
    "cs_workflow.add_node(\"handle_complaint\", handle_complaint)\n",
    "cs_workflow.add_node(\"handle_other\", handle_other)\n",
    "\n",
    "# è®¾ç½®å…¥å£\n",
    "cs_workflow.set_entry_point(\"analyze_intent\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "# add_conditional_edges(èµ·å§‹èŠ‚ç‚¹, æ¡ä»¶å‡½æ•°, å¯èƒ½çš„ç›®æ ‡èŠ‚ç‚¹å­—å…¸)\n",
    "cs_workflow.add_conditional_edges(\n",
    "    \"analyze_intent\",  # ä»è¿™ä¸ªèŠ‚ç‚¹å¼€å§‹\n",
    "    route_by_intent,   # ä½¿ç”¨è¿™ä¸ªå‡½æ•°å†³å®šå»å“ª\n",
    "    {                  # å¯èƒ½çš„ç›®æ ‡\n",
    "        \"handle_question\": \"handle_question\",\n",
    "        \"handle_complaint\": \"handle_complaint\",\n",
    "        \"handle_other\": \"handle_other\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# æ‰€æœ‰å¤„ç†èŠ‚ç‚¹éƒ½è¿æ¥åˆ°ç»“æŸ\n",
    "cs_workflow.add_edge(\"handle_question\", END)\n",
    "cs_workflow.add_edge(\"handle_complaint\", END)\n",
    "cs_workflow.add_edge(\"handle_other\", END)\n",
    "\n",
    "# ç¼–è¯‘\n",
    "cs_app = cs_workflow.compile()\n",
    "\n",
    "print(\"\\n=== å®¢æœæœºå™¨äººå·¥ä½œæµ ===\")\n",
    "print(\"\\nå·¥ä½œæµç»“æ„ï¼š\")\n",
    "print(\"å¼€å§‹ â†’ åˆ†ææ„å›¾ â†’ [æ ¹æ®æ„å›¾é€‰æ‹©] â†’ å¤„ç†èŠ‚ç‚¹ â†’ ç»“æŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å…¥\n",
    "test_inputs = [\n",
    "    \"ä½ ä»¬çš„äº§å“ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ\",\n",
    "    \"æˆ‘å¯¹ä½ ä»¬çš„æœåŠ¡éå¸¸ä¸æ»¡æ„ï¼\",\n",
    "    \"ä»Šå¤©å¤©æ°”çœŸå¥½\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ§ª æµ‹è¯•å®¢æœæœºå™¨äºº\")\n",
    "for user_input in test_inputs:\n",
    "    print(f\"\\n--- ç”¨æˆ·è¾“å…¥ï¼š{user_input} ---\")\n",
    "    \n",
    "    result = cs_app.invoke({\"user_input\": user_input})\n",
    "    \n",
    "    print(f\"æ„å›¾ï¼š{result.get('intent', 'æœªè¯†åˆ«')}\")\n",
    "    print(f\"å›å¤ï¼š{result.get('response', 'æ— å›å¤')[:100]}...\")\n",
    "    print(f\"æ»¡æ„åº¦ï¼š{result.get('satisfaction', 'æœªçŸ¥')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ·»åŠ å¾ªç¯å’ŒçŠ¶æ€ç´¯ç§¯\n",
    "\n",
    "æœ‰æ—¶æˆ‘ä»¬éœ€è¦é‡å¤æ‰§è¡ŒæŸäº›æ­¥éª¤ï¼Œæ¯”å¦‚ä¸æ–­æ”¹è¿›ç­”æ¡ˆç›´åˆ°æ»¡æ„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "\n",
    "# å®šä¹‰å¸¦æœ‰åˆ—è¡¨ç´¯ç§¯çš„çŠ¶æ€\n",
    "class IterativeState(TypedDict):\n",
    "    \"\"\"è¿­ä»£æ”¹è¿›çš„çŠ¶æ€\"\"\"\n",
    "    question: str                              # åŸå§‹é—®é¢˜\n",
    "    drafts: Annotated[Sequence[str], operator.add]  # ç­”æ¡ˆè‰ç¨¿åˆ—è¡¨ï¼ˆä¼šç´¯ç§¯ï¼‰\n",
    "    current_draft: str                         # å½“å‰è‰ç¨¿\n",
    "    is_satisfactory: bool                      # æ˜¯å¦æ»¡æ„\n",
    "    iteration: int                             # è¿­ä»£æ¬¡æ•°\n",
    "\n",
    "# æ³¨æ„ï¼šAnnotated[Sequence[str], operator.add] çš„å«ä¹‰ï¼š\n",
    "# - Sequence[str]ï¼šè¿™æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åºåˆ—\n",
    "# - operator.addï¼šå½“å¤šä¸ªèŠ‚ç‚¹è¿”å›è¿™ä¸ªå­—æ®µæ—¶ï¼Œä½¿ç”¨åŠ æ³•åˆå¹¶ï¼ˆåˆ—è¡¨æ‹¼æ¥ï¼‰\n",
    "\n",
    "def generate_draft(state: IterativeState) -> IterativeState:\n",
    "    \"\"\"ç”Ÿæˆç­”æ¡ˆè‰ç¨¿\"\"\"\n",
    "    iteration = state.get(\"iteration\", 0) + 1\n",
    "    print(f\"\\nğŸ“ ç”Ÿæˆç¬¬ {iteration} ç‰ˆè‰ç¨¿...\")\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # æ ¹æ®è¿­ä»£æ¬¡æ•°è°ƒæ•´æç¤ºè¯\n",
    "    if iteration == 1:\n",
    "        prompt = f\"è¯·å›ç­”è¿™ä¸ªé—®é¢˜ï¼ˆç¬¬ä¸€æ¬¡å°è¯•ï¼‰ï¼š{question}\"\n",
    "    else:\n",
    "        previous_draft = state.get(\"current_draft\", \"\")\n",
    "        prompt = f\"\"\"\n",
    "        ä¹‹å‰çš„å›ç­”ï¼š{previous_draft}\n",
    "        \n",
    "        è¿™ä¸ªå›ç­”ä¸å¤Ÿå¥½ï¼Œè¯·æ”¹è¿›å¹¶æä¾›æ›´å¥½çš„ç­”æ¡ˆã€‚\n",
    "        é—®é¢˜ï¼š{question}\n",
    "        \"\"\"\n",
    "    \n",
    "    draft = llm.invoke(prompt).content\n",
    "    \n",
    "    return {\n",
    "        \"drafts\": [f\"ç¬¬{iteration}ç‰ˆ: {draft}\"],  # æ·»åŠ åˆ°è‰ç¨¿åˆ—è¡¨\n",
    "        \"current_draft\": draft,\n",
    "        \"iteration\": iteration\n",
    "    }\n",
    "\n",
    "def evaluate_draft(state: IterativeState) -> IterativeState:\n",
    "    \"\"\"è¯„ä¼°è‰ç¨¿è´¨é‡\"\"\"\n",
    "    print(\"ğŸ” è¯„ä¼°è‰ç¨¿è´¨é‡...\")\n",
    "    \n",
    "    # ç®€å•çš„è¯„ä¼°é€»è¾‘ï¼š\n",
    "    # - ç¬¬1æ¬¡ï¼šæ€»æ˜¯ä¸æ»¡æ„ï¼ˆæ¼”ç¤ºå¾ªç¯ï¼‰\n",
    "    # - ç¬¬2æ¬¡ï¼šæœ‰50%æ¦‚ç‡æ»¡æ„\n",
    "    # - ç¬¬3æ¬¡åŠä»¥ä¸Šï¼šæ€»æ˜¯æ»¡æ„ï¼ˆé¿å…æ— é™å¾ªç¯ï¼‰\n",
    "    \n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    current_draft = state.get(\"current_draft\", \"\")\n",
    "    \n",
    "    # ä¹Ÿå¯ä»¥ç”¨LLMæ¥è¯„ä¼°\n",
    "    if iteration >= 3 or (iteration == 2 and len(current_draft) > 100):\n",
    "        is_satisfactory = True\n",
    "        print(\"âœ… è‰ç¨¿è´¨é‡æ»¡æ„\")\n",
    "    else:\n",
    "        is_satisfactory = False\n",
    "        print(\"âŒ è‰ç¨¿éœ€è¦æ”¹è¿›\")\n",
    "    \n",
    "    return {\"is_satisfactory\": is_satisfactory}\n",
    "\n",
    "def should_continue(state: IterativeState) -> Literal[\"generate_draft\", \"end\"]:\n",
    "    \"\"\"å†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£\"\"\"\n",
    "    if state.get(\"is_satisfactory\", False):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"generate_draft\"\n",
    "\n",
    "# æ„å»ºè¿­ä»£å·¥ä½œæµ\n",
    "iterative_workflow = StateGraph(IterativeState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "iterative_workflow.add_node(\"generate_draft\", generate_draft)\n",
    "iterative_workflow.add_node(\"evaluate_draft\", evaluate_draft)\n",
    "\n",
    "# è®¾ç½®æµç¨‹\n",
    "iterative_workflow.set_entry_point(\"generate_draft\")\n",
    "iterative_workflow.add_edge(\"generate_draft\", \"evaluate_draft\")\n",
    "\n",
    "# æ¡ä»¶è¾¹ï¼šè¯„ä¼°åå†³å®šæ˜¯ç»§ç»­è¿˜æ˜¯ç»“æŸ\n",
    "iterative_workflow.add_conditional_edges(\n",
    "    \"evaluate_draft\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"generate_draft\": \"generate_draft\",  # å¾ªç¯å›å»\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# ç¼–è¯‘\n",
    "iterative_app = iterative_workflow.compile()\n",
    "\n",
    "print(\"\\n=== è¿­ä»£æ”¹è¿›å·¥ä½œæµ ===\")\n",
    "print(\"æµç¨‹ï¼šç”Ÿæˆè‰ç¨¿ â†’ è¯„ä¼° â†’ [æ»¡æ„åˆ™ç»“æŸï¼Œå¦åˆ™å¾ªç¯]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æµ‹è¯•è¿­ä»£å·¥ä½œæµ\n",
    "print(\"\\nğŸ§ª æµ‹è¯•è¿­ä»£æ”¹è¿›\")\n",
    "question = \"å¦‚ä½•å­¦ä¹ LangGraphï¼Ÿ\"\n",
    "\n",
    "result = iterative_app.invoke({\"question\": question})\n",
    "\n",
    "print(f\"\\né—®é¢˜ï¼š{question}\")\n",
    "print(f\"\\næ€»å…±è¿­ä»£æ¬¡æ•°ï¼š{result['iteration']}\")\n",
    "print(\"\\næ‰€æœ‰è‰ç¨¿ç‰ˆæœ¬ï¼š\")\n",
    "for i, draft in enumerate(result['drafts']):\n",
    "    print(f\"\\n{draft[:150]}...\")\n",
    "\n",
    "print(f\"\\næœ€ç»ˆç­”æ¡ˆï¼š\")\n",
    "print(result['current_draft'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Human-in-the-Loopï¼ˆäººæœºåä½œï¼‰\n",
    "\n",
    "å¾ˆå¤šåœºæ™¯éœ€è¦äººå·¥å‚ä¸å†³ç­–æˆ–å®¡æ ¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "import uuid\n",
    "\n",
    "# å®šä¹‰éœ€è¦äººå·¥å®¡æ ¸çš„çŠ¶æ€\n",
    "class ApprovalState(TypedDict):\n",
    "    \"\"\"éœ€è¦å®¡æ‰¹çš„å·¥ä½œæµçŠ¶æ€\"\"\"\n",
    "    task: str                    # ä»»åŠ¡æè¿°\n",
    "    ai_suggestion: str           # AIçš„å»ºè®®\n",
    "    human_feedback: str          # äººå·¥åé¦ˆ\n",
    "    approved: bool              # æ˜¯å¦æ‰¹å‡†\n",
    "    final_output: str           # æœ€ç»ˆè¾“å‡º\n",
    "\n",
    "def generate_suggestion(state: ApprovalState) -> ApprovalState:\n",
    "    \"\"\"AIç”Ÿæˆå»ºè®®\"\"\"\n",
    "    print(\"ğŸ¤– AIæ­£åœ¨ç”Ÿæˆå»ºè®®...\")\n",
    "    \n",
    "    task = state[\"task\"]\n",
    "    prompt = f\"\"\"\n",
    "    è¯·ä¸ºä»¥ä¸‹ä»»åŠ¡æä¾›ä¸€ä¸ªè§£å†³æ–¹æ¡ˆå»ºè®®ï¼š\n",
    "    \n",
    "    ä»»åŠ¡ï¼š{task}\n",
    "    \n",
    "    å»ºè®®ï¼š\n",
    "    \"\"\"\n",
    "    \n",
    "    suggestion = llm.invoke(prompt).content\n",
    "    print(f\"\\nAIå»ºè®®ï¼š{suggestion[:100]}...\")\n",
    "    \n",
    "    return {\"ai_suggestion\": suggestion}\n",
    "\n",
    "def wait_for_approval(state: ApprovalState) -> ApprovalState:\n",
    "    \"\"\"ç­‰å¾…äººå·¥å®¡æ‰¹ï¼ˆæ¨¡æ‹Ÿï¼‰\"\"\"\n",
    "    print(\"\\nâ¸ï¸ ç­‰å¾…äººå·¥å®¡æ‰¹...\")\n",
    "    print(f\"\\nå½“å‰ä»»åŠ¡ï¼š{state['task']}\")\n",
    "    print(f\"AIå»ºè®®ï¼š{state['ai_suggestion']}\")\n",
    "    \n",
    "    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šï¼š\n",
    "    # 1. å‘é€é€šçŸ¥ç»™å®¡æ‰¹äºº\n",
    "    # 2. ç­‰å¾…å®¡æ‰¹ç»“æœ\n",
    "    # 3. è·å–åé¦ˆ\n",
    "    \n",
    "    # æ¨¡æ‹Ÿäººå·¥è¾“å…¥\n",
    "    print(\"\\nè¯·å®¡æ‰¹ï¼ˆè¾“å…¥ 'yes' æ‰¹å‡†ï¼Œ'no' æ‹’ç»ï¼Œæˆ–æä¾›ä¿®æ”¹å»ºè®®ï¼‰ï¼š\")\n",
    "    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬è‡ªåŠ¨æ‰¹å‡†\n",
    "    user_input = \"yes\"  # å®é™…åº”ç”¨ä¸­ä»ç”¨æˆ·è·å–\n",
    "    \n",
    "    if user_input.lower() == \"yes\":\n",
    "        return {\n",
    "            \"approved\": True,\n",
    "            \"human_feedback\": \"æ‰¹å‡†æ‰§è¡Œ\"\n",
    "        }\n",
    "    elif user_input.lower() == \"no\":\n",
    "        return {\n",
    "            \"approved\": False,\n",
    "            \"human_feedback\": \"æ‹’ç»æ‰§è¡Œ\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"approved\": False,\n",
    "            \"human_feedback\": user_input\n",
    "        }\n",
    "\n",
    "def execute_task(state: ApprovalState) -> ApprovalState:\n",
    "    \"\"\"æ‰§è¡Œä»»åŠ¡\"\"\"\n",
    "    print(\"âœ… æ‰§è¡Œå·²æ‰¹å‡†çš„ä»»åŠ¡...\")\n",
    "    \n",
    "    return {\n",
    "        \"final_output\": f\"ä»»åŠ¡å·²å®Œæˆï¼š{state['ai_suggestion']}\"\n",
    "    }\n",
    "\n",
    "def revise_suggestion(state: ApprovalState) -> ApprovalState:\n",
    "    \"\"\"æ ¹æ®åé¦ˆä¿®æ”¹å»ºè®®\"\"\"\n",
    "    print(\"ğŸ“ æ ¹æ®åé¦ˆä¿®æ”¹å»ºè®®...\")\n",
    "    \n",
    "    feedback = state[\"human_feedback\"]\n",
    "    original = state[\"ai_suggestion\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    åŸå§‹å»ºè®®ï¼š{original}\n",
    "    \n",
    "    äººå·¥åé¦ˆï¼š{feedback}\n",
    "    \n",
    "    è¯·æ ¹æ®åé¦ˆä¿®æ”¹å»ºè®®ï¼š\n",
    "    \"\"\"\n",
    "    \n",
    "    revised = llm.invoke(prompt).content\n",
    "    \n",
    "    return {\n",
    "        \"ai_suggestion\": revised,\n",
    "        \"human_feedback\": \"\"  # æ¸…ç©ºåé¦ˆï¼Œå‡†å¤‡ä¸‹æ¬¡å®¡æ‰¹\n",
    "    }\n",
    "\n",
    "def approval_router(state: ApprovalState) -> Literal[\"execute_task\", \"revise_suggestion\"]:\n",
    "    \"\"\"æ ¹æ®å®¡æ‰¹ç»“æœå†³å®šè·¯ç”±\"\"\"\n",
    "    if state.get(\"approved\", False):\n",
    "        return \"execute_task\"\n",
    "    else:\n",
    "        return \"revise_suggestion\"\n",
    "\n",
    "# æ„å»ºå®¡æ‰¹å·¥ä½œæµ\n",
    "approval_workflow = StateGraph(ApprovalState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "approval_workflow.add_node(\"generate_suggestion\", generate_suggestion)\n",
    "approval_workflow.add_node(\"wait_for_approval\", wait_for_approval)\n",
    "approval_workflow.add_node(\"execute_task\", execute_task)\n",
    "approval_workflow.add_node(\"revise_suggestion\", revise_suggestion)\n",
    "\n",
    "# è®¾ç½®æµç¨‹\n",
    "approval_workflow.set_entry_point(\"generate_suggestion\")\n",
    "approval_workflow.add_edge(\"generate_suggestion\", \"wait_for_approval\")\n",
    "\n",
    "# å®¡æ‰¹åçš„æ¡ä»¶è·¯ç”±\n",
    "approval_workflow.add_conditional_edges(\n",
    "    \"wait_for_approval\",\n",
    "    approval_router,\n",
    "    {\n",
    "        \"execute_task\": \"execute_task\",\n",
    "        \"revise_suggestion\": \"revise_suggestion\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# ä¿®æ”¹åé‡æ–°å®¡æ‰¹\n",
    "approval_workflow.add_edge(\"revise_suggestion\", \"wait_for_approval\")\n",
    "approval_workflow.add_edge(\"execute_task\", END)\n",
    "\n",
    "# ç¼–è¯‘ï¼ˆå¯ä»¥æ·»åŠ æ£€æŸ¥ç‚¹ä¿å­˜å™¨ä»¥æ”¯æŒä¸­æ–­å’Œæ¢å¤ï¼‰\n",
    "memory = MemorySaver()  # å†…å­˜ä¸­ä¿å­˜çŠ¶æ€\n",
    "approval_app = approval_workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"\\n=== äººæœºåä½œå·¥ä½œæµ ===\")\n",
    "print(\"æµç¨‹ï¼šç”Ÿæˆå»ºè®® â†’ äººå·¥å®¡æ‰¹ â†’ [æ‰¹å‡†åˆ™æ‰§è¡Œï¼Œå¦åˆ™ä¿®æ”¹åé‡å®¡]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æµ‹è¯•å®¡æ‰¹å·¥ä½œæµ\n",
    "print(\"\\nğŸ§ª æµ‹è¯•äººæœºåä½œå·¥ä½œæµ\")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªçº¿ç¨‹IDï¼ˆç”¨äºä¿å­˜çŠ¶æ€ï¼‰\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# è¿è¡Œå·¥ä½œæµ\n",
    "task = \"åˆ›å»ºä¸€ä¸ªç”¨æˆ·æ³¨å†ŒåŠŸèƒ½\"\n",
    "result = approval_app.invoke(\n",
    "    {\"task\": task},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(f\"\\næœ€ç»ˆç»“æœï¼š\")\n",
    "print(f\"ä»»åŠ¡ï¼š{result['task']}\")\n",
    "print(f\"æœ€ç»ˆè¾“å‡ºï¼š{result.get('final_output', 'æœªå®Œæˆ')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å®æˆ˜ï¼šæ„å»ºå®Œæ•´çš„ç ”ç©¶åŠ©æ‰‹å·¥ä½œæµ\n",
    "\n",
    "å°†ä»Šå¤©å­¦åˆ°çš„æ‰€æœ‰æ¦‚å¿µæ•´åˆåˆ°ä¸€ä¸ªå®é™…åº”ç”¨ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# å®šä¹‰ç ”ç©¶åŠ©æ‰‹çš„çŠ¶æ€\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"ç ”ç©¶åŠ©æ‰‹çŠ¶æ€\"\"\"\n",
    "    topic: str                                    # ç ”ç©¶ä¸»é¢˜\n",
    "    research_questions: List[str]                 # ç ”ç©¶é—®é¢˜åˆ—è¡¨\n",
    "    search_results: Annotated[List[str], operator.add]  # æœç´¢ç»“æœï¼ˆç´¯ç§¯ï¼‰\n",
    "    draft_report: str                            # æŠ¥å‘Šè‰ç¨¿\n",
    "    final_report: str                            # æœ€ç»ˆæŠ¥å‘Š\n",
    "    quality_score: float                         # è´¨é‡è¯„åˆ†\n",
    "    revision_count: int                          # ä¿®è®¢æ¬¡æ•°\n",
    "    messages: Annotated[Sequence[str], operator.add]    # è¿‡ç¨‹æ¶ˆæ¯\n",
    "\n",
    "# èŠ‚ç‚¹å®ç°\n",
    "def generate_questions(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"ç”Ÿæˆç ”ç©¶é—®é¢˜\"\"\"\n",
    "    print(\"\\nğŸ” ç”Ÿæˆç ”ç©¶é—®é¢˜...\")\n",
    "    \n",
    "    topic = state[\"topic\"]\n",
    "    prompt = f\"\"\"\n",
    "    ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜ç”Ÿæˆ3ä¸ªå…³é”®ç ”ç©¶é—®é¢˜ï¼š\n",
    "    \n",
    "    ä¸»é¢˜ï¼š{topic}\n",
    "    \n",
    "    è¯·ç”Ÿæˆå…·ä½“ã€å¯ç ”ç©¶çš„é—®é¢˜ã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content\n",
    "    # ç®€å•è§£æï¼ˆå®é™…åº”è¯¥ç”¨æ›´robustçš„æ–¹æ³•ï¼‰\n",
    "    questions = [q.strip() for q in response.split('\\n') if q.strip() and any(c.isalnum() for c in q)]\n",
    "    questions = questions[:3]  # æœ€å¤š3ä¸ªé—®é¢˜\n",
    "    \n",
    "    return {\n",
    "        \"research_questions\": questions,\n",
    "        \"messages\": [f\"ç”Ÿæˆäº†{len(questions)}ä¸ªç ”ç©¶é—®é¢˜\"]\n",
    "    }\n",
    "\n",
    "def search_information(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"æœç´¢ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰\"\"\"\n",
    "    print(\"\\nğŸ” æœç´¢ç›¸å…³ä¿¡æ¯...\")\n",
    "    \n",
    "    results = []\n",
    "    for question in state[\"research_questions\"]:\n",
    "        # æ¨¡æ‹Ÿæœç´¢ç»“æœ\n",
    "        result = f\"å…³äº'{question}'çš„æœç´¢ç»“æœï¼šè¿™æ˜¯ä¸€äº›ç›¸å…³ä¿¡æ¯...\"\n",
    "        results.append(result)\n",
    "        print(f\"  æœç´¢ï¼š{question[:50]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"search_results\": results,\n",
    "        \"messages\": [f\"å®Œæˆ{len(results)}ä¸ªé—®é¢˜çš„æœç´¢\"]\n",
    "    }\n",
    "\n",
    "def write_draft(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"æ’°å†™æŠ¥å‘Šè‰ç¨¿\"\"\"\n",
    "    print(\"\\nâœï¸ æ’°å†™ç ”ç©¶æŠ¥å‘Š...\")\n",
    "    \n",
    "    topic = state[\"topic\"]\n",
    "    questions = state[\"research_questions\"]\n",
    "    results = state.get(\"search_results\", [])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    åŸºäºä»¥ä¸‹ä¿¡æ¯æ’°å†™ç ”ç©¶æŠ¥å‘Šï¼š\n",
    "    \n",
    "    ä¸»é¢˜ï¼š{topic}\n",
    "    \n",
    "    ç ”ç©¶é—®é¢˜å’Œå‘ç°ï¼š\n",
    "    {chr(10).join([f'{i+1}. {q}\\n   {r}' for i, (q, r) in enumerate(zip(questions, results))])}\n",
    "    \n",
    "    è¯·æ’°å†™ä¸€ä»½ç»“æ„æ¸…æ™°çš„ç ”ç©¶æŠ¥å‘Šã€‚\n",
    "    \"\"\"\n",
    "    \n",
    "    draft = llm.invoke(prompt).content\n",
    "    \n",
    "    return {\n",
    "        \"draft_report\": draft,\n",
    "        \"revision_count\": state.get(\"revision_count\", 0) + 1,\n",
    "        \"messages\": [f\"å®Œæˆç¬¬{state.get('revision_count', 0) + 1}ç‰ˆè‰ç¨¿\"]\n",
    "    }\n",
    "\n",
    "def evaluate_quality(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"è¯„ä¼°æŠ¥å‘Šè´¨é‡\"\"\"\n",
    "    print(\"\\nğŸ“Š è¯„ä¼°æŠ¥å‘Šè´¨é‡...\")\n",
    "    \n",
    "    draft = state[\"draft_report\"]\n",
    "    \n",
    "    # ç®€å•çš„è´¨é‡è¯„åˆ†ï¼ˆåŸºäºé•¿åº¦å’Œä¿®è®¢æ¬¡æ•°ï¼‰\n",
    "    base_score = min(len(draft) / 1000, 1.0) * 0.5  # é•¿åº¦åˆ†\n",
    "    revision_bonus = min(state.get(\"revision_count\", 0) * 0.2, 0.5)  # ä¿®è®¢åˆ†\n",
    "    quality_score = base_score + revision_bonus\n",
    "    \n",
    "    print(f\"  è´¨é‡è¯„åˆ†ï¼š{quality_score:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"quality_score\": quality_score,\n",
    "        \"messages\": [f\"è´¨é‡è¯„åˆ†ï¼š{quality_score:.2f}\"]\n",
    "    }\n",
    "\n",
    "def finalize_report(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"å®ŒæˆæŠ¥å‘Š\"\"\"\n",
    "    print(\"\\nâœ… å®Œæˆç ”ç©¶æŠ¥å‘Š\")\n",
    "    \n",
    "    return {\n",
    "        \"final_report\": state[\"draft_report\"],\n",
    "        \"messages\": [\"ç ”ç©¶æŠ¥å‘Šå·²å®Œæˆ\"]\n",
    "    }\n",
    "\n",
    "def should_revise(state: ResearchState) -> Literal[\"write_draft\", \"finalize_report\"]:\n",
    "    \"\"\"å†³å®šæ˜¯å¦éœ€è¦ä¿®è®¢\"\"\"\n",
    "    score = state.get(\"quality_score\", 0)\n",
    "    revision_count = state.get(\"revision_count\", 0)\n",
    "    \n",
    "    # è´¨é‡ä½äº0.7ä¸”ä¿®è®¢æ¬¡æ•°å°‘äº3æ¬¡æ—¶ç»§ç»­ä¿®è®¢\n",
    "    if score < 0.7 and revision_count < 3:\n",
    "        print(\"  éœ€è¦ç»§ç»­æ”¹è¿›\")\n",
    "        return \"write_draft\"\n",
    "    else:\n",
    "        print(\"  è´¨é‡æ»¡è¶³è¦æ±‚\")\n",
    "        return \"finalize_report\"\n",
    "\n",
    "# æ„å»ºç ”ç©¶åŠ©æ‰‹å·¥ä½œæµ\n",
    "research_workflow = StateGraph(ResearchState)\n",
    "\n",
    "# æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹\n",
    "research_workflow.add_node(\"generate_questions\", generate_questions)\n",
    "research_workflow.add_node(\"search_information\", search_information)\n",
    "research_workflow.add_node(\"write_draft\", write_draft)\n",
    "research_workflow.add_node(\"evaluate_quality\", evaluate_quality)\n",
    "research_workflow.add_node(\"finalize_report\", finalize_report)\n",
    "\n",
    "# è®¾ç½®æµç¨‹\n",
    "research_workflow.set_entry_point(\"generate_questions\")\n",
    "research_workflow.add_edge(\"generate_questions\", \"search_information\")\n",
    "research_workflow.add_edge(\"search_information\", \"write_draft\")\n",
    "research_workflow.add_edge(\"write_draft\", \"evaluate_quality\")\n",
    "\n",
    "# æ¡ä»¶è¾¹ï¼šæ ¹æ®è´¨é‡å†³å®šæ˜¯ä¿®è®¢è¿˜æ˜¯å®Œæˆ\n",
    "research_workflow.add_conditional_edges(\n",
    "    \"evaluate_quality\",\n",
    "    should_revise,\n",
    "    {\n",
    "        \"write_draft\": \"write_draft\",\n",
    "        \"finalize_report\": \"finalize_report\"\n",
    "    }\n",
    ")\n",
    "\n",
    "research_workflow.add_edge(\"finalize_report\", END)\n",
    "\n",
    "# ç¼–è¯‘\n",
    "research_app = research_workflow.compile()\n",
    "\n",
    "print(\"\\n=== ç ”ç©¶åŠ©æ‰‹å·¥ä½œæµ ===\")\n",
    "print(\"æµç¨‹ï¼šç”Ÿæˆé—®é¢˜ â†’ æœç´¢ä¿¡æ¯ â†’ æ’°å†™æŠ¥å‘Š â†’ è¯„ä¼°è´¨é‡ â†’ [æ»¡æ„åˆ™å®Œæˆï¼Œå¦åˆ™ä¿®è®¢]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æµ‹è¯•ç ”ç©¶åŠ©æ‰‹\n",
    "print(\"\\nğŸ§ª æµ‹è¯•ç ”ç©¶åŠ©æ‰‹å·¥ä½œæµ\")\n",
    "\n",
    "research_topic = \"LangGraphåœ¨å®é™…é¡¹ç›®ä¸­çš„åº”ç”¨\"\n",
    "print(f\"\\nç ”ç©¶ä¸»é¢˜ï¼š{research_topic}\")\n",
    "\n",
    "# è¿è¡Œå·¥ä½œæµ\n",
    "result = research_app.invoke({\"topic\": research_topic})\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "print(\"\\nğŸ“Š æ‰§è¡Œè¿‡ç¨‹ï¼š\")\n",
    "for msg in result.get(\"messages\", []):\n",
    "    print(f\"  - {msg}\")\n",
    "\n",
    "print(f\"\\nğŸ“ ç ”ç©¶é—®é¢˜ï¼š\")\n",
    "for i, q in enumerate(result.get(\"research_questions\", []), 1):\n",
    "    print(f\"  {i}. {q}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æœ€ç»ˆè´¨é‡è¯„åˆ†ï¼š{result.get('quality_score', 0):.2f}\")\n",
    "print(f\"ğŸ“„ ä¿®è®¢æ¬¡æ•°ï¼š{result.get('revision_count', 0)}\")\n",
    "\n",
    "print(f\"\\nğŸ“‘ æœ€ç»ˆæŠ¥å‘Šé¢„è§ˆï¼š\")\n",
    "print(result.get(\"final_report\", \"æ— æŠ¥å‘Š\")[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ä»Šæ—¥å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… æ ¸å¿ƒæ¦‚å¿µæŒæ¡\n",
    "\n",
    "1. **LangGraphåŸºç¡€**\n",
    "   - å›¾ç»“æ„ï¼šèŠ‚ç‚¹ï¼ˆä»»åŠ¡ï¼‰+ è¾¹ï¼ˆæµç¨‹ï¼‰\n",
    "   - çŠ¶æ€ç®¡ç†ï¼šåœ¨èŠ‚ç‚¹é—´ä¼ é€’å’Œæ›´æ–°æ•°æ®\n",
    "   - ä¸LangChainçš„åŒºåˆ«å’Œä¼˜åŠ¿\n",
    "\n",
    "2. **æ¡ä»¶åˆ†æ”¯**\n",
    "   - ä½¿ç”¨æ¡ä»¶å‡½æ•°æ§åˆ¶æµç¨‹èµ°å‘\n",
    "   - add_conditional_edgesçš„ä½¿ç”¨æ–¹æ³•\n",
    "   - å¤šè·¯å¾„å·¥ä½œæµçš„è®¾è®¡\n",
    "\n",
    "3. **å¾ªç¯æ§åˆ¶**\n",
    "   - å®ç°è¿­ä»£æ”¹è¿›çš„æ¨¡å¼\n",
    "   - é¿å…æ— é™å¾ªç¯çš„ç­–ç•¥\n",
    "   - çŠ¶æ€ç´¯ç§¯ï¼ˆAnnotatedç±»å‹ï¼‰\n",
    "\n",
    "4. **äººæœºåä½œ**\n",
    "   - Human-in-the-loopæ¨¡å¼\n",
    "   - ä¸­æ–­å’Œæ¢å¤ï¼ˆcheckpointerï¼‰\n",
    "   - å®¡æ‰¹æµç¨‹çš„å®ç°\n",
    "\n",
    "### ğŸ¯ å…³é”®æŠ€å·§\n",
    "\n",
    "1. **çŠ¶æ€è®¾è®¡**ï¼šæ¸…æ™°å®šä¹‰éœ€è¦åœ¨èŠ‚ç‚¹é—´å…±äº«çš„æ•°æ®\n",
    "2. **èŠ‚ç‚¹èŒè´£**ï¼šæ¯ä¸ªèŠ‚ç‚¹åªåšä¸€ä»¶äº‹ï¼Œä¿æŒç®€å•\n",
    "3. **é”™è¯¯å¤„ç†**ï¼šåœ¨æ¡ä»¶å‡½æ•°ä¸­å¤„ç†å¼‚å¸¸æƒ…å†µ\n",
    "4. **å¯è§†åŒ–è°ƒè¯•**ï¼šä½¿ç”¨draw_mermaid()æŸ¥çœ‹å·¥ä½œæµç»“æ„\n",
    "\n",
    "### ğŸ’¡ å®è·µå»ºè®®\n",
    "\n",
    "1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆå®ç°çº¿æ€§æµç¨‹ï¼Œå†æ·»åŠ åˆ†æ”¯å’Œå¾ªç¯\n",
    "2. **æµ‹è¯•æ¯ä¸ªèŠ‚ç‚¹**ï¼šç¡®ä¿å•ä¸ªèŠ‚ç‚¹æ­£ç¡®åå†ç»„è£…\n",
    "3. **æ—¥å¿—å¾ˆé‡è¦**ï¼šåœ¨èŠ‚ç‚¹ä¸­æ·»åŠ printå¸®åŠ©è°ƒè¯•\n",
    "4. **çŠ¶æ€è¦å®Œæ•´**ï¼šé¿å…åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨å¤–éƒ¨å˜é‡\n",
    "\n",
    "### ğŸ“ æ˜æ—¥é¢„å‘Šï¼šç¬¬5å¤© - å¤šAgentåä½œç³»ç»Ÿ\n",
    "\n",
    "- ç†è§£å¤šAgentæ¶æ„æ¨¡å¼\n",
    "- ä½¿ç”¨CrewAIæ„å»ºAgentå›¢é˜Ÿ\n",
    "- Agenté—´çš„é€šä¿¡å’Œåè°ƒ\n",
    "- ä»»åŠ¡åˆ†é…å’Œç»“æœæ•´åˆ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}