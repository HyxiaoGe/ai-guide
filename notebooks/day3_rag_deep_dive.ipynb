{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3天：RAG（检索增强生成）核心技术\n",
    "\n",
    "## 今日学习目标\n",
    "1. 深入理解RAG的工作原理和架构\n",
    "2. 掌握向量数据库的使用（Chroma、FAISS）\n",
    "3. 实现文档嵌入和相似度检索\n",
    "4. 构建完整的RAG问答系统\n",
    "5. 学习检索质量优化技巧\n",
    "6. 实现混合搜索（语义+关键词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# 环境设置\nimport os\nimport shutil  # 添加用于目录操作\nfrom dotenv import load_dotenv\nimport numpy as np\nfrom typing import List, Dict, Any\n\nload_dotenv()\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n\nprint(\"✅ 环境配置完成\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RAG架构深度解析\n",
    "\n",
    "### RAG解决的核心问题\n",
    "1. **知识时效性**：LLM训练数据有截止时间，无法获取最新信息\n",
    "2. **领域专业性**：通用模型在特定领域知识上可能不够深入\n",
    "3. **幻觉问题**：模型可能生成看似合理但实际错误的信息\n",
    "4. **可解释性**：难以追溯回答的信息来源\n",
    "\n",
    "### RAG工作流程\n",
    "```\n",
    "用户查询 → 查询向量化 → 向量相似度搜索 → 检索相关文档 → 构建增强提示词 → LLM生成回答\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 核心导入\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# 初始化核心组件\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "print(\"🤖 LLM和嵌入模型初始化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建知识库：文档处理和嵌入\n",
    "\n",
    "### 2.1 准备示例文档数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建AI技术知识库文档\n",
    "ai_knowledge_base = [\n",
    "    {\n",
    "        \"title\": \"人工智能基础\",\n",
    "        \"content\": \"\"\"\n",
    "        人工智能（Artificial Intelligence, AI）是计算机科学的一个分支，旨在创建能够执行通常需要人类智能的任务的机器和软件。\n",
    "        AI的主要目标包括学习、推理、感知、语言理解和问题解决。现代AI主要基于机器学习技术，特别是深度学习。\n",
    "        AI应用广泛，包括自然语言处理、计算机视觉、语音识别、推荐系统、自动驾驶等领域。\n",
    "        \"\"\",\n",
    "        \"category\": \"基础概念\",\n",
    "        \"keywords\": [\"人工智能\", \"AI\", \"机器学习\", \"深度学习\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"机器学习算法\",\n",
    "        \"content\": \"\"\"\n",
    "        机器学习是人工智能的核心技术，主要分为三类：监督学习、无监督学习和强化学习。\n",
    "        监督学习包括分类和回归任务，常用算法有线性回归、逻辑回归、决策树、随机森林、支持向量机（SVM）等。\n",
    "        无监督学习主要用于发现数据中的隐藏模式，包括聚类、降维和关联规则挖掘。\n",
    "        强化学习通过与环境交互学习最优策略，在游戏AI、机器人控制等领域应用广泛。\n",
    "        \"\"\",\n",
    "        \"category\": \"技术详解\",\n",
    "        \"keywords\": [\"机器学习\", \"监督学习\", \"无监督学习\", \"强化学习\", \"算法\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"深度学习与神经网络\",\n",
    "        \"content\": \"\"\"\n",
    "        深度学习是机器学习的一个子集，使用多层神经网络来建模和理解复杂的数据模式。\n",
    "        卷积神经网络（CNN）主要用于图像处理，在计算机视觉任务中表现卓越。\n",
    "        循环神经网络（RNN）和长短期记忆网络（LSTM）适合处理序列数据，如文本和时间序列。\n",
    "        Transformer架构彻底改变了自然语言处理领域，GPT、BERT等大型语言模型都基于此架构。\n",
    "        \"\"\",\n",
    "        \"category\": \"技术详解\",\n",
    "        \"keywords\": [\"深度学习\", \"神经网络\", \"CNN\", \"RNN\", \"LSTM\", \"Transformer\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"自然语言处理技术\",\n",
    "        \"content\": \"\"\"\n",
    "        自然语言处理（NLP）是AI的重要分支，致力于让计算机理解和生成人类语言。\n",
    "        传统NLP技术包括分词、词性标注、命名实体识别、句法分析等基础任务。\n",
    "        现代NLP主要基于深度学习，特别是Transformer架构的预训练语言模型。\n",
    "        主要应用包括机器翻译、文本摘要、情感分析、问答系统、对话系统等。\n",
    "        BERT、GPT、T5等预训练模型在各种NLP任务上都取得了突破性进展。\n",
    "        \"\"\",\n",
    "        \"category\": \"应用领域\",\n",
    "        \"keywords\": [\"自然语言处理\", \"NLP\", \"BERT\", \"GPT\", \"机器翻译\", \"文本摘要\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"计算机视觉基础\",\n",
    "        \"content\": \"\"\"\n",
    "        计算机视觉是AI的另一个重要领域，目标是让机器能够理解和解释视觉信息。\n",
    "        基础任务包括图像分类、目标检测、图像分割、人脸识别等。\n",
    "        卷积神经网络（CNN）是计算机视觉的核心技术，经典架构包括LeNet、AlexNet、VGG、ResNet等。\n",
    "        现代计算机视觉还涉及生成对抗网络（GAN）、扩散模型等生成技术。\n",
    "        应用领域包括自动驾驶、医学影像分析、工业质检、增强现实等。\n",
    "        \"\"\",\n",
    "        \"category\": \"应用领域\",\n",
    "        \"keywords\": [\"计算机视觉\", \"CNN\", \"图像分类\", \"目标检测\", \"GAN\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"大语言模型发展\",\n",
    "        \"content\": \"\"\"\n",
    "        大语言模型（Large Language Models, LLMs）是近年来AI领域的重大突破。\n",
    "        从2018年的BERT到2019年的GPT-2，再到2020年的GPT-3，模型规模不断增长。\n",
    "        ChatGPT和GPT-4的发布标志着AI进入了新的时代，展现了强大的对话和推理能力。\n",
    "        这些模型基于Transformer架构，通过大规模预训练获得了广泛的知识和能力。\n",
    "        LLMs的应用包括文本生成、代码编写、翻译、摘要、问答等多个方面。\n",
    "        \"\"\",\n",
    "        \"category\": \"前沿技术\",\n",
    "        \"keywords\": [\"大语言模型\", \"LLM\", \"GPT\", \"ChatGPT\", \"BERT\", \"Transformer\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"AI伦理与安全\",\n",
    "        \"content\": \"\"\"\n",
    "        随着AI技术的快速发展，AI伦理和安全问题日益重要。\n",
    "        主要关注点包括算法偏见、隐私保护、透明度、可解释性、责任归属等。\n",
    "        AI安全涉及对抗性攻击、模型鲁棒性、数据安全等技术问题。\n",
    "        需要建立完善的AI治理框架，确保AI技术的负责任发展和应用。\n",
    "        国际组织和各国政府正在制定相关的AI伦理准则和法律法规。\n",
    "        \"\"\",\n",
    "        \"category\": \"伦理安全\",\n",
    "        \"keywords\": [\"AI伦理\", \"AI安全\", \"算法偏见\", \"隐私保护\", \"可解释性\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# 转换为Document对象\n",
    "documents = []\n",
    "for item in ai_knowledge_base:\n",
    "    doc = Document(\n",
    "        page_content=item[\"content\"].strip(),\n",
    "        metadata={\n",
    "            \"title\": item[\"title\"],\n",
    "            \"category\": item[\"category\"],\n",
    "            \"keywords\": item[\"keywords\"]\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"📚 创建了 {len(documents)} 篇AI技术文档\")\n",
    "print(f\"📄 示例文档: {documents[0].metadata['title']}\")\n",
    "print(f\"📝 内容预览: {documents[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 文档分块处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # 每块最大字符数\n",
    "    chunk_overlap=50,  # 重叠字符数，保持上下文连贯性\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \";\", \",\", \" \", \"\"]  # 分割优先级\n",
    ")\n",
    "\n",
    "# 分割文档\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"📊 文档分块统计:\")\n",
    "print(f\"原始文档数: {len(documents)}\")\n",
    "print(f\"分割后块数: {len(splits)}\")\n",
    "print(f\"平均每文档块数: {len(splits) / len(documents):.1f}\")\n",
    "\n",
    "# 显示分块示例\n",
    "print(f\"\\n📝 分块示例:\")\n",
    "for i, chunk in enumerate(splits[:3]):\n",
    "    print(f\"\\n块 {i+1} (长度: {len(chunk.page_content)} 字符):\")\n",
    "    print(f\"来源: {chunk.metadata['title']}\")\n",
    "    print(f\"内容: {chunk.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 向量数据库实践\n",
    "\n",
    "### 3.1 Chroma向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# 创建Chroma向量数据库\nprint(\"🗄️ 创建Chroma向量数据库...\")\n\n# 设置持久化目录\npersist_directory = \"./chroma_db\"\n\n# 清除可能存在的数据库（确保干净的开始）\nimport shutil\nif os.path.exists(persist_directory):\n    shutil.rmtree(persist_directory)\n    print(f\"🗑️ 清理旧的数据库目录: {persist_directory}\")\n\n# 创建目录（如果不存在）\nos.makedirs(persist_directory, exist_ok=True)\nprint(f\"📁 创建数据库目录: {persist_directory}\")\n\n# 创建向量存储\nchroma_vectorstore = Chroma.from_documents(\n    documents=splits,\n    embedding=embeddings,\n    persist_directory=persist_directory,\n    collection_name=\"ai_knowledge\"\n)\n\nprint(f\"✅ Chroma数据库创建完成\")\nprint(f\"📊 存储了 {chroma_vectorstore._collection.count()} 个向量\")\n\n# 测试相似度搜索\ntest_query = \"什么是深度学习？\"\nsimilar_docs = chroma_vectorstore.similarity_search(test_query, k=3)\n\nprint(f\"\\n🔍 相似度搜索测试\")\nprint(f\"查询: {test_query}\")\nprint(f\"找到 {len(similar_docs)} 个相似文档:\")\n\nfor i, doc in enumerate(similar_docs, 1):\n    print(f\"\\n{i}. {doc.metadata['title']}\")\n    print(f\"   内容: {doc.page_content[:120]}...\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 FAISS向量数据库（高性能）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建FAISS向量数据库\n",
    "print(\"\\n⚡ 创建FAISS向量数据库...\")\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"✅ FAISS数据库创建完成\")\n",
    "\n",
    "# 保存到本地\n",
    "faiss_vectorstore.save_local(\"./faiss_index\")\n",
    "print(f\"💾 FAISS索引已保存到本地\")\n",
    "\n",
    "# 测试FAISS搜索性能\n",
    "import time\n",
    "\n",
    "# 对比搜索速度\n",
    "queries = [\n",
    "    \"机器学习有哪些类型？\",\n",
    "    \"CNN在计算机视觉中的应用\",\n",
    "    \"GPT模型的发展历程\"\n",
    "]\n",
    "\n",
    "print(f\"\\n⏱️ 搜索性能对比:\")\n",
    "\n",
    "for query in queries:\n",
    "    # Chroma搜索\n",
    "    start_time = time.time()\n",
    "    chroma_results = chroma_vectorstore.similarity_search(query, k=2)\n",
    "    chroma_time = time.time() - start_time\n",
    "    \n",
    "    # FAISS搜索\n",
    "    start_time = time.time()\n",
    "    faiss_results = faiss_vectorstore.similarity_search(query, k=2)\n",
    "    faiss_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n查询: {query}\")\n",
    "    print(f\"Chroma: {chroma_time:.4f}s | FAISS: {faiss_time:.4f}s\")\n",
    "    print(f\"FAISS加速比: {chroma_time/faiss_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 相似度搜索与评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 带评分的相似度搜索\n",
    "def analyze_similarity_search(vectorstore, query: str, k: int = 5):\n",
    "    \"\"\"分析相似度搜索结果\"\"\"\n",
    "    print(f\"\\n🎯 详细相似度分析\")\n",
    "    print(f\"查询: {query}\")\n",
    "    print(f\"检索数量: {k}\")\n",
    "    \n",
    "    # 获取带评分的结果\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    print(f\"\\n📋 搜索结果:\")\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. 相似度得分: {score:.4f}\")\n",
    "        print(f\"   标题: {doc.metadata['title']}\")\n",
    "        print(f\"   分类: {doc.metadata['category']}\")\n",
    "        print(f\"   内容: {doc.page_content[:150]}...\")\n",
    "        \n",
    "        # 分析相关性\n",
    "        if score < 0.3:\n",
    "            relevance = \"🟢 高度相关\"\n",
    "        elif score < 0.5:\n",
    "            relevance = \"🟡 中度相关\"\n",
    "        else:\n",
    "            relevance = \"🔴 低度相关\"\n",
    "        print(f\"   相关性: {relevance}\")\n",
    "\n",
    "# 测试不同类型的查询\n",
    "test_queries = [\n",
    "    \"深度学习和神经网络的关系\",  # 精确匹配\n",
    "    \"AI在医疗领域的应用\",        # 间接相关\n",
    "    \"如何学习编程？\"            # 不相关\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    analyze_similarity_search(chroma_vectorstore, query, k=3)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 构建完整的RAG系统\n",
    "\n",
    "### 4.1 基础RAG实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建RAG提示词模板\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一个专业的AI技术专家，请基于以下参考文档回答用户的问题。\n",
    "\n",
    "参考文档:\n",
    "{context}\n",
    "\n",
    "用户问题: {question}\n",
    "\n",
    "请遵循以下要求：\n",
    "1. 基于参考文档提供准确的回答\n",
    "2. 如果参考文档中没有相关信息，请明确说明\n",
    "3. 可以适当扩展解释，但要确保准确性\n",
    "4. 用清晰、专业的语言回答\n",
    "\n",
    "回答:\n",
    "\"\"\")\n",
    "\n",
    "# 创建检索器\n",
    "retriever = chroma_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # 检索top-3最相似的文档\n",
    ")\n",
    "\n",
    "# 格式化文档函数\n",
    "def format_docs(docs):\n",
    "    \"\"\"格式化检索到的文档\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"文档{i}: {doc.metadata['title']}\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# 创建RAG链\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"🔗 RAG链创建完成\")\n",
    "\n",
    "# 测试RAG系统\n",
    "test_questions = [\n",
    "    \"什么是深度学习？它与机器学习有什么关系？\",\n",
    "    \"Transformer架构在NLP中有什么重要作用？\",\n",
    "    \"计算机视觉的主要应用领域有哪些？\",\n",
    "    \"大语言模型的发展历程是怎样的？\"\n",
    "]\n",
    "\n",
    "print(\"\\n🤖 RAG系统测试:\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- 问题 {i} ---\")\n",
    "    print(f\"❓ {question}\")\n",
    "    \n",
    "    # 获取答案\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"\\n🤖 RAG回答:\")\n",
    "    print(answer)\n",
    "    \n",
    "    # 显示检索到的文档\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "    print(f\"\\n📚 使用的参考文档:\")\n",
    "    for j, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"{j}. {doc.metadata['title']} ({doc.metadata['category']})\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 高级RAG：带引用和置信度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# 定义结构化输出模型\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"RAG回答结构化输出\"\"\"\n",
    "    answer: str = Field(description=\"基于参考文档的答案\")\n",
    "    confidence: float = Field(description=\"答案置信度 (0-1)\", ge=0, le=1)\n",
    "    sources: List[str] = Field(description=\"参考文档标题列表\")\n",
    "    has_sufficient_info: bool = Field(description=\"参考文档是否包含足够信息\")\n",
    "    additional_notes: str = Field(description=\"补充说明或限制条件\")\n",
    "\n",
    "# 创建高级RAG提示词\n",
    "advanced_rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一个AI技术专家，请基于参考文档回答问题，并提供结构化输出。\n",
    "\n",
    "参考文档:\n",
    "{context}\n",
    "\n",
    "用户问题: {question}\n",
    "\n",
    "请分析参考文档的相关性，并评估你能提供准确答案的置信度。\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\")\n",
    "\n",
    "# 创建解析器\n",
    "rag_parser = PydanticOutputParser(pydantic_object=RAGResponse)\n",
    "\n",
    "# 创建高级RAG链\n",
    "advanced_rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"format_instructions\": lambda _: rag_parser.get_format_instructions()\n",
    "    }\n",
    "    | advanced_rag_prompt\n",
    "    | llm\n",
    "    | rag_parser\n",
    ")\n",
    "\n",
    "print(\"\\n🚀 高级RAG系统测试:\")\n",
    "\n",
    "advanced_questions = [\n",
    "    \"CNN和RNN在深度学习中的区别是什么？\",\n",
    "    \"AI伦理方面有哪些主要关注点？\",\n",
    "    \"量子计算对AI发展有什么影响？\"  # 知识库中可能没有的信息\n",
    "]\n",
    "\n",
    "for i, question in enumerate(advanced_questions, 1):\n",
    "    print(f\"\\n--- 高级分析 {i} ---\")\n",
    "    print(f\"❓ {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = advanced_rag_chain.invoke(question)\n",
    "        \n",
    "        print(f\"\\n📊 分析结果:\")\n",
    "        print(f\"置信度: {response.confidence:.2f}\")\n",
    "        print(f\"信息充分性: {'✅ 充分' if response.has_sufficient_info else '❌ 不充分'}\")\n",
    "        print(f\"参考来源: {', '.join(response.sources)}\")\n",
    "        \n",
    "        print(f\"\\n🤖 回答:\")\n",
    "        print(response.answer)\n",
    "        \n",
    "        if response.additional_notes:\n",
    "            print(f\"\\n📝 补充说明:\")\n",
    "            print(response.additional_notes)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"解析错误: {e}\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 检索质量优化\n",
    "\n",
    "### 5.1 混合搜索（语义搜索 + 关键词搜索）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建BM25检索器（关键词搜索）\n",
    "print(\"🔍 创建混合搜索系统...\")\n",
    "\n",
    "# 从文档创建BM25检索器\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 创建语义搜索检索器\n",
    "semantic_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# 创建集成检索器（混合搜索）\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, semantic_retriever],\n",
    "    weights=[0.3, 0.7]  # BM25权重30%，语义搜索权重70%\n",
    ")\n",
    "\n",
    "print(\"✅ 混合搜索系统创建完成\")\n",
    "\n",
    "# 对比不同检索方法\n",
    "def compare_retrieval_methods(query: str):\n",
    "    \"\"\"对比不同检索方法的效果\"\"\"\n",
    "    print(f\"\\n🔍 检索方法对比\")\n",
    "    print(f\"查询: {query}\")\n",
    "    \n",
    "    # BM25检索\n",
    "    bm25_docs = bm25_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\n📋 BM25检索结果:\")\n",
    "    for i, doc in enumerate(bm25_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    # 语义检索\n",
    "    semantic_docs = semantic_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\n🎯 语义检索结果:\")\n",
    "    for i, doc in enumerate(semantic_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    # 混合检索\n",
    "    ensemble_docs = ensemble_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\n🚀 混合检索结果:\")\n",
    "    for i, doc in enumerate(ensemble_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    return {\n",
    "        \"bm25\": bm25_docs,\n",
    "        \"semantic\": semantic_docs,\n",
    "        \"ensemble\": ensemble_docs\n",
    "    }\n",
    "\n",
    "# 测试不同类型的查询\n",
    "test_cases = [\n",
    "    \"深度学习 神经网络 CNN\",  # 关键词密集\n",
    "    \"如何理解人工智能的发展趋势？\",  # 语义理解\n",
    "    \"机器学习算法有哪些分类？\"  # 混合查询\n",
    "]\n",
    "\n",
    "for query in test_cases:\n",
    "    results = compare_retrieval_methods(query)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# 创建使用混合搜索的RAG系统\n",
    "hybrid_rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 混合RAG系统测试:\")\n",
    "test_question = \"计算机视觉中的CNN技术有什么优势？\"\n",
    "\n",
    "hybrid_answer = hybrid_rag_chain.invoke(test_question)\n",
    "print(f\"问题: {test_question}\")\n",
    "print(f\"\\n混合RAG回答:\\n{hybrid_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 查询重写和扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 查询重写和扩展\n",
    "query_rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "你是一个查询优化专家。给定一个用户查询，请生成3个不同的重写版本，以提高检索效果。\n",
    "\n",
    "原始查询: {query}\n",
    "\n",
    "请生成：\n",
    "1. 更具体的查询（添加相关术语）\n",
    "2. 更广泛的查询（使用同义词）\n",
    "3. 结构化的查询（分解为子问题）\n",
    "\n",
    "输出格式：\n",
    "1. [具体查询]\n",
    "2. [广泛查询] \n",
    "3. [结构化查询]\n",
    "\"\"\")\n",
    "\n",
    "query_rewriter = query_rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "def enhanced_retrieval(original_query: str, k: int = 5):\n",
    "    \"\"\"增强检索：使用查询重写\"\"\"\n",
    "    print(f\"🔍 增强检索分析\")\n",
    "    print(f\"原始查询: {original_query}\")\n",
    "    \n",
    "    # 生成重写查询\n",
    "    rewritten_queries = query_rewriter.invoke({\"query\": original_query})\n",
    "    print(f\"\\n📝 重写查询:\\n{rewritten_queries}\")\n",
    "    \n",
    "    # 解析重写的查询\n",
    "    lines = rewritten_queries.strip().split('\\n')\n",
    "    queries = [original_query]\n",
    "    for line in lines:\n",
    "        if line.strip() and not line.startswith('输出格式'):\n",
    "            # 移除编号前缀\n",
    "            clean_query = line.split('.', 1)[-1].strip()\n",
    "            if clean_query and clean_query not in queries:\n",
    "                queries.append(clean_query)\n",
    "    \n",
    "    # 对每个查询进行检索\n",
    "    all_docs = []\n",
    "    doc_scores = {}\n",
    "    \n",
    "    for i, query in enumerate(queries[:4]):  # 限制查询数量\n",
    "        print(f\"\\n检索查询 {i+1}: {query}\")\n",
    "        docs = ensemble_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        for doc in docs:\n",
    "            doc_id = doc.metadata['title']\n",
    "            if doc_id in doc_scores:\n",
    "                doc_scores[doc_id] += 1  # 增加权重\n",
    "            else:\n",
    "                doc_scores[doc_id] = 1\n",
    "                all_docs.append(doc)\n",
    "    \n",
    "    # 根据得分排序\n",
    "    sorted_docs = sorted(all_docs, key=lambda x: doc_scores[x.metadata['title']], reverse=True)\n",
    "    \n",
    "    print(f\"\\n📊 综合检索结果 (Top {k}):\")\n",
    "    for i, doc in enumerate(sorted_docs[:k], 1):\n",
    "        score = doc_scores[doc.metadata['title']]\n",
    "        print(f\"{i}. {doc.metadata['title']} (得分: {score})\")\n",
    "    \n",
    "    return sorted_docs[:k]\n",
    "\n",
    "# 测试增强检索\n",
    "test_query = \"AI安全\"\n",
    "enhanced_docs = enhanced_retrieval(test_query, k=3)\n",
    "\n",
    "# 使用增强检索的结果生成答案\n",
    "enhanced_context = format_docs(enhanced_docs)\n",
    "enhanced_answer = rag_chain.invoke(test_query)\n",
    "\n",
    "print(f\"\\n🤖 增强RAG回答:\")\n",
    "print(enhanced_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAG系统评估\n",
    "\n",
    "### 6.1 检索质量评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# RAG系统评估\n",
    "def evaluate_rag_system():\n",
    "    \"\"\"评估RAG系统的性能\"\"\"\n",
    "    \n",
    "    # 测试用例：问题和期望相关的文档类别\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"question\": \"什么是卷积神经网络？\",\n",
    "            \"expected_categories\": [\"技术详解\", \"应用领域\"],\n",
    "            \"expected_keywords\": [\"CNN\", \"深度学习\", \"计算机视觉\"]\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"大语言模型有哪些发展里程碑？\",\n",
    "            \"expected_categories\": [\"前沿技术\"],\n",
    "            \"expected_keywords\": [\"GPT\", \"BERT\", \"LLM\"]\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"AI伦理包括哪些问题？\",\n",
    "            \"expected_categories\": [\"伦理安全\"],\n",
    "            \"expected_keywords\": [\"AI伦理\", \"算法偏见\", \"隐私保护\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"📊 RAG系统评估\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_score = 0\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        question = test_case[\"question\"]\n",
    "        expected_categories = test_case[\"expected_categories\"]\n",
    "        expected_keywords = test_case[\"expected_keywords\"]\n",
    "        \n",
    "        print(f\"\\n--- 测试用例 {i} ---\")\n",
    "        print(f\"问题: {question}\")\n",
    "        \n",
    "        # 检索文档\n",
    "        retrieved_docs = ensemble_retriever.get_relevant_documents(question)\n",
    "        \n",
    "        # 评估类别匹配\n",
    "        retrieved_categories = [doc.metadata['category'] for doc in retrieved_docs]\n",
    "        category_score = len(set(retrieved_categories) & set(expected_categories)) / len(expected_categories)\n",
    "        \n",
    "        # 评估关键词匹配\n",
    "        retrieved_text = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "        keyword_matches = sum(1 for keyword in expected_keywords if keyword.lower() in retrieved_text.lower())\n",
    "        keyword_score = keyword_matches / len(expected_keywords)\n",
    "        \n",
    "        # 计算综合得分\n",
    "        overall_score = (category_score + keyword_score) / 2\n",
    "        total_score += overall_score\n",
    "        \n",
    "        print(f\"检索到的文档:\")\n",
    "        for j, doc in enumerate(retrieved_docs[:3], 1):\n",
    "            print(f\"  {j}. {doc.metadata['title']} ({doc.metadata['category']})\")\n",
    "        \n",
    "        print(f\"\\n评估结果:\")\n",
    "        print(f\"  类别匹配度: {category_score:.2f}\")\n",
    "        print(f\"  关键词匹配度: {keyword_score:.2f}\")\n",
    "        print(f\"  综合得分: {overall_score:.2f}\")\n",
    "    \n",
    "    average_score = total_score / len(test_cases)\n",
    "    print(f\"\\n🎯 整体评估结果:\")\n",
    "    print(f\"平均得分: {average_score:.2f}\")\n",
    "    print(f\"系统性能: {'🟢 优秀' if average_score >= 0.8 else '🟡 良好' if average_score >= 0.6 else '🔴 需要改进'}\")\n",
    "\n",
    "# 运行评估\n",
    "evaluate_rag_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 今日学习总结\n",
    "\n",
    "### ✅ 核心技能掌握\n",
    "\n",
    "1. **RAG架构理解**\n",
    "   - RAG解决的核心问题\n",
    "   - 完整工作流程\n",
    "   - 组件间的协作机制\n",
    "\n",
    "2. **向量数据库实践**\n",
    "   - Chroma：易用性和持久化\n",
    "   - FAISS：高性能和可扩展性\n",
    "   - 相似度搜索和评分机制\n",
    "\n",
    "3. **文档处理技术**\n",
    "   - 智能文本分块策略\n",
    "   - 重叠机制保持上下文\n",
    "   - 元数据管理和利用\n",
    "\n",
    "4. **检索质量优化**\n",
    "   - 混合搜索（语义+关键词）\n",
    "   - 查询重写和扩展\n",
    "   - 多层检索策略\n",
    "\n",
    "5. **RAG系统构建**\n",
    "   - 基础RAG实现\n",
    "   - 结构化输出和置信度\n",
    "   - 系统性能评估\n",
    "\n",
    "### 🎯 关键收获\n",
    "\n",
    "- **RAG不仅是检索+生成**：需要考虑检索质量、上下文构建、答案生成的整体优化\n",
    "- **向量数据库选择很重要**：根据数据规模和性能需求选择合适的解决方案\n",
    "- **检索策略影响最终效果**：混合搜索通常比单一方法效果更好\n",
    "- **评估体系很关键**：需要建立完善的评估指标来优化系统\n",
    "\n",
    "### 📝 明日预告：第4天 - LangGraph工作流编排\n",
    "\n",
    "- StateGraph状态管理\n",
    "- 复杂工作流设计\n",
    "- 条件分支和循环\n",
    "- Human-in-the-loop模式\n",
    "- 错误处理和重试机制"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}