{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬3å¤©ï¼šRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ ¸å¿ƒæŠ€æœ¯\n",
    "\n",
    "## ä»Šæ—¥å­¦ä¹ ç›®æ ‡\n",
    "1. æ·±å…¥ç†è§£RAGçš„å·¥ä½œåŸç†å’Œæ¶æ„\n",
    "2. æŒæ¡å‘é‡æ•°æ®åº“çš„ä½¿ç”¨ï¼ˆChromaã€FAISSï¼‰\n",
    "3. å®ç°æ–‡æ¡£åµŒå…¥å’Œç›¸ä¼¼åº¦æ£€ç´¢\n",
    "4. æ„å»ºå®Œæ•´çš„RAGé—®ç­”ç³»ç»Ÿ\n",
    "5. å­¦ä¹ æ£€ç´¢è´¨é‡ä¼˜åŒ–æŠ€å·§\n",
    "6. å®ç°æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# ç¯å¢ƒè®¾ç½®\nimport os\nimport shutil  # æ·»åŠ ç”¨äºç›®å½•æ“ä½œ\nfrom dotenv import load_dotenv\nimport numpy as np\nfrom typing import List, Dict, Any\n\nload_dotenv()\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n\nprint(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆ\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RAGæ¶æ„æ·±åº¦è§£æ\n",
    "\n",
    "### RAGè§£å†³çš„æ ¸å¿ƒé—®é¢˜\n",
    "1. **çŸ¥è¯†æ—¶æ•ˆæ€§**ï¼šLLMè®­ç»ƒæ•°æ®æœ‰æˆªæ­¢æ—¶é—´ï¼Œæ— æ³•è·å–æœ€æ–°ä¿¡æ¯\n",
    "2. **é¢†åŸŸä¸“ä¸šæ€§**ï¼šé€šç”¨æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçŸ¥è¯†ä¸Šå¯èƒ½ä¸å¤Ÿæ·±å…¥\n",
    "3. **å¹»è§‰é—®é¢˜**ï¼šæ¨¡å‹å¯èƒ½ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…é”™è¯¯çš„ä¿¡æ¯\n",
    "4. **å¯è§£é‡Šæ€§**ï¼šéš¾ä»¥è¿½æº¯å›ç­”çš„ä¿¡æ¯æ¥æº\n",
    "\n",
    "### RAGå·¥ä½œæµç¨‹\n",
    "```\n",
    "ç”¨æˆ·æŸ¥è¯¢ â†’ æŸ¥è¯¢å‘é‡åŒ– â†’ å‘é‡ç›¸ä¼¼åº¦æœç´¢ â†’ æ£€ç´¢ç›¸å…³æ–‡æ¡£ â†’ æ„å»ºå¢å¼ºæç¤ºè¯ â†’ LLMç”Ÿæˆå›ç­”\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æ ¸å¿ƒå¯¼å…¥\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "print(\"ğŸ¤– LLMå’ŒåµŒå…¥æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. åˆ›å»ºçŸ¥è¯†åº“ï¼šæ–‡æ¡£å¤„ç†å’ŒåµŒå…¥\n",
    "\n",
    "### 2.1 å‡†å¤‡ç¤ºä¾‹æ–‡æ¡£æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºAIæŠ€æœ¯çŸ¥è¯†åº“æ–‡æ¡£\n",
    "ai_knowledge_base = [\n",
    "    {\n",
    "        \"title\": \"äººå·¥æ™ºèƒ½åŸºç¡€\",\n",
    "        \"content\": \"\"\"\n",
    "        äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨å’Œè½¯ä»¶ã€‚\n",
    "        AIçš„ä¸»è¦ç›®æ ‡åŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€æ„ŸçŸ¥ã€è¯­è¨€ç†è§£å’Œé—®é¢˜è§£å†³ã€‚ç°ä»£AIä¸»è¦åŸºäºæœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯æ·±åº¦å­¦ä¹ ã€‚\n",
    "        AIåº”ç”¨å¹¿æ³›ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³è¯†åˆ«ã€æ¨èç³»ç»Ÿã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"åŸºç¡€æ¦‚å¿µ\",\n",
    "        \"keywords\": [\"äººå·¥æ™ºèƒ½\", \"AI\", \"æœºå™¨å­¦ä¹ \", \"æ·±åº¦å­¦ä¹ \"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"æœºå™¨å­¦ä¹ ç®—æ³•\",\n",
    "        \"content\": \"\"\"\n",
    "        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œä¸»è¦åˆ†ä¸ºä¸‰ç±»ï¼šç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ã€‚\n",
    "        ç›‘ç£å­¦ä¹ åŒ…æ‹¬åˆ†ç±»å’Œå›å½’ä»»åŠ¡ï¼Œå¸¸ç”¨ç®—æ³•æœ‰çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰ç­‰ã€‚\n",
    "        æ— ç›‘ç£å­¦ä¹ ä¸»è¦ç”¨äºå‘ç°æ•°æ®ä¸­çš„éšè—æ¨¡å¼ï¼ŒåŒ…æ‹¬èšç±»ã€é™ç»´å’Œå…³è”è§„åˆ™æŒ–æ˜ã€‚\n",
    "        å¼ºåŒ–å­¦ä¹ é€šè¿‡ä¸ç¯å¢ƒäº¤äº’å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œåœ¨æ¸¸æˆAIã€æœºå™¨äººæ§åˆ¶ç­‰é¢†åŸŸåº”ç”¨å¹¿æ³›ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"æŠ€æœ¯è¯¦è§£\",\n",
    "        \"keywords\": [\"æœºå™¨å­¦ä¹ \", \"ç›‘ç£å­¦ä¹ \", \"æ— ç›‘ç£å­¦ä¹ \", \"å¼ºåŒ–å­¦ä¹ \", \"ç®—æ³•\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"æ·±åº¦å­¦ä¹ ä¸ç¥ç»ç½‘ç»œ\",\n",
    "        \"content\": \"\"\"\n",
    "        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡å’Œç†è§£å¤æ‚çš„æ•°æ®æ¨¡å¼ã€‚\n",
    "        å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ä¸»è¦ç”¨äºå›¾åƒå¤„ç†ï¼Œåœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šã€‚\n",
    "        å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰é€‚åˆå¤„ç†åºåˆ—æ•°æ®ï¼Œå¦‚æ–‡æœ¬å’Œæ—¶é—´åºåˆ—ã€‚\n",
    "        Transformeræ¶æ„å½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼ŒGPTã€BERTç­‰å¤§å‹è¯­è¨€æ¨¡å‹éƒ½åŸºäºæ­¤æ¶æ„ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"æŠ€æœ¯è¯¦è§£\",\n",
    "        \"keywords\": [\"æ·±åº¦å­¦ä¹ \", \"ç¥ç»ç½‘ç»œ\", \"CNN\", \"RNN\", \"LSTM\", \"Transformer\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯\",\n",
    "        \"content\": \"\"\"\n",
    "        è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯AIçš„é‡è¦åˆ†æ”¯ï¼Œè‡´åŠ›äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚\n",
    "        ä¼ ç»ŸNLPæŠ€æœ¯åŒ…æ‹¬åˆ†è¯ã€è¯æ€§æ ‡æ³¨ã€å‘½åå®ä½“è¯†åˆ«ã€å¥æ³•åˆ†æç­‰åŸºç¡€ä»»åŠ¡ã€‚\n",
    "        ç°ä»£NLPä¸»è¦åŸºäºæ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯Transformeræ¶æ„çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚\n",
    "        ä¸»è¦åº”ç”¨åŒ…æ‹¬æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿç­‰ã€‚\n",
    "        BERTã€GPTã€T5ç­‰é¢„è®­ç»ƒæ¨¡å‹åœ¨å„ç§NLPä»»åŠ¡ä¸Šéƒ½å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"åº”ç”¨é¢†åŸŸ\",\n",
    "        \"keywords\": [\"è‡ªç„¶è¯­è¨€å¤„ç†\", \"NLP\", \"BERT\", \"GPT\", \"æœºå™¨ç¿»è¯‘\", \"æ–‡æœ¬æ‘˜è¦\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"è®¡ç®—æœºè§†è§‰åŸºç¡€\",\n",
    "        \"content\": \"\"\"\n",
    "        è®¡ç®—æœºè§†è§‰æ˜¯AIçš„å¦ä¸€ä¸ªé‡è¦é¢†åŸŸï¼Œç›®æ ‡æ˜¯è®©æœºå™¨èƒ½å¤Ÿç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚\n",
    "        åŸºç¡€ä»»åŠ¡åŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ã€äººè„¸è¯†åˆ«ç­‰ã€‚\n",
    "        å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ˜¯è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œç»å…¸æ¶æ„åŒ…æ‹¬LeNetã€AlexNetã€VGGã€ResNetç­‰ã€‚\n",
    "        ç°ä»£è®¡ç®—æœºè§†è§‰è¿˜æ¶‰åŠç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€æ‰©æ•£æ¨¡å‹ç­‰ç”ŸæˆæŠ€æœ¯ã€‚\n",
    "        åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€åŒ»å­¦å½±åƒåˆ†æã€å·¥ä¸šè´¨æ£€ã€å¢å¼ºç°å®ç­‰ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"åº”ç”¨é¢†åŸŸ\",\n",
    "        \"keywords\": [\"è®¡ç®—æœºè§†è§‰\", \"CNN\", \"å›¾åƒåˆ†ç±»\", \"ç›®æ ‡æ£€æµ‹\", \"GAN\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"å¤§è¯­è¨€æ¨¡å‹å‘å±•\",\n",
    "        \"content\": \"\"\"\n",
    "        å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰æ˜¯è¿‘å¹´æ¥AIé¢†åŸŸçš„é‡å¤§çªç ´ã€‚\n",
    "        ä»2018å¹´çš„BERTåˆ°2019å¹´çš„GPT-2ï¼Œå†åˆ°2020å¹´çš„GPT-3ï¼Œæ¨¡å‹è§„æ¨¡ä¸æ–­å¢é•¿ã€‚\n",
    "        ChatGPTå’ŒGPT-4çš„å‘å¸ƒæ ‡å¿—ç€AIè¿›å…¥äº†æ–°çš„æ—¶ä»£ï¼Œå±•ç°äº†å¼ºå¤§çš„å¯¹è¯å’Œæ¨ç†èƒ½åŠ›ã€‚\n",
    "        è¿™äº›æ¨¡å‹åŸºäºTransformeræ¶æ„ï¼Œé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒè·å¾—äº†å¹¿æ³›çš„çŸ¥è¯†å’Œèƒ½åŠ›ã€‚\n",
    "        LLMsçš„åº”ç”¨åŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€ä»£ç ç¼–å†™ã€ç¿»è¯‘ã€æ‘˜è¦ã€é—®ç­”ç­‰å¤šä¸ªæ–¹é¢ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"å‰æ²¿æŠ€æœ¯\",\n",
    "        \"keywords\": [\"å¤§è¯­è¨€æ¨¡å‹\", \"LLM\", \"GPT\", \"ChatGPT\", \"BERT\", \"Transformer\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"AIä¼¦ç†ä¸å®‰å…¨\",\n",
    "        \"content\": \"\"\"\n",
    "        éšç€AIæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒAIä¼¦ç†å’Œå®‰å…¨é—®é¢˜æ—¥ç›Šé‡è¦ã€‚\n",
    "        ä¸»è¦å…³æ³¨ç‚¹åŒ…æ‹¬ç®—æ³•åè§ã€éšç§ä¿æŠ¤ã€é€æ˜åº¦ã€å¯è§£é‡Šæ€§ã€è´£ä»»å½’å±ç­‰ã€‚\n",
    "        AIå®‰å…¨æ¶‰åŠå¯¹æŠ—æ€§æ”»å‡»ã€æ¨¡å‹é²æ£’æ€§ã€æ•°æ®å®‰å…¨ç­‰æŠ€æœ¯é—®é¢˜ã€‚\n",
    "        éœ€è¦å»ºç«‹å®Œå–„çš„AIæ²»ç†æ¡†æ¶ï¼Œç¡®ä¿AIæŠ€æœ¯çš„è´Ÿè´£ä»»å‘å±•å’Œåº”ç”¨ã€‚\n",
    "        å›½é™…ç»„ç»‡å’Œå„å›½æ”¿åºœæ­£åœ¨åˆ¶å®šç›¸å…³çš„AIä¼¦ç†å‡†åˆ™å’Œæ³•å¾‹æ³•è§„ã€‚\n",
    "        \"\"\",\n",
    "        \"category\": \"ä¼¦ç†å®‰å…¨\",\n",
    "        \"keywords\": [\"AIä¼¦ç†\", \"AIå®‰å…¨\", \"ç®—æ³•åè§\", \"éšç§ä¿æŠ¤\", \"å¯è§£é‡Šæ€§\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# è½¬æ¢ä¸ºDocumentå¯¹è±¡\n",
    "documents = []\n",
    "for item in ai_knowledge_base:\n",
    "    doc = Document(\n",
    "        page_content=item[\"content\"].strip(),\n",
    "        metadata={\n",
    "            \"title\": item[\"title\"],\n",
    "            \"category\": item[\"category\"],\n",
    "            \"keywords\": item[\"keywords\"]\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "print(f\"ğŸ“š åˆ›å»ºäº† {len(documents)} ç¯‡AIæŠ€æœ¯æ–‡æ¡£\")\n",
    "print(f\"ğŸ“„ ç¤ºä¾‹æ–‡æ¡£: {documents[0].metadata['title']}\")\n",
    "print(f\"ğŸ“ å†…å®¹é¢„è§ˆ: {documents[0].page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æ–‡æ¡£åˆ†å—å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,  # æ¯å—æœ€å¤§å­—ç¬¦æ•°\n",
    "    chunk_overlap=50,  # é‡å å­—ç¬¦æ•°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \";\", \",\", \" \", \"\"]  # åˆ†å‰²ä¼˜å…ˆçº§\n",
    ")\n",
    "\n",
    "# åˆ†å‰²æ–‡æ¡£\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"ğŸ“Š æ–‡æ¡£åˆ†å—ç»Ÿè®¡:\")\n",
    "print(f\"åŸå§‹æ–‡æ¡£æ•°: {len(documents)}\")\n",
    "print(f\"åˆ†å‰²åå—æ•°: {len(splits)}\")\n",
    "print(f\"å¹³å‡æ¯æ–‡æ¡£å—æ•°: {len(splits) / len(documents):.1f}\")\n",
    "\n",
    "# æ˜¾ç¤ºåˆ†å—ç¤ºä¾‹\n",
    "print(f\"\\nğŸ“ åˆ†å—ç¤ºä¾‹:\")\n",
    "for i, chunk in enumerate(splits[:3]):\n",
    "    print(f\"\\nå— {i+1} (é•¿åº¦: {len(chunk.page_content)} å­—ç¬¦):\")\n",
    "    print(f\"æ¥æº: {chunk.metadata['title']}\")\n",
    "    print(f\"å†…å®¹: {chunk.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å‘é‡æ•°æ®åº“å®è·µ\n",
    "\n",
    "### 3.1 Chromaå‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# åˆ›å»ºChromaå‘é‡æ•°æ®åº“\nprint(\"ğŸ—„ï¸ åˆ›å»ºChromaå‘é‡æ•°æ®åº“...\")\n\n# è®¾ç½®æŒä¹…åŒ–ç›®å½•\npersist_directory = \"./chroma_db\"\n\n# æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ•°æ®åº“ï¼ˆç¡®ä¿å¹²å‡€çš„å¼€å§‹ï¼‰\nimport shutil\nif os.path.exists(persist_directory):\n    shutil.rmtree(persist_directory)\n    print(f\"ğŸ—‘ï¸ æ¸…ç†æ—§çš„æ•°æ®åº“ç›®å½•: {persist_directory}\")\n\n# åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\nos.makedirs(persist_directory, exist_ok=True)\nprint(f\"ğŸ“ åˆ›å»ºæ•°æ®åº“ç›®å½•: {persist_directory}\")\n\n# åˆ›å»ºå‘é‡å­˜å‚¨\nchroma_vectorstore = Chroma.from_documents(\n    documents=splits,\n    embedding=embeddings,\n    persist_directory=persist_directory,\n    collection_name=\"ai_knowledge\"\n)\n\nprint(f\"âœ… Chromaæ•°æ®åº“åˆ›å»ºå®Œæˆ\")\nprint(f\"ğŸ“Š å­˜å‚¨äº† {chroma_vectorstore._collection.count()} ä¸ªå‘é‡\")\n\n# æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢\ntest_query = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\"\nsimilar_docs = chroma_vectorstore.similarity_search(test_query, k=3)\n\nprint(f\"\\nğŸ” ç›¸ä¼¼åº¦æœç´¢æµ‹è¯•\")\nprint(f\"æŸ¥è¯¢: {test_query}\")\nprint(f\"æ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸ä¼¼æ–‡æ¡£:\")\n\nfor i, doc in enumerate(similar_docs, 1):\n    print(f\"\\n{i}. {doc.metadata['title']}\")\n    print(f\"   å†…å®¹: {doc.page_content[:120]}...\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 FAISSå‘é‡æ•°æ®åº“ï¼ˆé«˜æ€§èƒ½ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºFAISSå‘é‡æ•°æ®åº“\n",
    "print(\"\\nâš¡ åˆ›å»ºFAISSå‘é‡æ•°æ®åº“...\")\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"âœ… FAISSæ•°æ®åº“åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "# ä¿å­˜åˆ°æœ¬åœ°\n",
    "faiss_vectorstore.save_local(\"./faiss_index\")\n",
    "print(f\"ğŸ’¾ FAISSç´¢å¼•å·²ä¿å­˜åˆ°æœ¬åœ°\")\n",
    "\n",
    "# æµ‹è¯•FAISSæœç´¢æ€§èƒ½\n",
    "import time\n",
    "\n",
    "# å¯¹æ¯”æœç´¢é€Ÿåº¦\n",
    "queries = [\n",
    "    \"æœºå™¨å­¦ä¹ æœ‰å“ªäº›ç±»å‹ï¼Ÿ\",\n",
    "    \"CNNåœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨\",\n",
    "    \"GPTæ¨¡å‹çš„å‘å±•å†ç¨‹\"\n",
    "]\n",
    "\n",
    "print(f\"\\nâ±ï¸ æœç´¢æ€§èƒ½å¯¹æ¯”:\")\n",
    "\n",
    "for query in queries:\n",
    "    # Chromaæœç´¢\n",
    "    start_time = time.time()\n",
    "    chroma_results = chroma_vectorstore.similarity_search(query, k=2)\n",
    "    chroma_time = time.time() - start_time\n",
    "    \n",
    "    # FAISSæœç´¢\n",
    "    start_time = time.time()\n",
    "    faiss_results = faiss_vectorstore.similarity_search(query, k=2)\n",
    "    faiss_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\næŸ¥è¯¢: {query}\")\n",
    "    print(f\"Chroma: {chroma_time:.4f}s | FAISS: {faiss_time:.4f}s\")\n",
    "    print(f\"FAISSåŠ é€Ÿæ¯”: {chroma_time/faiss_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ç›¸ä¼¼åº¦æœç´¢ä¸è¯„åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# å¸¦è¯„åˆ†çš„ç›¸ä¼¼åº¦æœç´¢\n",
    "def analyze_similarity_search(vectorstore, query: str, k: int = 5):\n",
    "    \"\"\"åˆ†æç›¸ä¼¼åº¦æœç´¢ç»“æœ\"\"\"\n",
    "    print(f\"\\nğŸ¯ è¯¦ç»†ç›¸ä¼¼åº¦åˆ†æ\")\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"æ£€ç´¢æ•°é‡: {k}\")\n",
    "    \n",
    "    # è·å–å¸¦è¯„åˆ†çš„ç»“æœ\n",
    "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ æœç´¢ç»“æœ:\")\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. ç›¸ä¼¼åº¦å¾—åˆ†: {score:.4f}\")\n",
    "        print(f\"   æ ‡é¢˜: {doc.metadata['title']}\")\n",
    "        print(f\"   åˆ†ç±»: {doc.metadata['category']}\")\n",
    "        print(f\"   å†…å®¹: {doc.page_content[:150]}...\")\n",
    "        \n",
    "        # åˆ†æç›¸å…³æ€§\n",
    "        if score < 0.3:\n",
    "            relevance = \"ğŸŸ¢ é«˜åº¦ç›¸å…³\"\n",
    "        elif score < 0.5:\n",
    "            relevance = \"ğŸŸ¡ ä¸­åº¦ç›¸å…³\"\n",
    "        else:\n",
    "            relevance = \"ğŸ”´ ä½åº¦ç›¸å…³\"\n",
    "        print(f\"   ç›¸å…³æ€§: {relevance}\")\n",
    "\n",
    "# æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢\n",
    "test_queries = [\n",
    "    \"æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„å…³ç³»\",  # ç²¾ç¡®åŒ¹é…\n",
    "    \"AIåœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨\",        # é—´æ¥ç›¸å…³\n",
    "    \"å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ\"            # ä¸ç›¸å…³\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    analyze_similarity_search(chroma_vectorstore, query, k=3)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ\n",
    "\n",
    "### 4.1 åŸºç¡€RAGå®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºRAGæç¤ºè¯æ¨¡æ¿\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæŠ€æœ¯ä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "\n",
    "å‚è€ƒæ–‡æ¡£:\n",
    "{context}\n",
    "\n",
    "ç”¨æˆ·é—®é¢˜: {question}\n",
    "\n",
    "è¯·éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š\n",
    "1. åŸºäºå‚è€ƒæ–‡æ¡£æä¾›å‡†ç¡®çš„å›ç­”\n",
    "2. å¦‚æœå‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜\n",
    "3. å¯ä»¥é€‚å½“æ‰©å±•è§£é‡Šï¼Œä½†è¦ç¡®ä¿å‡†ç¡®æ€§\n",
    "4. ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”\n",
    "\n",
    "å›ç­”:\n",
    "\"\"\")\n",
    "\n",
    "# åˆ›å»ºæ£€ç´¢å™¨\n",
    "retriever = chroma_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # æ£€ç´¢top-3æœ€ç›¸ä¼¼çš„æ–‡æ¡£\n",
    ")\n",
    "\n",
    "# æ ¼å¼åŒ–æ–‡æ¡£å‡½æ•°\n",
    "def format_docs(docs):\n",
    "    \"\"\"æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£\"\"\"\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        formatted.append(f\"æ–‡æ¡£{i}: {doc.metadata['title']}\\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# åˆ›å»ºRAGé“¾\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"ğŸ”— RAGé“¾åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "# æµ‹è¯•RAGç³»ç»Ÿ\n",
    "test_questions = [\n",
    "    \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿå®ƒä¸æœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ\",\n",
    "    \"Transformeræ¶æ„åœ¨NLPä¸­æœ‰ä»€ä¹ˆé‡è¦ä½œç”¨ï¼Ÿ\",\n",
    "    \"è®¡ç®—æœºè§†è§‰çš„ä¸»è¦åº”ç”¨é¢†åŸŸæœ‰å“ªäº›ï¼Ÿ\",\n",
    "    \"å¤§è¯­è¨€æ¨¡å‹çš„å‘å±•å†ç¨‹æ˜¯æ€æ ·çš„ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ¤– RAGç³»ç»Ÿæµ‹è¯•:\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- é—®é¢˜ {i} ---\")\n",
    "    print(f\"â“ {question}\")\n",
    "    \n",
    "    # è·å–ç­”æ¡ˆ\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"\\nğŸ¤– RAGå›ç­”:\")\n",
    "    print(answer)\n",
    "    \n",
    "    # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "    print(f\"\\nğŸ“š ä½¿ç”¨çš„å‚è€ƒæ–‡æ¡£:\")\n",
    "    for j, doc in enumerate(retrieved_docs, 1):\n",
    "        print(f\"{j}. {doc.metadata['title']} ({doc.metadata['category']})\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 é«˜çº§RAGï¼šå¸¦å¼•ç”¨å’Œç½®ä¿¡åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"RAGå›ç­”ç»“æ„åŒ–è¾“å‡º\"\"\"\n",
    "    answer: str = Field(description=\"åŸºäºå‚è€ƒæ–‡æ¡£çš„ç­”æ¡ˆ\")\n",
    "    confidence: float = Field(description=\"ç­”æ¡ˆç½®ä¿¡åº¦ (0-1)\", ge=0, le=1)\n",
    "    sources: List[str] = Field(description=\"å‚è€ƒæ–‡æ¡£æ ‡é¢˜åˆ—è¡¨\")\n",
    "    has_sufficient_info: bool = Field(description=\"å‚è€ƒæ–‡æ¡£æ˜¯å¦åŒ…å«è¶³å¤Ÿä¿¡æ¯\")\n",
    "    additional_notes: str = Field(description=\"è¡¥å……è¯´æ˜æˆ–é™åˆ¶æ¡ä»¶\")\n",
    "\n",
    "# åˆ›å»ºé«˜çº§RAGæç¤ºè¯\n",
    "advanced_rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªAIæŠ€æœ¯ä¸“å®¶ï¼Œè¯·åŸºäºå‚è€ƒæ–‡æ¡£å›ç­”é—®é¢˜ï¼Œå¹¶æä¾›ç»“æ„åŒ–è¾“å‡ºã€‚\n",
    "\n",
    "å‚è€ƒæ–‡æ¡£:\n",
    "{context}\n",
    "\n",
    "ç”¨æˆ·é—®é¢˜: {question}\n",
    "\n",
    "è¯·åˆ†æå‚è€ƒæ–‡æ¡£çš„ç›¸å…³æ€§ï¼Œå¹¶è¯„ä¼°ä½ èƒ½æä¾›å‡†ç¡®ç­”æ¡ˆçš„ç½®ä¿¡åº¦ã€‚\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\")\n",
    "\n",
    "# åˆ›å»ºè§£æå™¨\n",
    "rag_parser = PydanticOutputParser(pydantic_object=RAGResponse)\n",
    "\n",
    "# åˆ›å»ºé«˜çº§RAGé“¾\n",
    "advanced_rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"format_instructions\": lambda _: rag_parser.get_format_instructions()\n",
    "    }\n",
    "    | advanced_rag_prompt\n",
    "    | llm\n",
    "    | rag_parser\n",
    ")\n",
    "\n",
    "print(\"\\nğŸš€ é«˜çº§RAGç³»ç»Ÿæµ‹è¯•:\")\n",
    "\n",
    "advanced_questions = [\n",
    "    \"CNNå’ŒRNNåœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"AIä¼¦ç†æ–¹é¢æœ‰å“ªäº›ä¸»è¦å…³æ³¨ç‚¹ï¼Ÿ\",\n",
    "    \"é‡å­è®¡ç®—å¯¹AIå‘å±•æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\"  # çŸ¥è¯†åº“ä¸­å¯èƒ½æ²¡æœ‰çš„ä¿¡æ¯\n",
    "]\n",
    "\n",
    "for i, question in enumerate(advanced_questions, 1):\n",
    "    print(f\"\\n--- é«˜çº§åˆ†æ {i} ---\")\n",
    "    print(f\"â“ {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = advanced_rag_chain.invoke(question)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š åˆ†æç»“æœ:\")\n",
    "        print(f\"ç½®ä¿¡åº¦: {response.confidence:.2f}\")\n",
    "        print(f\"ä¿¡æ¯å……åˆ†æ€§: {'âœ… å……åˆ†' if response.has_sufficient_info else 'âŒ ä¸å……åˆ†'}\")\n",
    "        print(f\"å‚è€ƒæ¥æº: {', '.join(response.sources)}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¤– å›ç­”:\")\n",
    "        print(response.answer)\n",
    "        \n",
    "        if response.additional_notes:\n",
    "            print(f\"\\nğŸ“ è¡¥å……è¯´æ˜:\")\n",
    "            print(response.additional_notes)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"è§£æé”™è¯¯: {e}\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ£€ç´¢è´¨é‡ä¼˜åŒ–\n",
    "\n",
    "### 5.1 æ··åˆæœç´¢ï¼ˆè¯­ä¹‰æœç´¢ + å…³é”®è¯æœç´¢ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åˆ›å»ºBM25æ£€ç´¢å™¨ï¼ˆå…³é”®è¯æœç´¢ï¼‰\n",
    "print(\"ğŸ” åˆ›å»ºæ··åˆæœç´¢ç³»ç»Ÿ...\")\n",
    "\n",
    "# ä»æ–‡æ¡£åˆ›å»ºBM25æ£€ç´¢å™¨\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# åˆ›å»ºè¯­ä¹‰æœç´¢æ£€ç´¢å™¨\n",
    "semantic_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# åˆ›å»ºé›†æˆæ£€ç´¢å™¨ï¼ˆæ··åˆæœç´¢ï¼‰\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, semantic_retriever],\n",
    "    weights=[0.3, 0.7]  # BM25æƒé‡30%ï¼Œè¯­ä¹‰æœç´¢æƒé‡70%\n",
    ")\n",
    "\n",
    "print(\"âœ… æ··åˆæœç´¢ç³»ç»Ÿåˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "# å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³•\n",
    "def compare_retrieval_methods(query: str):\n",
    "    \"\"\"å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³•çš„æ•ˆæœ\"\"\"\n",
    "    print(f\"\\nğŸ” æ£€ç´¢æ–¹æ³•å¯¹æ¯”\")\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    \n",
    "    # BM25æ£€ç´¢\n",
    "    bm25_docs = bm25_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\nğŸ“‹ BM25æ£€ç´¢ç»“æœ:\")\n",
    "    for i, doc in enumerate(bm25_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    # è¯­ä¹‰æ£€ç´¢\n",
    "    semantic_docs = semantic_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\nğŸ¯ è¯­ä¹‰æ£€ç´¢ç»“æœ:\")\n",
    "    for i, doc in enumerate(semantic_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    # æ··åˆæ£€ç´¢\n",
    "    ensemble_docs = ensemble_retriever.get_relevant_documents(query)\n",
    "    print(f\"\\nğŸš€ æ··åˆæ£€ç´¢ç»“æœ:\")\n",
    "    for i, doc in enumerate(ensemble_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata['title']}\")\n",
    "    \n",
    "    return {\n",
    "        \"bm25\": bm25_docs,\n",
    "        \"semantic\": semantic_docs,\n",
    "        \"ensemble\": ensemble_docs\n",
    "    }\n",
    "\n",
    "# æµ‹è¯•ä¸åŒç±»å‹çš„æŸ¥è¯¢\n",
    "test_cases = [\n",
    "    \"æ·±åº¦å­¦ä¹  ç¥ç»ç½‘ç»œ CNN\",  # å…³é”®è¯å¯†é›†\n",
    "    \"å¦‚ä½•ç†è§£äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿ï¼Ÿ\",  # è¯­ä¹‰ç†è§£\n",
    "    \"æœºå™¨å­¦ä¹ ç®—æ³•æœ‰å“ªäº›åˆ†ç±»ï¼Ÿ\"  # æ··åˆæŸ¥è¯¢\n",
    "]\n",
    "\n",
    "for query in test_cases:\n",
    "    results = compare_retrieval_methods(query)\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# åˆ›å»ºä½¿ç”¨æ··åˆæœç´¢çš„RAGç³»ç»Ÿ\n",
    "hybrid_rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯ æ··åˆRAGç³»ç»Ÿæµ‹è¯•:\")\n",
    "test_question = \"è®¡ç®—æœºè§†è§‰ä¸­çš„CNNæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ\"\n",
    "\n",
    "hybrid_answer = hybrid_rag_chain.invoke(test_question)\n",
    "print(f\"é—®é¢˜: {test_question}\")\n",
    "print(f\"\\næ··åˆRAGå›ç­”:\\n{hybrid_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 æŸ¥è¯¢é‡å†™å’Œæ‰©å±•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# æŸ¥è¯¢é‡å†™å’Œæ‰©å±•\n",
    "query_rewrite_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªç”¨æˆ·æŸ¥è¯¢ï¼Œè¯·ç”Ÿæˆ3ä¸ªä¸åŒçš„é‡å†™ç‰ˆæœ¬ï¼Œä»¥æé«˜æ£€ç´¢æ•ˆæœã€‚\n",
    "\n",
    "åŸå§‹æŸ¥è¯¢: {query}\n",
    "\n",
    "è¯·ç”Ÿæˆï¼š\n",
    "1. æ›´å…·ä½“çš„æŸ¥è¯¢ï¼ˆæ·»åŠ ç›¸å…³æœ¯è¯­ï¼‰\n",
    "2. æ›´å¹¿æ³›çš„æŸ¥è¯¢ï¼ˆä½¿ç”¨åŒä¹‰è¯ï¼‰\n",
    "3. ç»“æ„åŒ–çš„æŸ¥è¯¢ï¼ˆåˆ†è§£ä¸ºå­é—®é¢˜ï¼‰\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "1. [å…·ä½“æŸ¥è¯¢]\n",
    "2. [å¹¿æ³›æŸ¥è¯¢] \n",
    "3. [ç»“æ„åŒ–æŸ¥è¯¢]\n",
    "\"\"\")\n",
    "\n",
    "query_rewriter = query_rewrite_prompt | llm | StrOutputParser()\n",
    "\n",
    "def enhanced_retrieval(original_query: str, k: int = 5):\n",
    "    \"\"\"å¢å¼ºæ£€ç´¢ï¼šä½¿ç”¨æŸ¥è¯¢é‡å†™\"\"\"\n",
    "    print(f\"ğŸ” å¢å¼ºæ£€ç´¢åˆ†æ\")\n",
    "    print(f\"åŸå§‹æŸ¥è¯¢: {original_query}\")\n",
    "    \n",
    "    # ç”Ÿæˆé‡å†™æŸ¥è¯¢\n",
    "    rewritten_queries = query_rewriter.invoke({\"query\": original_query})\n",
    "    print(f\"\\nğŸ“ é‡å†™æŸ¥è¯¢:\\n{rewritten_queries}\")\n",
    "    \n",
    "    # è§£æé‡å†™çš„æŸ¥è¯¢\n",
    "    lines = rewritten_queries.strip().split('\\n')\n",
    "    queries = [original_query]\n",
    "    for line in lines:\n",
    "        if line.strip() and not line.startswith('è¾“å‡ºæ ¼å¼'):\n",
    "            # ç§»é™¤ç¼–å·å‰ç¼€\n",
    "            clean_query = line.split('.', 1)[-1].strip()\n",
    "            if clean_query and clean_query not in queries:\n",
    "                queries.append(clean_query)\n",
    "    \n",
    "    # å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæ£€ç´¢\n",
    "    all_docs = []\n",
    "    doc_scores = {}\n",
    "    \n",
    "    for i, query in enumerate(queries[:4]):  # é™åˆ¶æŸ¥è¯¢æ•°é‡\n",
    "        print(f\"\\næ£€ç´¢æŸ¥è¯¢ {i+1}: {query}\")\n",
    "        docs = ensemble_retriever.get_relevant_documents(query)\n",
    "        \n",
    "        for doc in docs:\n",
    "            doc_id = doc.metadata['title']\n",
    "            if doc_id in doc_scores:\n",
    "                doc_scores[doc_id] += 1  # å¢åŠ æƒé‡\n",
    "            else:\n",
    "                doc_scores[doc_id] = 1\n",
    "                all_docs.append(doc)\n",
    "    \n",
    "    # æ ¹æ®å¾—åˆ†æ’åº\n",
    "    sorted_docs = sorted(all_docs, key=lambda x: doc_scores[x.metadata['title']], reverse=True)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ç»¼åˆæ£€ç´¢ç»“æœ (Top {k}):\")\n",
    "    for i, doc in enumerate(sorted_docs[:k], 1):\n",
    "        score = doc_scores[doc.metadata['title']]\n",
    "        print(f\"{i}. {doc.metadata['title']} (å¾—åˆ†: {score})\")\n",
    "    \n",
    "    return sorted_docs[:k]\n",
    "\n",
    "# æµ‹è¯•å¢å¼ºæ£€ç´¢\n",
    "test_query = \"AIå®‰å…¨\"\n",
    "enhanced_docs = enhanced_retrieval(test_query, k=3)\n",
    "\n",
    "# ä½¿ç”¨å¢å¼ºæ£€ç´¢çš„ç»“æœç”Ÿæˆç­”æ¡ˆ\n",
    "enhanced_context = format_docs(enhanced_docs)\n",
    "enhanced_answer = rag_chain.invoke(test_query)\n",
    "\n",
    "print(f\"\\nğŸ¤– å¢å¼ºRAGå›ç­”:\")\n",
    "print(enhanced_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RAGç³»ç»Ÿè¯„ä¼°\n",
    "\n",
    "### 6.1 æ£€ç´¢è´¨é‡è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# RAGç³»ç»Ÿè¯„ä¼°\n",
    "def evaluate_rag_system():\n",
    "    \"\"\"è¯„ä¼°RAGç³»ç»Ÿçš„æ€§èƒ½\"\"\"\n",
    "    \n",
    "    # æµ‹è¯•ç”¨ä¾‹ï¼šé—®é¢˜å’ŒæœŸæœ›ç›¸å…³çš„æ–‡æ¡£ç±»åˆ«\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"question\": \"ä»€ä¹ˆæ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼Ÿ\",\n",
    "            \"expected_categories\": [\"æŠ€æœ¯è¯¦è§£\", \"åº”ç”¨é¢†åŸŸ\"],\n",
    "            \"expected_keywords\": [\"CNN\", \"æ·±åº¦å­¦ä¹ \", \"è®¡ç®—æœºè§†è§‰\"]\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"å¤§è¯­è¨€æ¨¡å‹æœ‰å“ªäº›å‘å±•é‡Œç¨‹ç¢‘ï¼Ÿ\",\n",
    "            \"expected_categories\": [\"å‰æ²¿æŠ€æœ¯\"],\n",
    "            \"expected_keywords\": [\"GPT\", \"BERT\", \"LLM\"]\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"AIä¼¦ç†åŒ…æ‹¬å“ªäº›é—®é¢˜ï¼Ÿ\",\n",
    "            \"expected_categories\": [\"ä¼¦ç†å®‰å…¨\"],\n",
    "            \"expected_keywords\": [\"AIä¼¦ç†\", \"ç®—æ³•åè§\", \"éšç§ä¿æŠ¤\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ“Š RAGç³»ç»Ÿè¯„ä¼°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_score = 0\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        question = test_case[\"question\"]\n",
    "        expected_categories = test_case[\"expected_categories\"]\n",
    "        expected_keywords = test_case[\"expected_keywords\"]\n",
    "        \n",
    "        print(f\"\\n--- æµ‹è¯•ç”¨ä¾‹ {i} ---\")\n",
    "        print(f\"é—®é¢˜: {question}\")\n",
    "        \n",
    "        # æ£€ç´¢æ–‡æ¡£\n",
    "        retrieved_docs = ensemble_retriever.get_relevant_documents(question)\n",
    "        \n",
    "        # è¯„ä¼°ç±»åˆ«åŒ¹é…\n",
    "        retrieved_categories = [doc.metadata['category'] for doc in retrieved_docs]\n",
    "        category_score = len(set(retrieved_categories) & set(expected_categories)) / len(expected_categories)\n",
    "        \n",
    "        # è¯„ä¼°å…³é”®è¯åŒ¹é…\n",
    "        retrieved_text = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "        keyword_matches = sum(1 for keyword in expected_keywords if keyword.lower() in retrieved_text.lower())\n",
    "        keyword_score = keyword_matches / len(expected_keywords)\n",
    "        \n",
    "        # è®¡ç®—ç»¼åˆå¾—åˆ†\n",
    "        overall_score = (category_score + keyword_score) / 2\n",
    "        total_score += overall_score\n",
    "        \n",
    "        print(f\"æ£€ç´¢åˆ°çš„æ–‡æ¡£:\")\n",
    "        for j, doc in enumerate(retrieved_docs[:3], 1):\n",
    "            print(f\"  {j}. {doc.metadata['title']} ({doc.metadata['category']})\")\n",
    "        \n",
    "        print(f\"\\nè¯„ä¼°ç»“æœ:\")\n",
    "        print(f\"  ç±»åˆ«åŒ¹é…åº¦: {category_score:.2f}\")\n",
    "        print(f\"  å…³é”®è¯åŒ¹é…åº¦: {keyword_score:.2f}\")\n",
    "        print(f\"  ç»¼åˆå¾—åˆ†: {overall_score:.2f}\")\n",
    "    \n",
    "    average_score = total_score / len(test_cases)\n",
    "    print(f\"\\nğŸ¯ æ•´ä½“è¯„ä¼°ç»“æœ:\")\n",
    "    print(f\"å¹³å‡å¾—åˆ†: {average_score:.2f}\")\n",
    "    print(f\"ç³»ç»Ÿæ€§èƒ½: {'ğŸŸ¢ ä¼˜ç§€' if average_score >= 0.8 else 'ğŸŸ¡ è‰¯å¥½' if average_score >= 0.6 else 'ğŸ”´ éœ€è¦æ”¹è¿›'}\")\n",
    "\n",
    "# è¿è¡Œè¯„ä¼°\n",
    "evaluate_rag_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ä»Šæ—¥å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… æ ¸å¿ƒæŠ€èƒ½æŒæ¡\n",
    "\n",
    "1. **RAGæ¶æ„ç†è§£**\n",
    "   - RAGè§£å†³çš„æ ¸å¿ƒé—®é¢˜\n",
    "   - å®Œæ•´å·¥ä½œæµç¨‹\n",
    "   - ç»„ä»¶é—´çš„åä½œæœºåˆ¶\n",
    "\n",
    "2. **å‘é‡æ•°æ®åº“å®è·µ**\n",
    "   - Chromaï¼šæ˜“ç”¨æ€§å’ŒæŒä¹…åŒ–\n",
    "   - FAISSï¼šé«˜æ€§èƒ½å’Œå¯æ‰©å±•æ€§\n",
    "   - ç›¸ä¼¼åº¦æœç´¢å’Œè¯„åˆ†æœºåˆ¶\n",
    "\n",
    "3. **æ–‡æ¡£å¤„ç†æŠ€æœ¯**\n",
    "   - æ™ºèƒ½æ–‡æœ¬åˆ†å—ç­–ç•¥\n",
    "   - é‡å æœºåˆ¶ä¿æŒä¸Šä¸‹æ–‡\n",
    "   - å…ƒæ•°æ®ç®¡ç†å’Œåˆ©ç”¨\n",
    "\n",
    "4. **æ£€ç´¢è´¨é‡ä¼˜åŒ–**\n",
    "   - æ··åˆæœç´¢ï¼ˆè¯­ä¹‰+å…³é”®è¯ï¼‰\n",
    "   - æŸ¥è¯¢é‡å†™å’Œæ‰©å±•\n",
    "   - å¤šå±‚æ£€ç´¢ç­–ç•¥\n",
    "\n",
    "5. **RAGç³»ç»Ÿæ„å»º**\n",
    "   - åŸºç¡€RAGå®ç°\n",
    "   - ç»“æ„åŒ–è¾“å‡ºå’Œç½®ä¿¡åº¦\n",
    "   - ç³»ç»Ÿæ€§èƒ½è¯„ä¼°\n",
    "\n",
    "### ğŸ¯ å…³é”®æ”¶è·\n",
    "\n",
    "- **RAGä¸ä»…æ˜¯æ£€ç´¢+ç”Ÿæˆ**ï¼šéœ€è¦è€ƒè™‘æ£€ç´¢è´¨é‡ã€ä¸Šä¸‹æ–‡æ„å»ºã€ç­”æ¡ˆç”Ÿæˆçš„æ•´ä½“ä¼˜åŒ–\n",
    "- **å‘é‡æ•°æ®åº“é€‰æ‹©å¾ˆé‡è¦**ï¼šæ ¹æ®æ•°æ®è§„æ¨¡å’Œæ€§èƒ½éœ€æ±‚é€‰æ‹©åˆé€‚çš„è§£å†³æ–¹æ¡ˆ\n",
    "- **æ£€ç´¢ç­–ç•¥å½±å“æœ€ç»ˆæ•ˆæœ**ï¼šæ··åˆæœç´¢é€šå¸¸æ¯”å•ä¸€æ–¹æ³•æ•ˆæœæ›´å¥½\n",
    "- **è¯„ä¼°ä½“ç³»å¾ˆå…³é”®**ï¼šéœ€è¦å»ºç«‹å®Œå–„çš„è¯„ä¼°æŒ‡æ ‡æ¥ä¼˜åŒ–ç³»ç»Ÿ\n",
    "\n",
    "### ğŸ“ æ˜æ—¥é¢„å‘Šï¼šç¬¬4å¤© - LangGraphå·¥ä½œæµç¼–æ’\n",
    "\n",
    "- StateGraphçŠ¶æ€ç®¡ç†\n",
    "- å¤æ‚å·¥ä½œæµè®¾è®¡\n",
    "- æ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯\n",
    "- Human-in-the-loopæ¨¡å¼\n",
    "- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}