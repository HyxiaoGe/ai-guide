{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬2å¤©ï¼šLangChainæ¡†æ¶æ·±å…¥å­¦ä¹ \n",
    "\n",
    "## ä»Šæ—¥å­¦ä¹ ç›®æ ‡\n",
    "1. æŒæ¡LangChainçš„æ ¸å¿ƒæ¶æ„\n",
    "2. æ·±å…¥ç†è§£Prompt Templateså’ŒOutput Parsers\n",
    "3. å®ç°å¤šç§Memoryç³»ç»Ÿ\n",
    "4. å­¦ä¹ Documentå¤„ç†æµç¨‹\n",
    "5. æ„å»ºä¸€ä¸ªå®Œæ•´çš„å¯¹è¯ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¯å¢ƒé…ç½®å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LangChainæ ¸å¿ƒæ¶æ„ç†è§£\n",
    "\n",
    "### LangChainçš„6å¤§æ ¸å¿ƒç»„ä»¶\n",
    "1. **Modelsï¼ˆæ¨¡å‹ï¼‰**ï¼šå„ç§LLMçš„ç»Ÿä¸€æ¥å£\n",
    "2. **Promptsï¼ˆæç¤ºè¯ï¼‰**ï¼šç®¡ç†å’Œä¼˜åŒ–æç¤ºè¯\n",
    "3. **Chainsï¼ˆé“¾ï¼‰**ï¼šç»„åˆå¤šä¸ªç»„ä»¶çš„å·¥ä½œæµ\n",
    "4. **Memoryï¼ˆè®°å¿†ï¼‰**ï¼šç»´æŒå¯¹è¯çŠ¶æ€å’Œå†å²\n",
    "5. **Agentsï¼ˆä»£ç†ï¼‰**ï¼šè®©LLMé€‰æ‹©å’Œæ‰§è¡Œå·¥å…·\n",
    "6. **Callbacksï¼ˆå›è°ƒï¼‰**ï¼šç›‘æ§å’Œè°ƒè¯•æ‰§è¡Œè¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– LLMæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n"
     ]
    }
   ],
   "source": [
    "# æ ¸å¿ƒå¯¼å…¥\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory\n",
    "from langchain.schema import BaseMessage\n",
    "from typing import List\n",
    "\n",
    "# åˆå§‹åŒ–åŸºç¡€æ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– LLMæ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Templatesæ·±å…¥å®è·µ\n",
    "\n",
    "### 2.1 åŸºç¡€Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== åŸºç¡€Prompt Templateæµ‹è¯• ===\n",
      "\n",
      "--- æµ‹è¯• 1 ---\n",
      "è§’è‰²: AIæŠ€æœ¯ä¸“å®¶\n",
      "å›ç­”: Transformeræ˜¯ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹æ¶æ„ï¼Œæœ€æ—©åœ¨2017å¹´è¢«Googleæå‡ºï¼Œä¸“é—¨ç”¨æ¥å¤„ç†åºåˆ—æ•°æ®ï¼Œæ¯”å¦‚è‡ªç„¶è¯­è¨€ï¼ˆæ–‡æœ¬ï¼‰ã€‚å®ƒé©æ–°äº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸï¼Œç°åœ¨å¾ˆå¤šå¼ºå¤§çš„AIæ¨¡å‹ï¼ˆæ¯”å¦‚ChatGPTã€BERTï¼‰éƒ½æ˜¯åŸºäºTransformerçš„ã€‚\n",
      "\n",
      "ç”¨é€šä¿—çš„è¯æ¥è¯´ï¼ŒTransformerå°±åƒæ˜¯ä¸€ä¸ªè¶…çº§â€œç¿»è¯‘å®˜â€ï¼Œèƒ½å¤Ÿç†è§£å’Œè½¬æ¢é•¿çŸ­ä¸ä¸€çš„æ–‡æœ¬ã€è¯­éŸ³ç”šè‡³ä»£ç ã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œå·ç§¯...\n",
      "\n",
      "--- æµ‹è¯• 2 ---\n",
      "è§’è‰²: è¯—äºº\n",
      "å›ç­”: æ˜¥å¤©æ˜¯ä¸€é¦–æ¸©æŸ”çš„è¯—ï¼Œ  \n",
      "åœ¨ç»†é›¨å’Œæ™¨æ›¦ä¸­æ…¢æ…¢å±•å¼€ã€‚  \n",
      "å«©ç»¿çš„èŠ½å°–ï¼Œæ‚„æ‚„æ¢å‡ºæ³¥åœŸï¼Œ  \n",
      "åƒåˆé†’çš„æ¢¦æƒ³ï¼Œå¾®å¾®é¢¤æŠ–ã€‚  \n",
      "æ¡ƒèŠ±ç²‰çº¢ï¼ŒæŸ³çµ®è½»æ‰¬ï¼Œ  \n",
      "é£ï¼Œå¸¦ç€æ³¥åœŸä¸èŠ±é¦™ï¼Œ  \n",
      "å”¤é†’æ²‰ç¡ä¸€å†¬çš„æ²³æµå’Œé¸Ÿé¸£ã€‚  \n",
      "ç”°é‡åœ¨é˜³å…‰ä¸‹æ¸æ¸é“ºå¼€ï¼Œ  \n",
      "å°è‰å·å·åœ°è£…ç‚¹ç€å¤§åœ°çš„è¡£è£³ã€‚  \n",
      "ä¸€åˆ‡éƒ½æ˜¯å´­æ–°çš„ï¼Œæ¸©æŸ”çš„ï¼Œ  \n",
      "ä»¿ä½›æ¯ä¸€å¯¸ç©ºæ°”é‡Œéƒ½è—ç€å¸Œæœ›ï¼Œ  \n",
      "åœ¨è¿™ä¸ªå­£èŠ‚ï¼Œè¿å‘¼å¸éƒ½æ˜¯è¯—è¡Œã€‚...\n"
     ]
    }
   ],
   "source": [
    "# åŸºç¡€æç¤ºè¯æ¨¡æ¿\n",
    "basic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{role}ï¼Œæ“…é•¿{skill}ã€‚è¯·ç”¨{style}çš„é£æ ¼å›ç­”é—®é¢˜ã€‚\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# åˆ›å»ºåŸºç¡€é“¾\n",
    "basic_chain = basic_prompt | llm | StrOutputParser()\n",
    "\n",
    "# æµ‹è¯•ä¸åŒè§’è‰²\n",
    "print(\"=== åŸºç¡€Prompt Templateæµ‹è¯• ===\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"role\": \"AIæŠ€æœ¯ä¸“å®¶\",\n",
    "        \"skill\": \"æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ \",\n",
    "        \"style\": \"é€šä¿—æ˜“æ‡‚\",\n",
    "        \"question\": \"ä»€ä¹ˆæ˜¯Transformeræ¶æ„ï¼Ÿ\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"è¯—äºº\",\n",
    "        \"skill\": \"ç°ä»£è¯—åˆ›ä½œ\",\n",
    "        \"style\": \"ä¼˜ç¾æŠ’æƒ…\",\n",
    "        \"question\": \"æè¿°ä¸€ä¸‹æ˜¥å¤©çš„æ™¯è‰²\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n--- æµ‹è¯• {i} ---\")\n",
    "    response = basic_chain.invoke(case)\n",
    "    print(f\"è§’è‰²: {case['role']}\")\n",
    "    print(f\"å›ç­”: {response[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æ¡ä»¶åŒ–Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ¡ä»¶åŒ–Prompt Templateæµ‹è¯• ===\n",
      "\n",
      "--- BEGINNER ç‰ˆæœ¬ ---\n",
      "å›ç­”: å¥½çš„ï¼Œè®©æˆ‘ä»¬ç”¨æœ€ç®€å•çš„æ–¹å¼æ¥ç†è§£RESTful APIã€‚\n",
      "\n",
      "**1. APIæ˜¯ä»€ä¹ˆï¼Ÿ**  \n",
      "API å°±åƒä¸€ä¸ªé¤å…çš„èœå•ã€‚ä½ ï¼ˆå®¢æˆ·ç«¯ï¼Œæ¯”å¦‚æ‰‹æœºAppæˆ–ç½‘é¡µï¼‰æƒ³ç‚¹èœï¼ˆè·å–æˆ–å‘é€æ•°æ®ï¼‰ï¼Œä½†ä½ ä¸èƒ½ç›´æ¥è¿›å¨æˆ¿ï¼ˆæœåŠ¡å™¨ï¼‰ã€‚ä½ é€šè¿‡èœå•ï¼ˆAPIï¼‰å‘Šè¯‰æœåŠ¡å‘˜ï¼ˆç¨‹åºï¼‰ä½ è¦ä»€ä¹ˆï¼ŒæœåŠ¡å‘˜å¸®ä½ æŠŠèœä»å¨æˆ¿å¸¦å‡ºæ¥ã€‚\n",
      "\n",
      "**2. RESTfulæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**  \n",
      "RESTful å…¶å®æ˜¯ä¸€ç§è®¾è®¡APIçš„æ–¹æ³•å’Œé£æ ¼ã€‚REST ä»£è¡¨â€œè¡¨ç°å±‚çŠ¶æ€è½¬ç§»ï¼ˆRepresentational State Transferï¼‰â€ï¼Œåå­—å¬èµ·æ¥æœ‰ç‚¹å¤æ‚ï¼Œä½†æ„æ€å¾ˆç®€å•ï¼š  \n",
      "- å®ƒç”¨â€œç½‘å€â€ï¼ˆURLï¼‰æ¥æŒ‡ä»£èµ„æºï¼ˆæ¯”å¦‚ç”¨æˆ·ã€å•†å“ã€æ–‡ç« ç­‰ï¼‰ã€‚\n",
      "- å®ƒ...\n",
      "\n",
      "--- INTERMEDIATE ç‰ˆæœ¬ ---\n",
      "å›ç­”: RESTful APIï¼ˆRepresentational State Transferï¼Œè¡¨ç°å±‚çŠ¶æ€è½¬ç§»çš„åº”ç”¨ç¨‹åºæ¥å£ï¼‰æ˜¯ä¸€ç§åŸºäºHTTPåè®®ã€éµå¾ªRESTæ¶æ„é£æ ¼çš„WebæœåŠ¡è®¾è®¡æ–¹å¼ã€‚å®ƒå…è®¸ä¸åŒçš„ç³»ç»Ÿé€šè¿‡æ ‡å‡†çš„HTTPåŠ¨è¯ï¼ˆå¦‚GETã€POSTã€PUTã€DELETEç­‰ï¼‰è¿›è¡Œé€šä¿¡ï¼Œå¸¸è§äºWebå¼€å‘ä¸­å‰åç«¯çš„æ•°æ®äº¤äº’ã€‚\n",
      "\n",
      "### 1. åŸºæœ¬åŸç†\n",
      "\n",
      "RESTå¼ºè°ƒèµ„æº(Resource)çš„æ¦‚å¿µï¼Œæ¯ä¸ªèµ„æºç”±ä¸€ä¸ªURLå”¯ä¸€æ ‡è¯†ã€‚å®¢æˆ·ç«¯é€šè¿‡HTTPæ–¹æ³•å¯¹èµ„æºè¿›è¡Œæ“ä½œï¼š\n",
      "\n",
      "| HTTPæ–¹æ³• | ä½œç”¨             | è¯´æ˜           |\n",
      "|----------|---------------...\n",
      "\n",
      "--- EXPERT ç‰ˆæœ¬ ---\n",
      "å›ç­”: RESTful APIï¼ˆRepresentational State Transfer Application Programming Interfaceï¼‰æ˜¯ä¸€ç§åŸºäºRESTæ¶æ„é£æ ¼è®¾è®¡çš„Web APIã€‚RESTç”±Roy Fieldingåœ¨2000å¹´æå‡ºï¼Œæ˜¯ä¸€ç§è½»é‡çº§ã€æ— çŠ¶æ€ã€ä»¥èµ„æºä¸ºä¸­å¿ƒçš„åˆ†å¸ƒå¼ç³»ç»Ÿæ¶æ„ã€‚RESTful APIå¹¿æ³›ç”¨äºWebæœåŠ¡çš„æ•°æ®äº¤äº’ï¼Œå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€æ˜“ç”¨æ€§å’Œä¸HTTPåè®®çš„é«˜åº¦å¥‘åˆã€‚\n",
      "\n",
      "## æ ¸å¿ƒæ¦‚å¿µ\n",
      "\n",
      "1. **èµ„æºï¼ˆResourceï¼‰**\n",
      "   - ä¸€åˆ‡çš†èµ„æºã€‚èµ„æºé€šå¸¸ç”¨URIï¼ˆç»Ÿä¸€èµ„æºæ ‡è¯†ç¬¦ï¼‰å”¯ä¸€æ ‡è¯†ï¼Œå¦‚`/users/123`ã€‚\n",
      "2. **HTTPæ–¹æ³•ï¼ˆMe...\n"
     ]
    }
   ],
   "source": [
    "# æ¡ä»¶åŒ–æç¤ºè¯ï¼ˆæ ¹æ®ç”¨æˆ·ç±»å‹è°ƒæ•´ï¼‰\n",
    "def create_conditional_prompt(user_type: str) -> ChatPromptTemplate:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·ç±»å‹åˆ›å»ºä¸åŒçš„æç¤ºè¯\"\"\"\n",
    "    \n",
    "    if user_type == \"beginner\":\n",
    "        system_message = \"\"\"\n",
    "        ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„AIå¯¼å¸ˆï¼Œä¸“é—¨ä¸ºåˆå­¦è€…è§£ç­”é—®é¢˜ã€‚\n",
    "        è¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šï¼Œé¿å…ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ã€‚\n",
    "        å¦‚æœå¿…é¡»ä½¿ç”¨æœ¯è¯­ï¼Œè¯·æä¾›ç®€å•çš„è§£é‡Šã€‚\n",
    "        ç”¨ç±»æ¯”å’Œä¾‹å­å¸®åŠ©ç†è§£ã€‚\n",
    "        \"\"\"\n",
    "    elif user_type == \"expert\":\n",
    "        system_message = \"\"\"\n",
    "        ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ä¸“å®¶ï¼Œä¸ºæœ‰ç»éªŒçš„å¼€å‘è€…æä¾›æ·±å…¥åˆ†æã€‚\n",
    "        å¯ä»¥ä½¿ç”¨ä¸“ä¸šæœ¯è¯­å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚\n",
    "        æä¾›ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚\n",
    "        å…³æ³¨æ€§èƒ½ä¼˜åŒ–å’Œæ¶æ„è®¾è®¡ã€‚\n",
    "        \"\"\"\n",
    "    else:  # intermediate\n",
    "        system_message = \"\"\"\n",
    "        ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„æŠ€æœ¯é¡¾é—®ã€‚\n",
    "        æä¾›ä¸­ç­‰æ·±åº¦çš„æŠ€æœ¯è§£é‡Šã€‚\n",
    "        åŒ…å«ä¸€äº›ä»£ç ç¤ºä¾‹å’Œå®è·µå»ºè®®ã€‚\n",
    "        å¹³è¡¡ç†è®ºå’Œå®è·µåº”ç”¨ã€‚\n",
    "        \"\"\"\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message.strip()),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "# æµ‹è¯•æ¡ä»¶åŒ–æç¤ºè¯\n",
    "print(\"=== æ¡ä»¶åŒ–Prompt Templateæµ‹è¯• ===\")\n",
    "question = \"ä»€ä¹ˆæ˜¯RESTful APIï¼Ÿ\"\n",
    "\n",
    "for user_type in [\"beginner\", \"intermediate\", \"expert\"]:\n",
    "    print(f\"\\n--- {user_type.upper()} ç‰ˆæœ¬ ---\")\n",
    "    prompt = create_conditional_prompt(user_type)\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    print(f\"å›ç­”: {response[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Output Parsersï¼šç»“æ„åŒ–è¾“å‡º\n",
    "\n",
    "### 3.1 JSON Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JSON Output Parseræµ‹è¯• ===\n",
      "\n",
      "--- åˆ†æï¼šDockerå®¹å™¨åŒ– ---\n",
      "æ¦‚å¿µ: Dockerå®¹å™¨åŒ–\n",
      "å®šä¹‰: Dockerå®¹å™¨åŒ–æ˜¯ä¸€ç§åˆ©ç”¨Dockerå¹³å°å°†åº”ç”¨åŠå…¶ä¾èµ–æ‰“åŒ…åœ¨ç‹¬ç«‹ã€å¯ç§»æ¤å®¹å™¨ä¸­çš„æŠ€æœ¯ï¼Œå®ç°ç¯å¢ƒä¸€è‡´æ€§å’Œé«˜æ•ˆéƒ¨ç½²ã€‚\n",
      "éš¾åº¦: medium\n",
      "å­¦ä¹ æ—¶é—´: 1-2å‘¨ï¼ˆåŸºç¡€åˆ°å…¥é—¨åº”ç”¨ï¼‰\n",
      "ä¼˜ç‚¹: åº”ç”¨éƒ¨ç½²å’Œè¿ç§»é€Ÿåº¦å¿«, ä¿è¯å¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒä¸€è‡´æ€§, èµ„æºåˆ©ç”¨ç‡é«˜ï¼Œä¾¿äºæ°´å¹³æ‰©å±•, æ˜“äºå¾®æœåŠ¡æ¶æ„å®ç°\n",
      "\n",
      "--- åˆ†æï¼šGraphQL ---\n",
      "æ¦‚å¿µ: GraphQL\n",
      "å®šä¹‰: GraphQLæ˜¯ä¸€ç§ç”¨äºAPIçš„æŸ¥è¯¢è¯­è¨€ä»¥åŠç›¸åº”çš„æœåŠ¡å™¨ç«¯è¿è¡Œæ—¶ï¼Œç”¨äºæ ¹æ®å®¢æˆ·ç«¯éœ€æ±‚è¿”å›æ•°æ®ã€‚\n",
      "éš¾åº¦: medium\n",
      "å­¦ä¹ æ—¶é—´: 1-2å‘¨ï¼ˆç†Ÿæ‚‰åŸºæœ¬æ¦‚å¿µã€è¯­æ³•å’Œå…¸å‹åº”ç”¨ï¼‰\n",
      "ä¼˜ç‚¹: å®¢æˆ·ç«¯å¯ä»¥ç²¾ç¡®è·å–æ‰€éœ€æ•°æ®ï¼Œå‡å°‘å†—ä½™ä¼ è¾“, å•ä¸€ç«¯ç‚¹ç»Ÿä¸€ç®¡ç†å¤šç§èµ„æº, å¼ºç±»å‹ç³»ç»Ÿï¼Œæ˜“äºå‰åç«¯åä½œå’Œæ–‡æ¡£ç”Ÿæˆ, é«˜æ•ˆå®ç°èšåˆæŸ¥è¯¢ï¼Œå‡å°‘å¤šæ¬¡è¯·æ±‚\n"
     ]
    }
   ],
   "source": [
    "# JSONè¾“å‡ºè§£æå™¨\n",
    "json_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯åˆ†æå¸ˆã€‚è¯·åˆ†æç»™å®šçš„æŠ€æœ¯æ¦‚å¿µï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚\n",
    "    \n",
    "    è¿”å›æ ¼å¼ï¼š\n",
    "    {{\n",
    "        \"concept\": \"æŠ€æœ¯æ¦‚å¿µåç§°\",\n",
    "        \"definition\": \"ç®€çŸ­å®šä¹‰\",\n",
    "        \"pros\": [\"ä¼˜ç‚¹1\", \"ä¼˜ç‚¹2\"],\n",
    "        \"cons\": [\"ç¼ºç‚¹1\", \"ç¼ºç‚¹2\"],\n",
    "        \"use_cases\": [\"ä½¿ç”¨åœºæ™¯1\", \"ä½¿ç”¨åœºæ™¯2\"],\n",
    "        \"difficulty\": \"easy/medium/hard\",\n",
    "        \"learning_time\": \"é¢„ä¼°å­¦ä¹ æ—¶é—´\"\n",
    "    }}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"è¯·åˆ†æï¼š{concept}\")\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_chain = json_prompt | llm | json_parser\n",
    "\n",
    "# æµ‹è¯•JSONè§£æ\n",
    "print(\"=== JSON Output Parseræµ‹è¯• ===\")\n",
    "concepts = [\"Dockerå®¹å™¨åŒ–\", \"GraphQL\"]\n",
    "\n",
    "for concept in concepts:\n",
    "    print(f\"\\n--- åˆ†æï¼š{concept} ---\")\n",
    "    try:\n",
    "        result = json_chain.invoke({\"concept\": concept})\n",
    "        print(f\"æ¦‚å¿µ: {result['concept']}\")\n",
    "        print(f\"å®šä¹‰: {result['definition']}\")\n",
    "        print(f\"éš¾åº¦: {result['difficulty']}\")\n",
    "        print(f\"å­¦ä¹ æ—¶é—´: {result['learning_time']}\")\n",
    "        print(f\"ä¼˜ç‚¹: {', '.join(result['pros'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"è§£æé”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pydantic Output Parserï¼ˆç±»å‹å®‰å…¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pydantic Output Parseræµ‹è¯• ===\n",
      "ğŸ“‹ åˆ†æç»“æœç±»å‹: <class '__main__.TechAnalysis'>\n",
      "ğŸ¯ æ¦‚å¿µ: å¾®æœåŠ¡æ¶æ„\n",
      "ğŸ“ å®šä¹‰: å¾®æœåŠ¡æ¶æ„æ˜¯ä¸€ç§å°†å•ä¸€åº”ç”¨ç¨‹åºåˆ’åˆ†ä¸ºä¸€ç»„å°çš„ã€ç‹¬ç«‹çš„æœåŠ¡çš„æ–¹æ³•ï¼Œæ¯ä¸ªæœåŠ¡è¿è¡Œåœ¨å…¶ç‹¬ç«‹çš„è¿›ç¨‹ä¸­ï¼Œå¹¶é€šè¿‡è½»é‡çº§é€šä¿¡æœºåˆ¶ï¼ˆé€šå¸¸æ˜¯HTTP APIï¼‰ç›¸äº’åä½œã€‚æ¯ä¸ªå¾®æœåŠ¡å›´ç»•ç€ç‰¹å®šçš„ä¸šåŠ¡èƒ½åŠ›æ„å»ºï¼Œèƒ½å¤Ÿç‹¬ç«‹éƒ¨ç½²å’Œæ‰©å±•ï¼Œé€šå¸¸ç”±å°å‹å›¢é˜Ÿè´Ÿè´£å¼€å‘å’Œç»´æŠ¤ã€‚\n",
      "â­ ä¼˜ç‚¹: ['æ˜“äºæ‰©å±•ï¼šæ¯ä¸ªæœåŠ¡å¯ä»¥ç‹¬ç«‹ä¼¸ç¼©ï¼Œæ»¡è¶³ä¸åŒæ¨¡å—çš„æ€§èƒ½éœ€æ±‚ã€‚', 'æŠ€æœ¯å¤šæ ·æ€§ï¼šä¸åŒå¾®æœåŠ¡å¯ä»¥ä½¿ç”¨æœ€åˆé€‚çš„æŠ€æœ¯æ ˆå’Œç¼–ç¨‹è¯­è¨€å¼€å‘ã€‚', 'é«˜å¯ç”¨æ€§ï¼šå•ä¸ªæœåŠ¡æ•…éšœä¸ä¼šå½±å“æ•´ä¸ªç³»ç»Ÿï¼Œæå‡ç³»ç»Ÿå®¹é”™èƒ½åŠ›ã€‚', 'çµæ´»éƒ¨ç½²ï¼šæ”¯æŒæŒç»­äº¤ä»˜å’ŒæŒç»­éƒ¨ç½²ï¼ŒåŠ å¿«äº§å“è¿­ä»£é€Ÿåº¦ã€‚', 'ä¾¿äºå›¢é˜Ÿåä½œï¼šå°å›¢é˜Ÿå¯ç‹¬ç«‹è´Ÿè´£ç‰¹å®šå¾®æœåŠ¡ï¼Œå‡å°‘æ²Ÿé€šæˆæœ¬ã€‚']\n",
      "âš ï¸ ç¼ºç‚¹: ['ç³»ç»Ÿå¤æ‚æ€§å¢åŠ ï¼šæœåŠ¡æ•°é‡å¢å¤šå¯¼è‡´éƒ¨ç½²ã€è¿ç»´å’Œç›‘æ§éš¾åº¦ä¸Šå‡ã€‚', 'åˆ†å¸ƒå¼ç³»ç»ŸæŒ‘æˆ˜ï¼šéœ€è¦å¤„ç†æœåŠ¡é—´é€šä¿¡ã€æ•°æ®ä¸€è‡´æ€§ã€ç½‘ç»œå»¶è¿Ÿç­‰å¤æ‚é—®é¢˜ã€‚', 'è¿ç»´æˆæœ¬æå‡ï¼šéœ€è¦å¼•å…¥æœåŠ¡æ³¨å†Œã€å‘ç°ã€é…ç½®ç®¡ç†ã€é“¾è·¯è¿½è¸ªç­‰åŸºç¡€è®¾æ–½ã€‚', 'æµ‹è¯•å›°éš¾ï¼šé›†æˆæµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•æ›´åŠ å¤æ‚ï¼Œæ•…éšœå®šä½éš¾åº¦å¢åŠ ã€‚', 'æ•°æ®ç®¡ç†å¤æ‚ï¼šè·¨æœåŠ¡çš„æ•°æ®ä¸€è‡´æ€§å’Œäº‹åŠ¡ç®¡ç†æˆä¸ºéš¾ç‚¹ã€‚']\n",
      "ğŸšï¸ éš¾åº¦: hard\n",
      "â° å­¦ä¹ æ—¶é—´: 1-3ä¸ªæœˆï¼ˆæœ‰åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€ï¼‰\n",
      "ğŸ”— ç›¸å…³æŠ€æœ¯: ['å®¹å™¨åŒ–ï¼ˆDockerã€Kubernetesï¼‰', 'æœåŠ¡ç½‘æ ¼ï¼ˆIstioã€Linkerdï¼‰', 'APIç½‘å…³ï¼ˆKongã€Nginxã€Zuulï¼‰', 'æœåŠ¡æ³¨å†Œä¸å‘ç°ï¼ˆConsulã€Eurekaã€Zookeeperï¼‰', 'æŒç»­é›†æˆ/æŒç»­éƒ¨ç½²ï¼ˆCI/CDï¼‰', 'æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆKafkaã€RabbitMQã€RocketMQï¼‰', 'Spring Cloud', 'gRPC']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# å®šä¹‰Pydanticæ¨¡å‹\n",
    "class TechAnalysis(BaseModel):\n",
    "    \"\"\"æŠ€æœ¯åˆ†æç»“æœæ¨¡å‹\"\"\"\n",
    "    concept: str = Field(description=\"æŠ€æœ¯æ¦‚å¿µåç§°\")\n",
    "    definition: str = Field(description=\"æŠ€æœ¯å®šä¹‰\")\n",
    "    pros: List[str] = Field(description=\"ä¼˜ç‚¹åˆ—è¡¨\")\n",
    "    cons: List[str] = Field(description=\"ç¼ºç‚¹åˆ—è¡¨\")\n",
    "    difficulty: str = Field(description=\"éš¾åº¦ç­‰çº§ï¼šeasy/medium/hard\")\n",
    "    learning_time: str = Field(description=\"é¢„ä¼°å­¦ä¹ æ—¶é—´\")\n",
    "    related_technologies: List[str] = Field(description=\"ç›¸å…³æŠ€æœ¯\")\n",
    "\n",
    "# åˆ›å»ºPydanticè§£æå™¨\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=TechAnalysis)\n",
    "\n",
    "pydantic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç»™å®šçš„æŠ€æœ¯æ¦‚å¿µã€‚\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"è¯·è¯¦ç»†åˆ†æï¼š{concept}\")\n",
    "])\n",
    "\n",
    "pydantic_chain = pydantic_prompt | llm | pydantic_parser\n",
    "\n",
    "# æµ‹è¯•Pydanticè§£æ\n",
    "print(\"=== Pydantic Output Parseræµ‹è¯• ===\")\n",
    "concept = \"å¾®æœåŠ¡æ¶æ„\"\n",
    "\n",
    "try:\n",
    "    result = pydantic_chain.invoke({\n",
    "        \"concept\": concept,\n",
    "        \"format_instructions\": pydantic_parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ“‹ åˆ†æç»“æœç±»å‹: {type(result)}\")\n",
    "    print(f\"ğŸ¯ æ¦‚å¿µ: {result.concept}\")\n",
    "    print(f\"ğŸ“ å®šä¹‰: {result.definition}\")\n",
    "    print(f\"â­ ä¼˜ç‚¹: {result.pros}\")\n",
    "    print(f\"âš ï¸ ç¼ºç‚¹: {result.cons}\")\n",
    "    print(f\"ğŸšï¸ éš¾åº¦: {result.difficulty}\")\n",
    "    print(f\"â° å­¦ä¹ æ—¶é—´: {result.learning_time}\")\n",
    "    print(f\"ğŸ”— ç›¸å…³æŠ€æœ¯: {result.related_technologies}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"è§£æé”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memoryç³»ç»Ÿï¼šè®©AIè®°ä½å¯¹è¯\n",
    "\n",
    "### 4.1 ConversationBufferMemoryï¼ˆå®Œæ•´è®°å¿†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ConversationBufferMemoryæµ‹è¯• ===\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 1 ---\n",
      "ç”¨æˆ·: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "\n",
      "å½“å‰è®°å¿†:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 2 ---\n",
      "ç”¨æˆ·: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "\n",
      "å½“å‰è®°å¿†:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 3 ---\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "Human: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: å½“ç„¶è®°å¾—ï¼ä½ çš„åå­—æ˜¯å¼ ä¸‰ï¼Œä½ æ˜¯ä¸€åPythonå¼€å‘è€…ã€‚ä½ æœ€è¿‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨LangChainã€‚å¦‚æœæœ‰ä»»ä½•å…³äºPythonæˆ–LangChainç›¸å…³çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘å“¦ï¼\n",
      "\n",
      "å½“å‰è®°å¿†:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "Human: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ï¼ä½ çš„åå­—æ˜¯å¼ ä¸‰ï¼Œä½ æ˜¯ä¸€åPythonå¼€å‘è€…ã€‚ä½ æœ€è¿‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨LangChainã€‚å¦‚æœæœ‰ä»»ä½•å…³äºPythonæˆ–LangChainç›¸å…³çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘å“¦ï¼\n",
      "\n",
      "--- å¯¹è¯è½®æ¬¡ 4 ---\n",
      "ç”¨æˆ·: æˆ‘ä¹‹å‰æåˆ°æˆ‘åœ¨å­¦ä¹ ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "Human: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ï¼ä½ çš„åå­—æ˜¯å¼ ä¸‰ï¼Œä½ æ˜¯ä¸€åPythonå¼€å‘è€…ã€‚ä½ æœ€è¿‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨LangChainã€‚å¦‚æœæœ‰ä»»ä½•å…³äºPythonæˆ–LangChainç›¸å…³çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘å“¦ï¼\n",
      "Human: æˆ‘ä¹‹å‰æåˆ°æˆ‘åœ¨å­¦ä¹ ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: ä½ ä¹‹å‰æåˆ°ä½ æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChainã€‚LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„æ¡†æ¶ï¼Œéå¸¸é€‚åˆä¸Pythonç»“åˆå¼€å‘æ™ºèƒ½é—®ç­”ã€æ–‡æ¡£æ£€ç´¢ç­‰AIåº”ç”¨ã€‚å¦‚æœä½ å¯¹LangChainçš„æŸä¸ªå…·ä½“åŠŸèƒ½æˆ–è€…å®ç°ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "å½“å‰è®°å¿†:\n",
      "Human: æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åPythonå¼€å‘è€…ï¼Œä½ å¹³æ—¶ä¸»è¦ç”¨Pythonåšå“ªäº›æ–¹é¢çš„å¼€å‘å‘¢ï¼Ÿæ¯”å¦‚Webå¼€å‘ã€æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–è„šæœ¬ã€æœºå™¨å­¦ä¹ ï¼Œè¿˜æ˜¯å…¶ä»–çš„æ–¹å‘ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•æŠ€æœ¯ä¸Šçš„é—®é¢˜ï¼Œæˆ–è€…æƒ³è¦äº¤æµä¸€äº›Pythonç›¸å…³çš„ç»éªŒå’Œèµ„æºï¼Œéšæ—¶å¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n",
      "Human: æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\n",
      "AI: å¤ªæ£’äº†ï¼LangChain ç›®å‰æ˜¯éå¸¸çƒ­é—¨çš„ AI æŠ€æœ¯ï¼Œå°¤å…¶åœ¨æ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨æ–¹é¢éå¸¸æœ‰ç”¨ã€‚å®ƒä¸ºå¼€å‘è€…æä¾›äº†ä¸€ä¸ªçµæ´»çš„æ¡†æ¶ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°é›†æˆå„ç§è¯­è¨€æ¨¡å‹ï¼ˆæ¯”å¦‚ OpenAI çš„ GPT ç³»åˆ—ï¼‰ï¼Œå¹¶ä¸”æ”¯æŒä¸æ–‡æ¡£æ£€ç´¢ã€å·¥å…·è°ƒç”¨ã€å¤šè½®å¯¹è¯ç­‰å¤šç§åŠŸèƒ½çš„é›†æˆã€‚\n",
      "\n",
      "ç®€å•ä»‹ç»ä¸€ä¸‹ LangChain çš„ä¸»è¦ç‰¹ç‚¹å’Œåº”ç”¨åœºæ™¯ï¼š\n",
      "\n",
      "1. **é“¾å¼æ€ç»´ï¼ˆChainsï¼‰**ï¼šä½ å¯ä»¥æŠŠå¤šä¸ªè¯­è¨€æ¨¡å‹è°ƒç”¨ã€å·¥å…·è°ƒç”¨ç­‰æ“ä½œç»„åˆæˆâ€œé“¾â€ï¼Œå®ç°å¤æ‚çš„ä¸šåŠ¡é€»è¾‘ï¼Œæ¯”å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€æ–‡æ¡£æ‘˜è¦ç­‰ã€‚\n",
      "\n",
      "2. **å·¥å…·é›†æˆï¼ˆTools & Agentsï¼‰**ï¼šLangChain æ”¯æŒé›†æˆæœç´¢å¼•æ“ã€æ•°æ®åº“ã€Python è§£é‡Šå™¨ç­‰å·¥å…·ï¼Œè¿˜å¯ä»¥è®©æ¨¡å‹ä¸»åŠ¨é€‰æ‹©å’Œè°ƒç”¨è¿™äº›å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "3. **æ–‡æ¡£é—®ç­”ï¼ˆDocument QAï¼‰**ï¼šé€šè¿‡ä¸ Embedding æ¨¡å‹ç»“åˆï¼Œå¯ä»¥è®©ä½ çš„åº”ç”¨åœ¨æœ¬åœ°æ–‡æ¡£ã€çŸ¥è¯†åº“ä¸­æ£€ç´¢ç­”æ¡ˆï¼Œå¸¸ç”¨çš„æœ‰ FAISSã€ChromaDB ç­‰å‘é‡æ•°æ®åº“ã€‚\n",
      "\n",
      "4. **å¤šæ¨¡æ€å’Œæ’ä»¶æ‰©å±•**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ç­‰å¤šç§è¾“å…¥ç±»å‹ï¼Œæ’ä»¶ç”Ÿæ€ä¹Ÿå¾ˆä¸°å¯Œï¼Œæ¯”å¦‚ä¸ Streamlitã€FastAPI ç­‰ Web æ¡†æ¶ç»“åˆã€‚\n",
      "\n",
      "å¦‚æœä½ åˆšåˆšå¼€å§‹å­¦ LangChainï¼Œæ¨èå…ˆä»å®ƒçš„å®˜æ–¹æ–‡æ¡£å’Œ Github ä»“åº“å…¥æ‰‹ï¼Œé‡Œé¢æœ‰å¾ˆå¤šå®ç”¨çš„æ•™ç¨‹å’Œä»£ç ç¤ºä¾‹ï¼ˆ[LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)ï¼‰ã€‚å¦å¤–ï¼ŒLangChain ç¤¾åŒºä¹Ÿå¾ˆæ´»è·ƒï¼Œå¦‚æœé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ GitHub Issuesã€Discussions é‡Œæé—®ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰å…·ä½“æƒ³å®ç°çš„åŠŸèƒ½ã€é‡åˆ°çš„æŠ€æœ¯éš¾é¢˜ï¼Œæˆ–è€…æƒ³äº†è§£ä¸€äº›æœ€ä½³å®è·µï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„å»ºè®®å’Œä»£ç ç¤ºä¾‹ï¼ä½ ç›®å‰å¯¹ LangChain çš„å“ªä¸€å—æœ€æ„Ÿå…´è¶£å‘¢ï¼Ÿ\n",
      "Human: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ï¼ä½ çš„åå­—æ˜¯å¼ ä¸‰ï¼Œä½ æ˜¯ä¸€åPythonå¼€å‘è€…ã€‚ä½ æœ€è¿‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨LangChainã€‚å¦‚æœæœ‰ä»»ä½•å…³äºPythonæˆ–LangChainç›¸å…³çš„é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘å“¦ï¼\n",
      "Human: æˆ‘ä¹‹å‰æåˆ°æˆ‘åœ¨å­¦ä¹ ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ\n",
      "AI: ä½ ä¹‹å‰æåˆ°ä½ æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChainã€‚LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨çš„æ¡†æ¶ï¼Œéå¸¸é€‚åˆä¸Pythonç»“åˆå¼€å‘æ™ºèƒ½é—®ç­”ã€æ–‡æ¡£æ£€ç´¢ç­‰AIåº”ç”¨ã€‚å¦‚æœä½ å¯¹LangChainçš„æŸä¸ªå…·ä½“åŠŸèƒ½æˆ–è€…å®ç°ç»†èŠ‚æ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ—¶å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# åˆ›å»ºå®Œæ•´è®°å¿†ç³»ç»Ÿ\n",
    "buffer_memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"=== ConversationBufferMemoryæµ‹è¯• ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿå¯¹è¯\n",
    "conversation_topics = [\n",
    "    \"æˆ‘çš„åå­—æ˜¯å¼ ä¸‰ï¼Œæˆ‘æ˜¯ä¸€åPythonå¼€å‘è€…\",\n",
    "    \"æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯LangChain\",\n",
    "    \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\",\n",
    "    \"æˆ‘ä¹‹å‰æåˆ°æˆ‘åœ¨å­¦ä¹ ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for i, topic in enumerate(conversation_topics, 1):\n",
    "    print(f\"\\n--- å¯¹è¯è½®æ¬¡ {i} ---\")\n",
    "    print(f\"ç”¨æˆ·: {topic}\")\n",
    "    response = conversation.predict(input=topic)\n",
    "    print(f\"AI: {response}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºè®°å¿†å†…å®¹\n",
    "    print(f\"\\nå½“å‰è®°å¿†:\")\n",
    "    print(buffer_memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ConversationBufferWindowMemoryï¼ˆæ»‘åŠ¨çª—å£è®°å¿†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ConversationBufferWindowMemoryæµ‹è¯• ===\n",
      "åªè®°ä½æœ€è¿‘3è½®å¯¹è¯\n",
      "\n",
      "ç¬¬1è½®ï¼šæˆ‘å–œæ¬¢è“è‰²\n",
      "AI: è“è‰²çœŸæ˜¯ä¸€ä¸ªå¾ˆç¾çš„é¢œè‰²ï¼å®ƒå¸¸å¸¸è®©äººè”æƒ³åˆ°å¤©ç©ºå’Œå¤§æµ·ï¼Œç»™äººä¸€ç§å®é™ã€æ¸…æ–°çš„æ„Ÿè§‰ã€‚ä½ å–œæ¬¢è“è‰²çš„å“ªä¸€ç§å‘¢ï¼Ÿæ¯”å¦‚è¯´å¤©è“ã€å®çŸ³è“ã€è—é’è‰²ï¼Œè¿˜æ˜¯å…¶ä»–ä»€ä¹ˆè“è‰²ï¼Ÿä½ æœ‰æ²¡æœ‰å–œæ¬¢çš„è“è‰²ç‰©å“ï¼Œæ¯”å¦‚è¡£æœã€æ–‡å…·ï¼Œæˆ–è€…æˆ¿é—´çš„è£…é¥°...\n",
      "è®°å¿†è½®æ¬¡: 1\n",
      "\n",
      "ç¬¬2è½®ï¼šæˆ‘çš„çˆ±å¥½æ˜¯ç¼–ç¨‹\n",
      "AI: ç¼–ç¨‹çœŸæ£’ï¼å®ƒä¸ä»…èƒ½é”»ç‚¼é€»è¾‘æ€ç»´ï¼Œè¿˜èƒ½è®©ä½ åˆ›é€ å‡ºå„ç§æœ‰è¶£çš„é¡¹ç›®ã€‚ä½ æ˜¯æ€ä¹ˆå¼€å§‹æ¥è§¦ç¼–ç¨‹çš„å‘¢ï¼Ÿä½ å¹³æ—¶ç”¨ä»€ä¹ˆç¼–ç¨‹è¯­è¨€æ¯”è¾ƒå¤šï¼Ÿæ¯”å¦‚ Pythonã€Javaã€C++ è¿˜æ˜¯ JavaScriptï¼Ÿä½ æœ‰æ²¡æœ‰åšè¿‡ä¸€äº›è®©...\n",
      "è®°å¿†è½®æ¬¡: 2\n",
      "\n",
      "ç¬¬3è½®ï¼šæˆ‘ä½åœ¨åŒ—äº¬\n",
      "AI: åŒ—äº¬æ˜¯ä¸€åº§å……æ»¡å†å²ä¸ç°ä»£æ°”æ¯çš„åŸå¸‚ï¼è¿™é‡Œæ—¢æœ‰å£®ä¸½çš„å¤è¿¹ï¼Œæ¯”å¦‚æ•…å®«ã€å¤©å›ã€é•¿åŸï¼Œä¹Ÿæœ‰ç¹åçš„éƒ½å¸‚ç”Ÿæ´»ï¼Œæ¯”å¦‚ä¸‰é‡Œå±¯ã€å›½è´¸ã€798è‰ºæœ¯åŒºã€‚åŒ—äº¬çš„å°åƒä¹Ÿå¾ˆæœ‰ç‰¹è‰²ï¼Œåƒè±†æ±å„¿ã€ç‚¸é…±é¢ã€å¤ç…®ç«çƒ§ã€å†°ç³–è‘«èŠ¦ï¼Œéƒ½è®©äººéš¾å¿˜...\n",
      "è®°å¿†è½®æ¬¡: 3\n",
      "\n",
      "ç¬¬4è½®ï¼šæˆ‘ä»Šå¹´25å²\n",
      "AI: 25å²æ­£æ˜¯å……æ»¡æ´»åŠ›å’Œæ— é™å¯èƒ½çš„å¹´çºªï¼è¿™ä¸ªé˜¶æ®µï¼Œå¾ˆå¤šäººä¼šåœ¨å­¦ä¹ ã€å·¥ä½œã€ç”Ÿæ´»ä¸­ä¸æ–­æ¢ç´¢å’Œæˆé•¿ã€‚ä½ ç°åœ¨æ˜¯åœ¨ä¸Šå­¦ã€åˆšå¼€å§‹å·¥ä½œï¼Œè¿˜æ˜¯å·²ç»æœ‰ä¸€äº›èŒä¸šç»éªŒäº†å‘¢ï¼Ÿæœ‰æ²¡æœ‰ä»€ä¹ˆç›®æ ‡æˆ–è€…æ¢¦æƒ³æ˜¯ä½ ç‰¹åˆ«æƒ³å®ç°çš„ï¼Ÿ\n",
      "\n",
      "å…¶å®ï¼Œ25...\n",
      "è®°å¿†è½®æ¬¡: 4\n",
      "\n",
      "ç¬¬5è½®ï¼šæˆ‘å­¦è¿‡Java\n",
      "AI: å¤ªæ£’äº†ï¼Java æ˜¯ä¸€é—¨éå¸¸å®ç”¨è€Œä¸”æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ï¼Œæ— è®ºæ˜¯åœ¨ä¼ä¸šçº§å¼€å‘ã€ç§»åŠ¨åº”ç”¨ï¼ˆæ¯”å¦‚ Androidï¼‰ã€è¿˜æ˜¯åç«¯å¼€å‘ä¸­éƒ½éå¸¸å¸¸è§ã€‚ä½ å­¦ Java æœ‰å¤šä¹…äº†ï¼Ÿä¸»è¦æ˜¯è‡ªå­¦ã€åœ¨å­¦æ ¡è¯¾ç¨‹ä¸­å­¦çš„ï¼Œè¿˜æ˜¯å·¥ä½œä¸­ç”¨...\n",
      "è®°å¿†è½®æ¬¡: 5\n",
      "\n",
      "ç¬¬6è½®ï¼šä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²å—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ï¼ä½ å–œæ¬¢è“è‰²ã€‚è“è‰²æ˜¯ä¸€ä¸ªå¾ˆå—æ¬¢è¿çš„é¢œè‰²ï¼Œæ—¢æœ‰æ¸…æ–°çš„å¤©è“ï¼Œä¹Ÿæœ‰æ·±é‚ƒçš„å®çŸ³è“å’Œè—é’è‰²ã€‚ä¹‹å‰æˆ‘ä»¬è¿˜èŠåˆ°è¿‡å…³äºè“è‰²æœ‰ä»€ä¹ˆä¸åŒçš„è‰²è°ƒå’Œä½ å–œæ¬¢çš„è“è‰²ç‰©å“ã€‚å¦‚æœä½ è¿˜æƒ³èŠæ›´å¤šå’Œè“è‰²ç›¸å…³çš„è¯é¢˜ï¼Œæ¯”å¦‚è“è‰²çš„æ­é…ã€...\n",
      "è®°å¿†è½®æ¬¡: 6\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºæ»‘åŠ¨çª—å£è®°å¿†ï¼ˆåªè®°ä½æœ€è¿‘3è½®å¯¹è¯ï¼‰\n",
    "window_memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "window_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== ConversationBufferWindowMemoryæµ‹è¯• ===\")\n",
    "print(\"åªè®°ä½æœ€è¿‘3è½®å¯¹è¯\")\n",
    "\n",
    "# è¿›è¡Œå¤šè½®å¯¹è¯æµ‹è¯•\n",
    "test_messages = [\n",
    "    \"ç¬¬1è½®ï¼šæˆ‘å–œæ¬¢è“è‰²\",\n",
    "    \"ç¬¬2è½®ï¼šæˆ‘çš„çˆ±å¥½æ˜¯ç¼–ç¨‹\", \n",
    "    \"ç¬¬3è½®ï¼šæˆ‘ä½åœ¨åŒ—äº¬\",\n",
    "    \"ç¬¬4è½®ï¼šæˆ‘ä»Šå¹´25å²\",\n",
    "    \"ç¬¬5è½®ï¼šæˆ‘å­¦è¿‡Java\",\n",
    "    \"ç¬¬6è½®ï¼šä½ è¿˜è®°å¾—æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²å—ï¼Ÿ\"  # åº”è¯¥ä¸è®°å¾—ï¼Œå› ä¸ºè¶…å‡ºçª—å£\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    response = window_conversation.predict(input=msg)\n",
    "    print(f\"\\n{msg}\")\n",
    "    print(f\"AI: {response[:100]}...\")\n",
    "    print(f\"è®°å¿†è½®æ¬¡: {len(window_memory.chat_memory.messages)//2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ConversationSummaryMemoryï¼ˆæ‘˜è¦è®°å¿†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18889\\AppData\\Local\\Temp\\ipykernel_31376\\2700894171.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryMemory(\n",
      "C:\\Users\\18889\\AppData\\Local\\Temp\\ipykernel_31376\\2700894171.py:15: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  summary_conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ConversationSummaryMemoryæµ‹è¯• ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è½®æ¬¡ 1: æˆ‘æ˜¯ä¸€åAIç ”ç©¶å‘˜ï¼Œä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†\n",
      "AI: å¤ªæ£’äº†ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸæœ€æ´»è·ƒã€æœ€æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ä¹‹ä¸€ã€‚ä½ æœ€è¿‘åœ¨å…³æ³¨å“ªäº›NLPå­é¢†åŸŸå‘¢ï¼Ÿæ¯”å¦‚å¤§è¯­è¨€æ¨¡å‹ã€å¯¹è¯ç³»ç»Ÿã€ä¿¡æ¯æŠ½å–ã€æ–‡æœ¬ç”Ÿæˆï¼Œè¿˜æ˜¯å¤šæ¨¡æ€å­¦ä¹ ï¼Ÿå¦‚æœä½ æ„¿æ„åˆ†äº«çš„è¯ï¼Œä¹Ÿå¾ˆæƒ³å¬å¬ä½ ç›®å‰å‚ä¸çš„é¡¹ç›®æˆ–è€…é‡åˆ°çš„æœ‰è¶£æŒ‘æˆ˜ã€‚...\n",
      "æ‘˜è¦: A humanä»‹ç»è‡ªå·±æ˜¯ä¸€åä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„AIç ”ç©¶å‘˜ã€‚AIè¡¨ç¤ºå¾ˆé«˜å…´è®¤è¯†å¯¹æ–¹ï¼Œå¹¶æŒ‡å‡ºè‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­æœ€æ´»è·ƒã€æœ€æœ‰å‰æ™¯çš„æ–¹å‘ä¹‹ä¸€ã€‚AIè¿˜è¯¢é—®å¯¹æ–¹æœ€è¿‘å…³æ³¨çš„NLPå­é¢†åŸŸï¼Œä»¥åŠç›®å‰å‚ä¸çš„é¡¹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è½®æ¬¡ 2: æˆ‘æœ€è¿‘åœ¨ç ”ç©¶å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯\n",
      "AI: å¤ªæ£’äº†ï¼å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒï¼ˆfine-tuningï¼‰ä¸€ç›´æ˜¯å½“å‰NLPé¢†åŸŸçš„çƒ­é—¨è¯é¢˜ï¼Œä¹Ÿæ˜¯æå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°çš„é‡è¦æ‰‹æ®µã€‚è¿‘å¹´æ¥ï¼Œéšç€LLMï¼ˆå¦‚GPTã€T5ã€BERTç­‰ï¼‰çš„å¹¿æ³›åº”ç”¨ï¼Œå¾®è°ƒæŠ€æœ¯ä¹Ÿåœ¨ä¸æ–­å‘å±•å’Œæ¼”è¿›ã€‚ä¸çŸ¥é“ä½ æœ€è¿‘ä¸»è¦å…³æ³¨å“ªä¸€ç±»å¾®è°ƒæ–¹æ³•ï¼Ÿæ¯”å¦‚ï¼š\n",
      "\n",
      "1. **å…¨å‚æ•°å¾®è°ƒï¼ˆFull-Parame...\n",
      "æ‘˜è¦: A humanä»‹ç»è‡ªå·±æ˜¯ä¸€åä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„AIç ”ç©¶å‘˜ã€‚AIè¡¨ç¤ºå¾ˆé«˜å…´è®¤è¯†å¯¹æ–¹ï¼Œå¹¶æŒ‡å‡ºè‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­æœ€æ´»è·ƒã€æœ€æœ‰å‰æ™¯çš„æ–¹å‘ä¹‹ä¸€ã€‚AIè¿˜è¯¢é—®å¯¹æ–¹æœ€è¿‘å…³æ³¨çš„NLPå­é¢†åŸŸï¼Œä»¥åŠç›®å‰å‚ä¸çš„é¡¹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è½®æ¬¡ 3: æˆ‘å‘ç°LoRAæ˜¯ä¸€ä¸ªå¾ˆæœ‰æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•\n",
      "AI: å®Œå…¨åŒæ„ï¼LoRAï¼ˆLow-Rank Adaptationï¼‰ä½œä¸ºä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œè¿‘å¹´æ¥åœ¨å¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ä¸­éå¸¸å—æ¬¢è¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å‚æ•°é‡å·¨å¤§çš„æ¨¡å‹ï¼ˆå¦‚GPT-3ã€Llamaç­‰ï¼‰ä¸Šã€‚LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨å†»ç»“åŸå§‹æ¨¡å‹å‚æ•°çš„åŸºç¡€ä¸Šï¼Œä»…åœ¨éƒ¨åˆ†å±‚ä¸­å¼•å…¥ä½ç§©å¯è®­ç»ƒçš„é€‚é…å™¨æƒé‡ã€‚è¿™æ ·å¤§å¤§å‡å°‘äº†éœ€è¦æ›´æ–°å’Œå­˜...\n",
      "æ‘˜è¦: A humanä»‹ç»è‡ªå·±æ˜¯ä¸€åä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„AIç ”ç©¶å‘˜ã€‚AIè¡¨ç¤ºå¾ˆé«˜å…´è®¤è¯†å¯¹æ–¹ï¼Œå¹¶æŒ‡å‡ºè‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­æœ€æ´»è·ƒã€æœ€æœ‰å‰æ™¯çš„æ–¹å‘ä¹‹ä¸€ã€‚AIè¿˜è¯¢é—®å¯¹æ–¹æœ€è¿‘å…³æ³¨çš„NLPå­é¢†åŸŸï¼Œä»¥åŠç›®å‰å‚ä¸çš„é¡¹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è½®æ¬¡ 4: æˆ‘è¿˜å°è¯•è¿‡QLoRAï¼Œå®ƒåœ¨å†…å­˜ä½¿ç”¨ä¸Šæ›´ä¼˜åŒ–\n",
      "AI: æ˜¯çš„ï¼ŒQLoRAï¼ˆQuantized LoRAï¼‰ç¡®å®åœ¨å†…å­˜å’Œè®¡ç®—èµ„æºä½¿ç”¨æ–¹é¢æœ‰äº†è¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚QLoRAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆå¦‚LoRAï¼‰å’Œæƒé‡é‡åŒ–æŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼ŒQLoRAé€šè¿‡å°†åŸºç¡€å¤§è¯­è¨€æ¨¡å‹çš„æƒé‡è¿›è¡Œä½æ¯”ç‰¹ï¼ˆå¦‚4-bitï¼‰é‡åŒ–ï¼Œå¤§å¹…å‹ç¼©äº†æ¨¡å‹åœ¨å¾®è°ƒå’Œæ¨ç†æ—¶çš„å†…å­˜å ç”¨ï¼›åŒæ—¶ï¼Œåœ¨é‡åŒ–æ¨¡å‹...\n",
      "æ‘˜è¦: A humanä»‹ç»è‡ªå·±æ˜¯ä¸€åä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†çš„AIç ”ç©¶å‘˜ï¼ŒAIè¡¨ç¤ºå¾ˆé«˜å…´è®¤è¯†å¯¹æ–¹ï¼Œå¹¶æŒ‡å‡ºNLPæ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸä¸­æœ€æ´»è·ƒã€æœ€æœ‰å‰æ™¯çš„æ–¹å‘ä¹‹ä¸€ï¼Œè¯¢é—®å¯¹æ–¹å½“å‰å…³æ³¨çš„NLPå­é¢†åŸŸåŠé¡¹ç›®æŒ‘æˆ˜ã€‚Humanè¡¨ç¤ºè‡ªå·±...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     24\u001b[39m long_conversation = [\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mæˆ‘æ˜¯ä¸€åAIç ”ç©¶å‘˜ï¼Œä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mæˆ‘æœ€è¿‘åœ¨ç ”ç©¶å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mä½ èƒ½æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆšæ‰è®¨è®ºçš„å†…å®¹å—ï¼Ÿ\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m ]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(long_conversation, \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     response = \u001b[43msummary_conversation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mè½®æ¬¡ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[:\u001b[32m150\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\llm.py:319\u001b[39m, in \u001b[36mLLMChain.predict\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    305\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m \u001b[33;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m.output_key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:189\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\llm.py:127\u001b[39m, in \u001b[36mLLMChain._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    125\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    126\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.create_outputs(response)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain\\chains\\llm.py:139\u001b[39m, in \u001b[36mLLMChain.generate\u001b[39m\u001b[34m(self, input_list, run_manager)\u001b[39m\n\u001b[32m    137\u001b[39m callbacks = run_manager.get_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm, BaseLanguageModel):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     results = \u001b[38;5;28mself\u001b[39m.llm.bind(stop=stop, **\u001b[38;5;28mself\u001b[39m.llm_kwargs).batch(\n\u001b[32m    147\u001b[39m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks}\n\u001b[32m    148\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    956\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    960\u001b[39m     **kwargs: Any,\n\u001b[32m    961\u001b[39m ) -> LLMResult:\n\u001b[32m    962\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    781\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    788\u001b[39m         )\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    790\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1032\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1130\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1128\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1044\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1084\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1085\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1086\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1087\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\openai\\_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    970\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    978\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\http_proxy.py:343\u001b[39m, in \u001b[36mTunnelHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    336\u001b[39m             \u001b[38;5;28mself\u001b[39m._connection = HTTP11Connection(\n\u001b[32m    337\u001b[39m                 origin=\u001b[38;5;28mself\u001b[39m._remote_origin,\n\u001b[32m    338\u001b[39m                 stream=stream,\n\u001b[32m    339\u001b[39m                 keepalive_expiry=\u001b[38;5;28mself\u001b[39m._keepalive_expiry,\n\u001b[32m    340\u001b[39m             )\n\u001b[32m    342\u001b[39m         \u001b[38;5;28mself\u001b[39m._connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda\\envs\\ai-guide\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# åˆ›å»ºæ‘˜è¦è®°å¿†ç³»ç»Ÿ\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=200  # å½“è®°å¿†è¶…è¿‡1000 tokensæ—¶å¼€å§‹æ‘˜è¦\n",
    ")\n",
    "\n",
    "summary_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== ConversationSummaryMemoryæµ‹è¯• ===\")\n",
    "\n",
    "# æ¨¡æ‹Ÿé•¿å¯¹è¯\n",
    "long_conversation = [\n",
    "    \"æˆ‘æ˜¯ä¸€åAIç ”ç©¶å‘˜ï¼Œä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†\",\n",
    "    \"æˆ‘æœ€è¿‘åœ¨ç ”ç©¶å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯\",\n",
    "    \"æˆ‘å‘ç°LoRAæ˜¯ä¸€ä¸ªå¾ˆæœ‰æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•\",\n",
    "    \"æˆ‘è¿˜å°è¯•è¿‡QLoRAï¼Œå®ƒåœ¨å†…å­˜ä½¿ç”¨ä¸Šæ›´ä¼˜åŒ–\",\n",
    "    \"é™¤äº†å¾®è°ƒï¼Œæˆ‘ä¹Ÿåœ¨ç ”ç©¶RAGæŠ€æœ¯\",\n",
    "    \"RAGå¯ä»¥è®©æ¨¡å‹è·å–æœ€æ–°çš„å¤–éƒ¨çŸ¥è¯†\",\n",
    "    \"ä½ èƒ½æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆšæ‰è®¨è®ºçš„å†…å®¹å—ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(long_conversation, 1):\n",
    "    response = summary_conversation.predict(input=msg)\n",
    "    print(f\"\\nè½®æ¬¡ {i}: {msg}\")\n",
    "    print(f\"AI: {response[:150]}...\")\n",
    "    \n",
    "    # æ˜¾ç¤ºæ‘˜è¦\n",
    "    if hasattr(summary_memory, 'buffer'):\n",
    "        print(f\"æ‘˜è¦: {summary_memory.buffer[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Document Loaderså’ŒText Splitters\n",
    "\n",
    "### 5.1 å¤„ç†ä¸åŒæ ¼å¼çš„æ–‡æ¡£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ–‡æ¡£å¤„ç†æµ‹è¯• ===\n",
      "åŸå§‹æ–‡æ¡£é•¿åº¦: 441 å­—ç¬¦\n",
      "åŸå§‹æ–‡æ¡£:\n",
      "\n",
      "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "\n",
      "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ç»Ÿè®¡æŠ€æœ¯æ¥æ‰¾åˆ°æ•°æ®ä¸­çš„æ¨¡å¼ã€‚\n",
      "\n",
      "æ·±åº¦å­¦ä¹ ï¼ˆDeep Learning, DLï¼‰æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œ...\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹æ–‡æ¡£\n",
    "sample_text = \"\"\"\n",
    "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
    "\n",
    "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ç»Ÿè®¡æŠ€æœ¯æ¥æ‰¾åˆ°æ•°æ®ä¸­çš„æ¨¡å¼ã€‚\n",
    "\n",
    "æ·±åº¦å­¦ä¹ ï¼ˆDeep Learning, DLï¼‰æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚\n",
    "\n",
    "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processing, NLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚NLPç»“åˆäº†è®¡ç®—è¯­è¨€å­¦ã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚\n",
    "\n",
    "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰å¦‚GPTã€BERTç­‰ï¼Œä»£è¡¨äº†NLPé¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚è¿™äº›æ¨¡å‹åœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆé«˜è´¨é‡çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ã€‚\n",
    "\"\"\"\n",
    "\n",
    "# åˆ›å»ºæ–‡æ¡£å¯¹è±¡\n",
    "doc = Document(page_content=sample_text, metadata={\"source\": \"AIæŠ€æœ¯æ¦‚è¿°\"})\n",
    "\n",
    "print(\"=== æ–‡æ¡£å¤„ç†æµ‹è¯• ===\")\n",
    "print(f\"åŸå§‹æ–‡æ¡£é•¿åº¦: {len(sample_text)} å­—ç¬¦\")\n",
    "print(f\"åŸå§‹æ–‡æ¡£:\\n{sample_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ä¸åŒçš„æ–‡æœ¬åˆ†å‰²ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== é€’å½’å­—ç¬¦åˆ†å‰²å™¨ ===\n",
      "åˆ†å‰²åå—æ•°: 3\n",
      "\n",
      "å— 1 (é•¿åº¦: 154)\n",
      "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "\n",
      "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚æœºå™¨å­¦ä¹ ç®—æ³•ä½¿ç”¨ç»Ÿè®¡æŠ€æœ¯æ¥æ‰¾åˆ°æ•°æ®ä¸­...\n",
      "\n",
      "å— 2 (é•¿åº¦: 186)\n",
      "æ·±åº¦å­¦ä¹ ï¼ˆDeep Learning, DLï¼‰æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚\n",
      "\n",
      "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNatural Language Processing, NLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œä¸“æ³¨äºè®©è®¡ç®—æœºç†...\n",
      "\n",
      "å— 3 (é•¿åº¦: 95)\n",
      "å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰å¦‚GPTã€BERTç­‰ï¼Œä»£è¡¨äº†NLPé¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚è¿™äº›æ¨¡å‹åœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆé«˜è´¨é‡çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬ã€‚...\n",
      "\n",
      "=== Tokenåˆ†å‰²å™¨ ===\n",
      "åˆ†å‰²åå—æ•°: 9\n",
      "\n",
      "å— 1:\n",
      "\n",
      "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "\n",
      "ï¿½...\n",
      "\n",
      "å— 2:\n",
      "ï¿½ï¿½èƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "\n",
      "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ï¿½...\n"
     ]
    }
   ],
   "source": [
    "# 1. é€’å½’å­—ç¬¦åˆ†å‰²å™¨ï¼ˆæ¨èï¼‰\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # æ¯å—æœ€å¤§å­—ç¬¦æ•°\n",
    "    chunk_overlap=50,  # é‡å å­—ç¬¦æ•°\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼\", \"ï¼Ÿ\", \";\", \",\", \" \", \"\"]  # åˆ†å‰²ä¼˜å…ˆçº§\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_documents([doc])\n",
    "\n",
    "print(\"\\n=== é€’å½’å­—ç¬¦åˆ†å‰²å™¨ ===\")\n",
    "print(f\"åˆ†å‰²åå—æ•°: {len(recursive_chunks)}\")\n",
    "for i, chunk in enumerate(recursive_chunks):\n",
    "    print(f\"\\nå— {i+1} (é•¿åº¦: {len(chunk.page_content)})\")\n",
    "    print(f\"{chunk.page_content[:150]}...\")\n",
    "\n",
    "# 2. åŸºäºTokençš„åˆ†å‰²å™¨\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=100,  # æ¯å—æœ€å¤§tokenæ•°\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_documents([doc])\n",
    "\n",
    "print(f\"\\n=== Tokenåˆ†å‰²å™¨ ===\")\n",
    "print(f\"åˆ†å‰²åå—æ•°: {len(token_chunks)}\")\n",
    "for i, chunk in enumerate(token_chunks[:2]):  # åªæ˜¾ç¤ºå‰ä¸¤å—\n",
    "    print(f\"\\nå— {i+1}:\")\n",
    "    print(f\"{chunk.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç»¼åˆå®è·µï¼šæ„å»ºæ™ºèƒ½å¯¹è¯åŠ©æ‰‹\n",
    "\n",
    "å°†ä»Šå¤©å­¦åˆ°çš„æ‰€æœ‰æŠ€æœ¯æ•´åˆåˆ°ä¸€ä¸ªå®Œæ•´çš„å¯¹è¯ç³»ç»Ÿä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18889\\AppData\\Local\\Temp\\ipykernel_31376\\756752796.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferWindowMemory(k=5)  # è®°ä½æœ€è¿‘5è½®å¯¹è¯\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== æ™ºèƒ½å¯¹è¯åŠ©æ‰‹æµ‹è¯• ===\n",
      "\n",
      "--- å¯¹è¯ 1 ---\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹\n",
      "åŠ©æ‰‹: ä½ å¥½å°æ˜ï¼Œå¾ˆé«˜å…´èƒ½å¸®åŠ©ä½ å­¦ä¹ Pythonç¼–ç¨‹ã€‚ä½ å·²ç»æœ‰ç¼–ç¨‹ç»éªŒäº†å—ï¼Ÿè¿˜æ˜¯ä»é›¶å¼€å§‹å­¦ä¹ å‘¢ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•å…³äºPythonç¼–ç¨‹çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥éšæ—¶é—®æˆ‘å“¦ï¼...\n",
      "\n",
      "--- å¯¹è¯ 2 ---\n",
      "ç”¨æˆ·: æˆ‘å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹\n",
      "åŠ©æ‰‹: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ å¯¹æœºå™¨å­¦ä¹ æ„Ÿå…´è¶£ã€‚ä½œä¸ºä¸€ä¸ªåˆå­¦è€…ï¼Œä½ å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ ï¼š\n",
      "\n",
      "1. æŒæ¡åŸºç¡€æ•°å­¦çŸ¥è¯†ï¼šæœºå™¨å­¦ä¹ æ¶‰åŠåˆ°å¾ˆå¤šæ•°å­¦æ¦‚å¿µï¼Œç‰¹åˆ«æ˜¯çº¿æ€§ä»£æ•°ã€å¾®ç§¯åˆ†å’Œæ¦‚ç‡è®ºç­‰ã€‚å»ºè®®ä½ å…ˆæ‰“å¥½æ•°å­¦åŸºç¡€ã€‚\n",
      "\n",
      "2. å­¦ä¹ ç¼–ç¨‹è¯­è¨€ï¼šPythonæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸæœ€å¸¸ç”¨çš„ç¼–ç¨‹è¯­è¨€ä¹‹ä¸€ï¼Œä½ å¯ä»¥ä»å­¦ä¹ Pythonå¼€å§‹ã€‚æŒæ¡PythonåŸºç¡€è¯­æ³•å’Œç›¸å…³åº“ï¼ˆå¦‚NumPyã€Pandasã€Matplotlibç­‰ï¼‰å¯¹äºæœºå™¨å­¦...\n",
      "\n",
      "--- å¯¹è¯ 3 ---\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿæˆ‘æƒ³å­¦ä¹ ä»€ä¹ˆï¼Ÿ\n",
      "åŠ©æ‰‹: å½“ç„¶è®°å¾—ï¼ä½ æ˜¯å°æ˜ï¼Œä½ å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹å­¦ä¹ ã€‚å¦‚æœä½ æƒ³äº†è§£å¦‚ä½•å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œæˆ‘å¯ä»¥ç»™ä½ ä¸€äº›å»ºè®®å“¦ï¼...\n",
      "\n",
      "--- å¯¹è¯ 4 ---\n",
      "ç”¨æˆ·: èƒ½ç»™æˆ‘æ¨èä¸€äº›Pythonæœºå™¨å­¦ä¹ çš„å­¦ä¹ è·¯å¾„å—ï¼Ÿ\n",
      "åŠ©æ‰‹: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ å¯¹Pythonæœºå™¨å­¦ä¹ æ„Ÿå…´è¶£ã€‚ä½œä¸ºä¸€ä¸ªåˆå­¦è€…ï¼Œä½ å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤å¼€å§‹å­¦ä¹ Pythonæœºå™¨å­¦ä¹ ï¼š\n",
      "\n",
      "1. æŒæ¡åŸºç¡€æ•°å­¦çŸ¥è¯†ï¼šæœºå™¨å­¦ä¹ æ¶‰åŠåˆ°å¾ˆå¤šæ•°å­¦æ¦‚å¿µï¼Œç‰¹åˆ«æ˜¯çº¿æ€§ä»£æ•°ã€å¾®ç§¯åˆ†å’Œæ¦‚ç‡è®ºç­‰ã€‚å»ºè®®ä½ å…ˆæ‰“å¥½æ•°å­¦åŸºç¡€ã€‚\n",
      "\n",
      "2. å­¦ä¹ ç¼–ç¨‹è¯­è¨€ï¼šPythonæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸæœ€å¸¸ç”¨çš„ç¼–ç¨‹è¯­è¨€ä¹‹ä¸€ï¼Œä½ å¯ä»¥ä»å­¦ä¹ Pythonå¼€å§‹ã€‚æŒæ¡PythonåŸºç¡€è¯­æ³•å’Œç›¸å…³åº“ï¼ˆå¦‚NumPyã€Pandasã€Matpl...\n",
      "\n",
      "--- å¯¹è¯ 5 ---\n",
      "ç”¨æˆ·: è°¢è°¢ä½ çš„å»ºè®®ï¼Œæˆ‘ä¼šæŒ‰ç…§è¿™ä¸ªè·¯å¾„å­¦ä¹ çš„\n",
      "åŠ©æ‰‹: ä¸å®¢æ°”ï¼Œå¾ˆé«˜å…´èƒ½å¸®åŠ©åˆ°ä½ ï¼å¦‚æœåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„æŒ‡å¯¼ï¼Œéƒ½å¯ä»¥éšæ—¶å‘æˆ‘å’¨è¯¢ã€‚ç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼ŒæŒæ¡æœºå™¨å­¦ä¹ çš„çŸ¥è¯†å’ŒæŠ€èƒ½ï¼å¦‚æœæœ‰å…¶ä»–é—®é¢˜ï¼Œä¹Ÿæ¬¢è¿éšæ—¶å’Œæˆ‘äº¤æµã€‚...\n",
      "\n",
      "=== å¯¹è¯è®°å¿†æ‘˜è¦ ===\n",
      "Human: ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹\n",
      "AI: ä½ å¥½å°æ˜ï¼Œå¾ˆé«˜å…´èƒ½å¸®åŠ©ä½ å­¦ä¹ Pythonç¼–ç¨‹ã€‚ä½ å·²ç»æœ‰ç¼–ç¨‹ç»éªŒäº†å—ï¼Ÿè¿˜æ˜¯ä»é›¶å¼€å§‹å­¦ä¹ å‘¢ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•å…³äºPythonç¼–ç¨‹çš„é—®é¢˜ï¼Œéƒ½å¯ä»¥éšæ—¶é—®æˆ‘å“¦ï¼\n",
      "Human: æˆ‘å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹\n",
      "AI: ä½ å¥½ï¼å¾ˆé«˜å…´å¬åˆ°ä½ å¯¹æœºå™¨å­¦ä¹ æ„Ÿå…´è¶£ã€‚ä½œä¸ºä¸€ä¸ªåˆå­¦è€…ï¼Œä½ å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤å¼€å§‹å­¦ä¹ æœºå™¨å­¦ä¹ ï¼š\n",
      "\n",
      "1. æŒæ¡åŸºç¡€æ•°å­¦çŸ¥è¯†ï¼šæœºå™¨å­¦ä¹ æ¶‰åŠåˆ°å¾ˆå¤šæ•°å­¦æ¦‚å¿µï¼Œç‰¹åˆ«æ˜¯çº¿æ€§ä»£æ•°ã€å¾®ç§¯åˆ†å’Œæ¦‚ç‡è®ºç­‰ã€‚å»ºè®®ä½ å…ˆæ‰“å¥½æ•°å­¦åŸºç¡€ã€‚\n",
      "\n",
      "2. å­¦ä¹ ç¼–ç¨‹è¯­è¨€ï¼šPythonæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸæœ€å¸¸ç”¨çš„ç¼–ç¨‹è¯­è¨€ä¹‹ä¸€ï¼Œä½ å¯ä»¥ä»å­¦ä¹ Pythonå¼€å§‹ã€‚æŒæ¡PythonåŸºç¡€...\n"
     ]
    }
   ],
   "source": [
    "class SmartConversationAssistant:\n",
    "    \"\"\"æ™ºèƒ½å¯¹è¯åŠ©æ‰‹ - æ•´åˆä»Šæ—¥æ‰€å­¦æŠ€æœ¯\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "        self.memory = ConversationBufferWindowMemory(k=5)  # è®°ä½æœ€è¿‘5è½®å¯¹è¯\n",
    "        \n",
    "        # æ™ºèƒ½æç¤ºè¯æ¨¡æ¿\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "            ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå…·æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š\n",
    "            1. è®°ä½å¯¹è¯å†å²ï¼Œæä¾›è¿è´¯çš„å›ç­”\n",
    "            2. æ ¹æ®ç”¨æˆ·é—®é¢˜ç±»å‹è°ƒæ•´å›ç­”é£æ ¼\n",
    "            3. æä¾›ç»“æ„åŒ–çš„ä¿¡æ¯åˆ†æ\n",
    "            \n",
    "            å¯¹è¯å†å²ï¼š{history}\n",
    "            \n",
    "            è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ç±»å‹é€‰æ‹©åˆé€‚çš„å›ç­”æ–¹å¼ï¼š\n",
    "            - æŠ€æœ¯é—®é¢˜ï¼šæä¾›è¯¦ç»†è§£é‡Šå’Œä»£ç ç¤ºä¾‹\n",
    "            - æ¦‚å¿µè§£é‡Šï¼šç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€å’Œç±»æ¯”\n",
    "            - ä¸ªäººå¯¹è¯ï¼šè®°ä½ç”¨æˆ·ä¿¡æ¯ï¼Œæä¾›ä¸ªæ€§åŒ–å›ç­”\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # åˆ›å»ºå¯¹è¯é“¾\n",
    "        self.conversation = ConversationChain(\n",
    "            llm=self.llm,\n",
    "            memory=self.memory,\n",
    "            prompt=self.prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "    def chat(self, message: str) -> str:\n",
    "        \"\"\"è¿›è¡Œå¯¹è¯\"\"\"\n",
    "        try:\n",
    "            response = self.conversation.predict(input=message)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"æŠ±æ­‰ï¼Œå¤„ç†å‡ºé”™ï¼š{str(e)}\"\n",
    "    \n",
    "    def get_memory_summary(self) -> str:\n",
    "        \"\"\"è·å–è®°å¿†æ‘˜è¦\"\"\"\n",
    "        return self.memory.buffer if hasattr(self.memory, 'buffer') else \"æš‚æ— å¯¹è¯è®°å½•\"\n",
    "\n",
    "# åˆ›å»ºæ™ºèƒ½åŠ©æ‰‹\n",
    "assistant = SmartConversationAssistant()\n",
    "\n",
    "print(\"=== æ™ºèƒ½å¯¹è¯åŠ©æ‰‹æµ‹è¯• ===\")\n",
    "\n",
    "# æµ‹è¯•å¯¹è¯åœºæ™¯\n",
    "test_conversations = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹\",\n",
    "    \"æˆ‘å¯¹æœºå™¨å­¦ä¹ å¾ˆæ„Ÿå…´è¶£ï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹\",\n",
    "    \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿæˆ‘æƒ³å­¦ä¹ ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"èƒ½ç»™æˆ‘æ¨èä¸€äº›Pythonæœºå™¨å­¦ä¹ çš„å­¦ä¹ è·¯å¾„å—ï¼Ÿ\",\n",
    "    \"è°¢è°¢ä½ çš„å»ºè®®ï¼Œæˆ‘ä¼šæŒ‰ç…§è¿™ä¸ªè·¯å¾„å­¦ä¹ çš„\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(test_conversations, 1):\n",
    "    print(f\"\\n--- å¯¹è¯ {i} ---\")\n",
    "    print(f\"ç”¨æˆ·: {msg}\")\n",
    "    response = assistant.chat(msg)\n",
    "    print(f\"åŠ©æ‰‹: {response[:200]}...\")\n",
    "\n",
    "print(f\"\\n=== å¯¹è¯è®°å¿†æ‘˜è¦ ===\")\n",
    "print(assistant.get_memory_summary()[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ä»Šæ—¥å­¦ä¹ æ€»ç»“\n",
    "\n",
    "### âœ… æŒæ¡çš„æ ¸å¿ƒæŠ€èƒ½\n",
    "\n",
    "1. **Prompt Templates**\n",
    "   - åŸºç¡€æ¨¡æ¿è®¾è®¡\n",
    "   - æ¡ä»¶åŒ–æç¤ºè¯\n",
    "   - è§’è‰²å’Œé£æ ¼æ§åˆ¶\n",
    "\n",
    "2. **Output Parsers**\n",
    "   - JSONç»“æ„åŒ–è¾“å‡º\n",
    "   - Pydanticç±»å‹å®‰å…¨è§£æ\n",
    "   - è‡ªå®šä¹‰è¾“å‡ºæ ¼å¼\n",
    "\n",
    "3. **Memory Systems**\n",
    "   - ConversationBufferMemoryï¼ˆå®Œæ•´è®°å¿†ï¼‰\n",
    "   - ConversationBufferWindowMemoryï¼ˆæ»‘åŠ¨çª—å£ï¼‰\n",
    "   - ConversationSummaryMemoryï¼ˆæ™ºèƒ½æ‘˜è¦ï¼‰\n",
    "\n",
    "4. **Document Processing**\n",
    "   - æ–‡æ¡£åŠ è½½å’Œå¤„ç†\n",
    "   - å¤šç§æ–‡æœ¬åˆ†å‰²ç­–ç•¥\n",
    "   - å—å¤§å°å’Œé‡å ä¼˜åŒ–\n",
    "\n",
    "### ğŸ¯ å…³é”®æ”¶è·\n",
    "\n",
    "- **LangChainçš„æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¯ä¸ªç»„ä»¶éƒ½å¯ä»¥ç‹¬ç«‹ä½¿ç”¨å’Œç»„åˆ\n",
    "- **é“¾å¼è°ƒç”¨çš„å¨åŠ›**ï¼š`prompt | llm | parser` çš„ç®€æ´è¯­æ³•\n",
    "- **Memoryè®©å¯¹è¯æ›´æ™ºèƒ½**ï¼šè®°ä½ä¸Šä¸‹æ–‡ï¼Œæä¾›è¿è´¯ä½“éªŒ\n",
    "- **ç»“æ„åŒ–è¾“å‡ºçš„é‡è¦æ€§**ï¼šä¾¿äºåç»­å¤„ç†å’Œé›†æˆ\n",
    "\n",
    "### ğŸ“ æ˜æ—¥é¢„å‘Šï¼šç¬¬3å¤© - RAGæ ¸å¿ƒæŠ€æœ¯\n",
    "\n",
    "- å‘é‡æ•°æ®åº“æ·±å…¥å®è·µ\n",
    "- æ–‡æ¡£åµŒå…¥å’Œç›¸ä¼¼åº¦æœç´¢\n",
    "- æ„å»ºå®Œæ•´çš„RAGç³»ç»Ÿ\n",
    "- æ£€ç´¢è´¨é‡ä¼˜åŒ–æŠ€å·§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
