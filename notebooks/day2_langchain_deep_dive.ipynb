{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第2天：LangChain框架深入学习\n",
    "\n",
    "## 今日学习目标\n",
    "1. 掌握LangChain的核心架构\n",
    "2. 深入理解Prompt Templates和Output Parsers\n",
    "3. 实现多种Memory系统\n",
    "4. 学习Document处理流程\n",
    "5. 构建一个完整的对话系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 环境设置\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "\n",
    "print(\"✅ 环境配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LangChain核心架构理解\n",
    "\n",
    "### LangChain的6大核心组件\n",
    "1. **Models（模型）**：各种LLM的统一接口\n",
    "2. **Prompts（提示词）**：管理和优化提示词\n",
    "3. **Chains（链）**：组合多个组件的工作流\n",
    "4. **Memory（记忆）**：维持对话状态和历史\n",
    "5. **Agents（代理）**：让LLM选择和执行工具\n",
    "6. **Callbacks（回调）**：监控和调试执行过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 核心导入\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory\n",
    "from langchain.schema import BaseMessage\n",
    "from typing import List\n",
    "\n",
    "# 初始化基础模型\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "print(\"🤖 LLM模型初始化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompt Templates深入实践\n",
    "\n",
    "### 2.1 基础Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 基础提示词模板\n",
    "basic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个专业的{role}，擅长{skill}。请用{style}的风格回答问题。\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 创建基础链\n",
    "basic_chain = basic_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 测试不同角色\n",
    "print(\"=== 基础Prompt Template测试 ===\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"role\": \"AI技术专家\",\n",
    "        \"skill\": \"深度学习和机器学习\",\n",
    "        \"style\": \"通俗易懂\",\n",
    "        \"question\": \"什么是Transformer架构？\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"诗人\",\n",
    "        \"skill\": \"现代诗创作\",\n",
    "        \"style\": \"优美抒情\",\n",
    "        \"question\": \"描述一下春天的景色\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n--- 测试 {i} ---\")\n",
    "    response = basic_chain.invoke(case)\n",
    "    print(f\"角色: {case['role']}\")\n",
    "    print(f\"回答: {response[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 条件化Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 条件化提示词（根据用户类型调整）\n",
    "def create_conditional_prompt(user_type: str) -> ChatPromptTemplate:\n",
    "    \"\"\"根据用户类型创建不同的提示词\"\"\"\n",
    "    \n",
    "    if user_type == \"beginner\":\n",
    "        system_message = \"\"\"\n",
    "        你是一个耐心的AI导师，专门为初学者解答问题。\n",
    "        请用简单易懂的语言解释，避免使用专业术语。\n",
    "        如果必须使用术语，请提供简单的解释。\n",
    "        用类比和例子帮助理解。\n",
    "        \"\"\"\n",
    "    elif user_type == \"expert\":\n",
    "        system_message = \"\"\"\n",
    "        你是一个技术专家，为有经验的开发者提供深入分析。\n",
    "        可以使用专业术语和技术细节。\n",
    "        提供代码示例和最佳实践。\n",
    "        关注性能优化和架构设计。\n",
    "        \"\"\"\n",
    "    else:  # intermediate\n",
    "        system_message = \"\"\"\n",
    "        你是一个经验丰富的技术顾问。\n",
    "        提供中等深度的技术解释。\n",
    "        包含一些代码示例和实践建议。\n",
    "        平衡理论和实践应用。\n",
    "        \"\"\"\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message.strip()),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "# 测试条件化提示词\n",
    "print(\"=== 条件化Prompt Template测试 ===\")\n",
    "question = \"什么是RESTful API？\"\n",
    "\n",
    "for user_type in [\"beginner\", \"intermediate\", \"expert\"]:\n",
    "    print(f\"\\n--- {user_type.upper()} 版本 ---\")\n",
    "    prompt = create_conditional_prompt(user_type)\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    print(f\"回答: {response[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Output Parsers：结构化输出\n",
    "\n",
    "### 3.1 JSON Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# JSON输出解析器\n",
    "json_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    你是一个技术分析师。请分析给定的技术概念，并以JSON格式返回结果。\n",
    "    \n",
    "    返回格式：\n",
    "    {\n",
    "        \"concept\": \"技术概念名称\",\n",
    "        \"definition\": \"简短定义\",\n",
    "        \"pros\": [\"优点1\", \"优点2\"],\n",
    "        \"cons\": [\"缺点1\", \"缺点2\"],\n",
    "        \"use_cases\": [\"使用场景1\", \"使用场景2\"],\n",
    "        \"difficulty\": \"easy/medium/hard\",\n",
    "        \"learning_time\": \"预估学习时间\"\n",
    "    }\n",
    "    \"\"\"),\n",
    "    (\"human\", \"请分析：{concept}\")\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_chain = json_prompt | llm | json_parser\n",
    "\n",
    "# 测试JSON解析\n",
    "print(\"=== JSON Output Parser测试 ===\")\n",
    "concepts = [\"Docker容器化\", \"GraphQL\"]\n",
    "\n",
    "for concept in concepts:\n",
    "    print(f\"\\n--- 分析：{concept} ---\")\n",
    "    try:\n",
    "        result = json_chain.invoke({\"concept\": concept})\n",
    "        print(f\"概念: {result['concept']}\")\n",
    "        print(f\"定义: {result['definition']}\")\n",
    "        print(f\"难度: {result['difficulty']}\")\n",
    "        print(f\"学习时间: {result['learning_time']}\")\n",
    "        print(f\"优点: {', '.join(result['pros'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"解析错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pydantic Output Parser（类型安全）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 定义Pydantic模型\n",
    "class TechAnalysis(BaseModel):\n",
    "    \"\"\"技术分析结果模型\"\"\"\n",
    "    concept: str = Field(description=\"技术概念名称\")\n",
    "    definition: str = Field(description=\"技术定义\")\n",
    "    pros: List[str] = Field(description=\"优点列表\")\n",
    "    cons: List[str] = Field(description=\"缺点列表\")\n",
    "    difficulty: str = Field(description=\"难度等级：easy/medium/hard\")\n",
    "    learning_time: str = Field(description=\"预估学习时间\")\n",
    "    related_technologies: List[str] = Field(description=\"相关技术\")\n",
    "\n",
    "# 创建Pydantic解析器\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=TechAnalysis)\n",
    "\n",
    "pydantic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    你是一个技术分析专家。请分析给定的技术概念。\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"请详细分析：{concept}\")\n",
    "])\n",
    "\n",
    "pydantic_chain = pydantic_prompt | llm | pydantic_parser\n",
    "\n",
    "# 测试Pydantic解析\n",
    "print(\"=== Pydantic Output Parser测试 ===\")\n",
    "concept = \"微服务架构\"\n",
    "\n",
    "try:\n",
    "    result = pydantic_chain.invoke({\n",
    "        \"concept\": concept,\n",
    "        \"format_instructions\": pydantic_parser.get_format_instructions()\n",
    "    })\n",
    "    \n",
    "    print(f\"📋 分析结果类型: {type(result)}\")\n",
    "    print(f\"🎯 概念: {result.concept}\")\n",
    "    print(f\"📝 定义: {result.definition}\")\n",
    "    print(f\"⭐ 优点: {result.pros}\")\n",
    "    print(f\"⚠️ 缺点: {result.cons}\")\n",
    "    print(f\"🎚️ 难度: {result.difficulty}\")\n",
    "    print(f\"⏰ 学习时间: {result.learning_time}\")\n",
    "    print(f\"🔗 相关技术: {result.related_technologies}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"解析错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory系统：让AI记住对话\n",
    "\n",
    "### 4.1 ConversationBufferMemory（完整记忆）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# 创建完整记忆系统\n",
    "buffer_memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"=== ConversationBufferMemory测试 ===\")\n",
    "\n",
    "# 模拟对话\n",
    "conversation_topics = [\n",
    "    \"我的名字是张三，我是一名Python开发者\",\n",
    "    \"我正在学习AI技术，特别是LangChain\",\n",
    "    \"你还记得我的名字和职业吗？\",\n",
    "    \"我之前提到我在学习什么技术？\"\n",
    "]\n",
    "\n",
    "for i, topic in enumerate(conversation_topics, 1):\n",
    "    print(f\"\\n--- 对话轮次 {i} ---\")\n",
    "    print(f\"用户: {topic}\")\n",
    "    response = conversation.predict(input=topic)\n",
    "    print(f\"AI: {response}\")\n",
    "    \n",
    "    # 显示记忆内容\n",
    "    print(f\"\\n当前记忆:\")\n",
    "    print(buffer_memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ConversationBufferWindowMemory（滑动窗口记忆）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建滑动窗口记忆（只记住最近3轮对话）\n",
    "window_memory = ConversationBufferWindowMemory(k=3)\n",
    "\n",
    "window_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== ConversationBufferWindowMemory测试 ===\")\n",
    "print(\"只记住最近3轮对话\")\n",
    "\n",
    "# 进行多轮对话测试\n",
    "test_messages = [\n",
    "    \"第1轮：我喜欢蓝色\",\n",
    "    \"第2轮：我的爱好是编程\", \n",
    "    \"第3轮：我住在北京\",\n",
    "    \"第4轮：我今年25岁\",\n",
    "    \"第5轮：我学过Java\",\n",
    "    \"第6轮：你还记得我喜欢什么颜色吗？\"  # 应该不记得，因为超出窗口\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    response = window_conversation.predict(input=msg)\n",
    "    print(f\"\\n{msg}\")\n",
    "    print(f\"AI: {response[:100]}...\")\n",
    "    print(f\"记忆轮次: {len(window_memory.chat_memory.messages)//2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ConversationSummaryMemory（摘要记忆）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 创建摘要记忆系统\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=1000  # 当记忆超过1000 tokens时开始摘要\n",
    ")\n",
    "\n",
    "summary_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n=== ConversationSummaryMemory测试 ===\")\n",
    "\n",
    "# 模拟长对话\n",
    "long_conversation = [\n",
    "    \"我是一名AI研究员，专注于自然语言处理\",\n",
    "    \"我最近在研究大语言模型的微调技术\",\n",
    "    \"我发现LoRA是一个很有效的参数高效微调方法\",\n",
    "    \"我还尝试过QLoRA，它在内存使用上更优化\",\n",
    "    \"除了微调，我也在研究RAG技术\",\n",
    "    \"RAG可以让模型获取最新的外部知识\",\n",
    "    \"你能总结一下我们刚才讨论的内容吗？\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(long_conversation, 1):\n",
    "    response = summary_conversation.predict(input=msg)\n",
    "    print(f\"\\n轮次 {i}: {msg}\")\n",
    "    print(f\"AI: {response[:150]}...\")\n",
    "    \n",
    "    # 显示摘要\n",
    "    if hasattr(summary_memory, 'buffer'):\n",
    "        print(f\"摘要: {summary_memory.buffer[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Document Loaders和Text Splitters\n",
    "\n",
    "### 5.1 处理不同格式的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 创建示例文档\n",
    "sample_text = \"\"\"\n",
    "人工智能（Artificial Intelligence, AI）是计算机科学的一个分支，致力于创建能够执行通常需要人类智能的任务的系统。\n",
    "\n",
    "机器学习（Machine Learning, ML）是人工智能的一个子集，它使计算机能够在没有明确编程的情况下学习和改进。机器学习算法使用统计技术来找到数据中的模式。\n",
    "\n",
    "深度学习（Deep Learning, DL）是机器学习的一个子集，它使用人工神经网络来模拟人脑的学习过程。深度学习在图像识别、自然语言处理和语音识别等领域取得了突破性进展。\n",
    "\n",
    "自然语言处理（Natural Language Processing, NLP）是人工智能的一个重要分支，专注于让计算机理解、解释和生成人类语言。NLP结合了计算语言学、机器学习和深度学习技术。\n",
    "\n",
    "大语言模型（Large Language Models, LLMs）如GPT、BERT等，代表了NLP领域的最新进展。这些模型在大量文本数据上进行预训练，能够理解和生成高质量的自然语言文本。\n",
    "\"\"\"\n",
    "\n",
    "# 创建文档对象\n",
    "doc = Document(page_content=sample_text, metadata={\"source\": \"AI技术概述\"})\n",
    "\n",
    "print(\"=== 文档处理测试 ===\")\n",
    "print(f\"原始文档长度: {len(sample_text)} 字符\")\n",
    "print(f\"原始文档:\\n{sample_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 不同的文本分割策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. 递归字符分割器（推荐）\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # 每块最大字符数\n",
    "    chunk_overlap=50,  # 重叠字符数\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"！\", \"？\", \";\", \",\", \" \", \"\"]  # 分割优先级\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_documents([doc])\n",
    "\n",
    "print(\"\\n=== 递归字符分割器 ===\")\n",
    "print(f\"分割后块数: {len(recursive_chunks)}\")\n",
    "for i, chunk in enumerate(recursive_chunks):\n",
    "    print(f\"\\n块 {i+1} (长度: {len(chunk.page_content)})\")\n",
    "    print(f\"{chunk.page_content[:150]}...\")\n",
    "\n",
    "# 2. 基于Token的分割器\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=100,  # 每块最大token数\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_documents([doc])\n",
    "\n",
    "print(f\"\\n=== Token分割器 ===\")\n",
    "print(f\"分割后块数: {len(token_chunks)}\")\n",
    "for i, chunk in enumerate(token_chunks[:2]):  # 只显示前两块\n",
    "    print(f\"\\n块 {i+1}:\")\n",
    "    print(f\"{chunk.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 综合实践：构建智能对话助手\n",
    "\n",
    "将今天学到的所有技术整合到一个完整的对话系统中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class SmartConversationAssistant:\n",
    "    \"\"\"智能对话助手 - 整合今日所学技术\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "        self.memory = ConversationBufferWindowMemory(k=5)  # 记住最近5轮对话\n",
    "        \n",
    "        # 智能提示词模板\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "            你是一个智能AI助手，具有以下能力：\n",
    "            1. 记住对话历史，提供连贯的回答\n",
    "            2. 根据用户问题类型调整回答风格\n",
    "            3. 提供结构化的信息分析\n",
    "            \n",
    "            对话历史：{history}\n",
    "            \n",
    "            请根据用户的问题类型选择合适的回答方式：\n",
    "            - 技术问题：提供详细解释和代码示例\n",
    "            - 概念解释：用简单易懂的语言和类比\n",
    "            - 个人对话：记住用户信息，提供个性化回答\n",
    "            \"\"\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        \n",
    "        # 创建对话链\n",
    "        self.conversation = ConversationChain(\n",
    "            llm=self.llm,\n",
    "            memory=self.memory,\n",
    "            prompt=self.prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "    def chat(self, message: str) -> str:\n",
    "        \"\"\"进行对话\"\"\"\n",
    "        try:\n",
    "            response = self.conversation.predict(input=message)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            return f\"抱歉，处理出错：{str(e)}\"\n",
    "    \n",
    "    def get_memory_summary(self) -> str:\n",
    "        \"\"\"获取记忆摘要\"\"\"\n",
    "        return self.memory.buffer if hasattr(self.memory, 'buffer') else \"暂无对话记录\"\n",
    "\n",
    "# 创建智能助手\n",
    "assistant = SmartConversationAssistant()\n",
    "\n",
    "print(\"=== 智能对话助手测试 ===\")\n",
    "\n",
    "# 测试对话场景\n",
    "test_conversations = [\n",
    "    \"你好，我是小明，我想学习Python编程\",\n",
    "    \"我对机器学习很感兴趣，但不知道从哪里开始\",\n",
    "    \"你还记得我的名字吗？我想学习什么？\",\n",
    "    \"能给我推荐一些Python机器学习的学习路径吗？\",\n",
    "    \"谢谢你的建议，我会按照这个路径学习的\"\n",
    "]\n",
    "\n",
    "for i, msg in enumerate(test_conversations, 1):\n",
    "    print(f\"\\n--- 对话 {i} ---\")\n",
    "    print(f\"用户: {msg}\")\n",
    "    response = assistant.chat(msg)\n",
    "    print(f\"助手: {response[:200]}...\")\n",
    "\n",
    "print(f\"\\n=== 对话记忆摘要 ===\")\n",
    "print(assistant.get_memory_summary()[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 今日学习总结\n",
    "\n",
    "### ✅ 掌握的核心技能\n",
    "\n",
    "1. **Prompt Templates**\n",
    "   - 基础模板设计\n",
    "   - 条件化提示词\n",
    "   - 角色和风格控制\n",
    "\n",
    "2. **Output Parsers**\n",
    "   - JSON结构化输出\n",
    "   - Pydantic类型安全解析\n",
    "   - 自定义输出格式\n",
    "\n",
    "3. **Memory Systems**\n",
    "   - ConversationBufferMemory（完整记忆）\n",
    "   - ConversationBufferWindowMemory（滑动窗口）\n",
    "   - ConversationSummaryMemory（智能摘要）\n",
    "\n",
    "4. **Document Processing**\n",
    "   - 文档加载和处理\n",
    "   - 多种文本分割策略\n",
    "   - 块大小和重叠优化\n",
    "\n",
    "### 🎯 关键收获\n",
    "\n",
    "- **LangChain的模块化设计**：每个组件都可以独立使用和组合\n",
    "- **链式调用的威力**：`prompt | llm | parser` 的简洁语法\n",
    "- **Memory让对话更智能**：记住上下文，提供连贯体验\n",
    "- **结构化输出的重要性**：便于后续处理和集成\n",
    "\n",
    "### 📝 明日预告：第3天 - RAG核心技术\n",
    "\n",
    "- 向量数据库深入实践\n",
    "- 文档嵌入和相似度搜索\n",
    "- 构建完整的RAG系统\n",
    "- 检索质量优化技巧"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.11.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}"